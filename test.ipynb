{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# LLM-based history update solution\n",
    "import importlib.util\n",
    "import inspect\n",
    "from typing import List\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import difflib\n",
    "from collections import Counter\n",
    "# from spellchecker import SpellChecker\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "import logging \n",
    "# from history_update_problem.call_or import export_rows\n",
    "from call_or import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worflow eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_workflows(pp_id, gt_wf_fp, pred_wf_fp):\n",
    "    # print(gt_wf_fp)\n",
    "    gt_ops_list = parse_recipe(pp_id, recipe=gt_wf_fp)\n",
    "    pred_ops_list = parse_recipe(pp_id, recipe=pred_wf_fp)\n",
    "    \n",
    "    return {'pp_id': pp_id, 'gt_ops': gt_ops_list[pp_id], 'pred_ops': pred_ops_list[pp_id]}\n",
    "    # print(gt_ops_list)\n",
    "    # print(pred_ops_list)\n",
    "\n",
    "\n",
    "models = ['llama3.1', 'gemma2', 'mistral']\n",
    "answer_gt_path = '/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_small_table.json'\n",
    "answer_preds_llama = '/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_llama3.1.json'\n",
    "\n",
    "\n",
    "# eval_answer_results = eval_answers(answer_gt_path, answer_preds_llama)\n",
    "model = models[2]\n",
    "wf_gt_folder = '/projects/bces/lanl2/LLM4DC/datasets'\n",
    "wf_pred_folder = f'/projects/bces/lanl2/LLM4DC/CoT.response/{model}/recipes_llm'\n",
    "\n",
    "ops_list = []\n",
    "query_contents = pd.read_csv('/projects/bces/lanl2/LLM4DC/purposes/queries.csv')\n",
    "for query_id in range(111):\n",
    "    row = query_contents[query_contents['ID'] == query_id]\n",
    "    if len(row) == 0:\n",
    "        continue\n",
    "    if model == 'llama3.1':\n",
    "        if query_id >= 62 and query_id <= 91:\n",
    "            target_path = f'{wf_gt_folder}/ppp_datasets/cleaned_tables/ppp_sample_p{query_id}.csv'\n",
    "            wf_gt_fp = f\"{wf_gt_folder}/ppp_datasets/workflows/ppp_sample_p{query_id}.json\"\n",
    "            wf_pred_fp = f\"{wf_pred_folder}/ppp_test_{query_id}.json\"\n",
    "        elif query_id >= 92:\n",
    "            target_path = f'{wf_gt_folder}/dish_datasets/cleaned_tables/dish_sample_p{query_id}.csv'\n",
    "            wf_gt_fp = f\"{wf_gt_folder}/dish_datasets/workflows/dish_sample_p{query_id}.json\"\n",
    "            wf_pred_fp = f\"{wf_pred_folder}/dish_test_{query_id}.json\"\n",
    "        elif query_id >= 31 and query_id <= 61:\n",
    "            target_path = f'{wf_gt_folder}/chi_food_inspection_datasets/cleaned_tables/chi_sample_p{query_id}.csv'\n",
    "            wf_gt_fp = f\"{wf_gt_folder}/chi_food_inspection_datasets/workflows/chi_sample_p{query_id}.json\"\n",
    "            wf_pred_fp = f\"{wf_pred_folder}/chi_test_{query_id}.json\"\n",
    "        elif query_id <31:\n",
    "            target_path = f'{wf_gt_folder}/purpose-prepared-datasets/menu/menu_p{query_id}'\n",
    "            wf_gt_fp = f\"{wf_gt_folder}/purpose-prepared-datasets/menu/workflows/menu_p{query_id}.json\"\n",
    "            wf_pred_fp = f\"{wf_pred_folder}/menu_test_{query_id}.json\"\n",
    "    else: \n",
    "        if query_id >= 62 and query_id <= 91:\n",
    "            target_path = f'{wf_gt_folder}/ppp_datasets/cleaned_tables/ppp_sample_p{query_id}.csv'\n",
    "            wf_gt_fp = f\"{wf_gt_folder}/ppp_datasets/workflows/ppp_sample_p{query_id}.json\"\n",
    "            wf_pred_fp = f\"{wf_pred_folder}/{model}_ppp_test_{query_id}.json\"\n",
    "        elif query_id >= 92:\n",
    "            target_path = f'{wf_gt_folder}/dish_datasets/cleaned_tables/dish_sample_p{query_id}.csv'\n",
    "            wf_gt_fp = f\"{wf_gt_folder}/dish_datasets/workflows/dish_sample_p{query_id}.json\"\n",
    "            wf_pred_fp = f\"{wf_pred_folder}/{model}_dish_test_{query_id}.json\"\n",
    "        elif query_id >= 31 and query_id <= 61:\n",
    "            target_path = f'{wf_gt_folder}/chi_food_inspection_datasets/cleaned_tables/chi_sample_p{query_id}.csv'\n",
    "            wf_gt_fp = f\"{wf_gt_folder}/chi_food_inspection_datasets/workflows/chi_sample_p{query_id}.json\"\n",
    "            wf_pred_fp = f\"{wf_pred_folder}/{model}_chi_test_{query_id}.json\"\n",
    "        elif query_id <31:\n",
    "            target_path = f'{wf_gt_folder}/purpose-prepared-datasets/menu/menu_p{query_id}'\n",
    "            wf_gt_fp = f\"{wf_gt_folder}/purpose-prepared-datasets/menu/workflows/menu_p{query_id}.json\"\n",
    "            wf_pred_fp = f\"{wf_pred_folder}/{model}_menu_test_{query_id}.json\"\n",
    "\n",
    "    ops_list.append(eval_workflows(query_id, wf_gt_fp, wf_pred_fp))\n",
    "ops_df = pd.DataFrame(ops_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_df['gt_ops_length'] = ops_df['gt_ops'].apply(len)\n",
    "ops_df['pred_ops_length'] = ops_df['pred_ops'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_df['gt_ops_set_length'] = ops_df['gt_ops'].apply(lambda x: len(set(x)))\n",
    "ops_df['pred_ops_set_length'] = ops_df['pred_ops'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp_id</th>\n",
       "      <th>gt_ops_length</th>\n",
       "      <th>pred_ops_length</th>\n",
       "      <th>gt_ops_set_length</th>\n",
       "      <th>pred_ops_set_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>58.074627</td>\n",
       "      <td>5.268657</td>\n",
       "      <td>3.402985</td>\n",
       "      <td>2.925373</td>\n",
       "      <td>1.955224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.047290</td>\n",
       "      <td>3.226698</td>\n",
       "      <td>2.322875</td>\n",
       "      <td>1.197389</td>\n",
       "      <td>0.944407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pp_id  gt_ops_length  pred_ops_length  gt_ops_set_length  \\\n",
       "count   67.000000      67.000000        67.000000          67.000000   \n",
       "mean    58.074627       5.268657         3.402985           2.925373   \n",
       "std     35.047290       3.226698         2.322875           1.197389   \n",
       "min      1.000000       1.000000         1.000000           1.000000   \n",
       "25%     31.500000       3.000000         2.000000           2.000000   \n",
       "50%     66.000000       5.000000         3.000000           3.000000   \n",
       "75%     88.000000       6.000000         5.000000           4.000000   \n",
       "max    110.000000      14.000000        10.000000           4.000000   \n",
       "\n",
       "       pred_ops_set_length  \n",
       "count            67.000000  \n",
       "mean              1.955224  \n",
       "std               0.944407  \n",
       "min               1.000000  \n",
       "25%               1.000000  \n",
       "50%               2.000000  \n",
       "75%               2.000000  \n",
       "max               4.000000  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import calculate_operation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_results = calculate_operation_metrics(ops_df['gt_ops'], ops_df['pred_ops'])\n",
    "workflow_results['pp_id'] = ops_df['pp_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_results.to_csv(f'evaluation/workflow_result_{model}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.855721</td>\n",
       "      <td>0.615672</td>\n",
       "      <td>0.684151</td>\n",
       "      <td>58.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.429572</td>\n",
       "      <td>0.241254</td>\n",
       "      <td>0.282767</td>\n",
       "      <td>0.246258</td>\n",
       "      <td>35.047290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision     recall         f1       pp_id\n",
       "count  67.000000  67.000000  67.000000  67.000000   67.000000\n",
       "mean    0.238806   0.855721   0.615672   0.684151   58.074627\n",
       "std     0.429572   0.241254   0.282767   0.246258   35.047290\n",
       "min     0.000000   0.000000   0.000000   0.000000    1.000000\n",
       "25%     0.000000   0.750000   0.500000   0.500000   31.500000\n",
       "50%     0.000000   1.000000   0.500000   0.666667   66.000000\n",
       "75%     0.000000   1.000000   0.875000   0.857143   88.000000\n",
       "max     1.000000   1.000000   1.000000   1.000000  110.000000"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_671706/814825836.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ppp_results = workflow_results[workflow_results['pp_id'] >= 62][workflow_results['pp_id'] <=91]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.734632</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455842</td>\n",
       "      <td>0.284822</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.235405</td>\n",
       "      <td>7.438638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>67.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>77.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision     recall         f1      pp_id\n",
       "count  22.000000  22.000000  22.000000  22.000000  22.000000\n",
       "mean    0.272727   0.799242   0.757576   0.734632  73.000000\n",
       "std     0.455842   0.284822   0.285112   0.235405   7.438638\n",
       "min     0.000000   0.000000   0.000000   0.000000  62.000000\n",
       "25%     0.000000   0.666667   0.541667   0.666667  67.250000\n",
       "50%     0.000000   1.000000   0.833333   0.666667  72.500000\n",
       "75%     0.750000   1.000000   1.000000   0.964286  77.750000\n",
       "max     1.000000   1.000000   1.000000   1.000000  89.000000"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppp_results = workflow_results[workflow_results['pp_id'] >= 62][workflow_results['pp_id'] <=91]\n",
    "ppp_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_671706/3831109375.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ppp_ops = ops_df[ops_df['pp_id'] >= 62][ops_df['pp_id'] <=91]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp_id</th>\n",
       "      <th>gt_ops_length</th>\n",
       "      <th>pred_ops_length</th>\n",
       "      <th>gt_ops_set_length</th>\n",
       "      <th>pred_ops_set_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>3.409091</td>\n",
       "      <td>3.863636</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>2.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.438638</td>\n",
       "      <td>1.842852</td>\n",
       "      <td>2.816541</td>\n",
       "      <td>1.255292</td>\n",
       "      <td>0.940894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>72.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pp_id  gt_ops_length  pred_ops_length  gt_ops_set_length  \\\n",
       "count  22.000000      22.000000        22.000000          22.000000   \n",
       "mean   73.000000       3.409091         3.863636           2.363636   \n",
       "std     7.438638       1.842852         2.816541           1.255292   \n",
       "min    62.000000       1.000000         1.000000           1.000000   \n",
       "25%    67.250000       2.000000         2.000000           1.000000   \n",
       "50%    72.500000       3.000000         3.000000           3.000000   \n",
       "75%    77.750000       5.000000         4.000000           3.000000   \n",
       "max    89.000000       6.000000        10.000000           4.000000   \n",
       "\n",
       "       pred_ops_set_length  \n",
       "count            22.000000  \n",
       "mean              2.136364  \n",
       "std               0.940894  \n",
       "min               1.000000  \n",
       "25%               1.250000  \n",
       "50%               2.000000  \n",
       "75%               3.000000  \n",
       "max               4.000000  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppp_ops = ops_df[ops_df['pp_id'] >= 62][ops_df['pp_id'] <=91]\n",
    "ppp_ops.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.596429</td>\n",
       "      <td>101.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261539</td>\n",
       "      <td>0.213478</td>\n",
       "      <td>0.207858</td>\n",
       "      <td>5.65059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>98.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>102.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>106.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>110.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision     recall         f1      pp_id\n",
       "count      16.0  16.000000  16.000000  16.000000   16.00000\n",
       "mean        0.0   0.760417   0.515625   0.596429  101.93750\n",
       "std         0.0   0.261539   0.213478   0.207858    5.65059\n",
       "min         0.0   0.000000   0.000000   0.000000   92.00000\n",
       "25%         0.0   0.666667   0.500000   0.571429   98.75000\n",
       "50%         0.0   0.750000   0.500000   0.666667  102.50000\n",
       "75%         0.0   1.000000   0.750000   0.750000  106.25000\n",
       "max         0.0   1.000000   0.750000   0.857143  110.00000"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dish_results = workflow_results[workflow_results['pp_id'] >= 92]\n",
    "dish_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp_id</th>\n",
       "      <th>gt_ops_length</th>\n",
       "      <th>pred_ops_length</th>\n",
       "      <th>gt_ops_set_length</th>\n",
       "      <th>pred_ops_set_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>101.93750</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>3.8125</td>\n",
       "      <td>2.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.65059</td>\n",
       "      <td>1.310216</td>\n",
       "      <td>2.552776</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.014479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>92.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>98.75000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>102.50000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>106.25000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pp_id  gt_ops_length  pred_ops_length  gt_ops_set_length  \\\n",
       "count   16.00000      16.000000        16.000000            16.0000   \n",
       "mean   101.93750       5.375000         5.625000             3.8125   \n",
       "std      5.65059       1.310216         2.552776             0.7500   \n",
       "min     92.00000       1.000000         1.000000             1.0000   \n",
       "25%     98.75000       5.000000         3.750000             4.0000   \n",
       "50%    102.50000       6.000000         6.000000             4.0000   \n",
       "75%    106.25000       6.000000         8.000000             4.0000   \n",
       "max    110.00000       7.000000         9.000000             4.0000   \n",
       "\n",
       "       pred_ops_set_length  \n",
       "count            16.000000  \n",
       "mean              2.687500  \n",
       "std               1.014479  \n",
       "min               1.000000  \n",
       "25%               2.000000  \n",
       "50%               3.000000  \n",
       "75%               3.250000  \n",
       "max               4.000000  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dish_ops= ops_df[ops_df['pp_id'] >= 92]\n",
    "\n",
    "dish_ops.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_671706/2907689086.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  chi_results = workflow_results[workflow_results['pp_id'] >= 31][workflow_results['pp_id'] <=61]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.506410</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>38.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.375534</td>\n",
       "      <td>0.389956</td>\n",
       "      <td>0.347713</td>\n",
       "      <td>0.314126</td>\n",
       "      <td>6.260376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision     recall         f1      pp_id\n",
       "count  13.000000  13.000000  13.000000  13.000000  13.000000\n",
       "mean    0.153846   0.692308   0.506410   0.538462  38.769231\n",
       "std     0.375534   0.389956   0.347713   0.314126   6.260376\n",
       "min     0.000000   0.000000   0.000000   0.000000  31.000000\n",
       "25%     0.000000   0.500000   0.333333   0.400000  34.000000\n",
       "50%     0.000000   1.000000   0.500000   0.500000  38.000000\n",
       "75%     0.000000   1.000000   0.666667   0.666667  41.000000\n",
       "max     1.000000   1.000000   1.000000   1.000000  52.000000"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_results = workflow_results[workflow_results['pp_id'] >= 31][workflow_results['pp_id'] <=61]\n",
    "chi_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_671706/2470253216.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  chi_ops = ops_df[ops_df['pp_id'] >= 31][ops_df['pp_id'] <=61]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp_id</th>\n",
       "      <th>gt_ops_length</th>\n",
       "      <th>pred_ops_length</th>\n",
       "      <th>gt_ops_set_length</th>\n",
       "      <th>pred_ops_set_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.769231</td>\n",
       "      <td>4.769231</td>\n",
       "      <td>5.153846</td>\n",
       "      <td>2.692308</td>\n",
       "      <td>2.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.260376</td>\n",
       "      <td>2.047513</td>\n",
       "      <td>3.647971</td>\n",
       "      <td>1.031553</td>\n",
       "      <td>1.091928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pp_id  gt_ops_length  pred_ops_length  gt_ops_set_length  \\\n",
       "count  13.000000      13.000000        13.000000          13.000000   \n",
       "mean   38.769231       4.769231         5.153846           2.692308   \n",
       "std     6.260376       2.047513         3.647971           1.031553   \n",
       "min    31.000000       1.000000         1.000000           1.000000   \n",
       "25%    34.000000       4.000000         3.000000           2.000000   \n",
       "50%    38.000000       5.000000         4.000000           3.000000   \n",
       "75%    41.000000       6.000000         9.000000           3.000000   \n",
       "max    52.000000       8.000000        13.000000           4.000000   \n",
       "\n",
       "       pred_ops_set_length  \n",
       "count            13.000000  \n",
       "mean              2.230769  \n",
       "std               1.091928  \n",
       "min               1.000000  \n",
       "25%               1.000000  \n",
       "50%               2.000000  \n",
       "75%               3.000000  \n",
       "max               4.000000  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_ops = ops_df[ops_df['pp_id'] >= 31][ops_df['pp_id'] <=61]\n",
    "\n",
    "chi_ops.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.579464</td>\n",
       "      <td>9.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.299498</td>\n",
       "      <td>0.280335</td>\n",
       "      <td>0.220044</td>\n",
       "      <td>5.667157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>14.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision     recall         f1      pp_id\n",
       "count   16.0000  16.000000  16.000000  16.000000  16.000000\n",
       "mean     0.0625   0.802083   0.510417   0.579464   9.375000\n",
       "std      0.2500   0.299498   0.280335   0.220044   5.667157\n",
       "min      0.0000   0.000000   0.000000   0.000000   1.000000\n",
       "25%      0.0000   0.625000   0.333333   0.500000   4.750000\n",
       "50%      0.0000   1.000000   0.500000   0.666667   8.500000\n",
       "75%      0.0000   1.000000   0.500000   0.666667  14.250000\n",
       "max      1.0000   1.000000   1.000000   1.000000  18.000000"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_results = workflow_results[workflow_results['pp_id'] < 31]\n",
    "menu_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp_id</th>\n",
       "      <th>gt_ops_length</th>\n",
       "      <th>pred_ops_length</th>\n",
       "      <th>gt_ops_set_length</th>\n",
       "      <th>pred_ops_set_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.375000</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.667157</td>\n",
       "      <td>4.688639</td>\n",
       "      <td>5.389805</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>0.7932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.250000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pp_id  gt_ops_length  pred_ops_length  gt_ops_set_length  \\\n",
       "count  16.000000      16.000000        16.000000          16.000000   \n",
       "mean    9.375000       8.125000         5.625000           3.000000   \n",
       "std     5.667157       4.688639         5.389805           1.154701   \n",
       "min     1.000000       1.000000         0.000000           1.000000   \n",
       "25%     4.750000       4.000000         1.750000           2.000000   \n",
       "50%     8.500000       7.500000         3.500000           3.500000   \n",
       "75%    14.250000      11.750000         8.500000           4.000000   \n",
       "max    18.000000      14.000000        18.000000           4.000000   \n",
       "\n",
       "       pred_ops_set_length  \n",
       "count              16.0000  \n",
       "mean                1.6875  \n",
       "std                 0.7932  \n",
       "min                 0.0000  \n",
       "25%                 1.0000  \n",
       "50%                 2.0000  \n",
       "75%                 2.0000  \n",
       "max                 3.0000  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_ops = ops_df[ops_df['pp_id'] < 31]\n",
    "menu_ops.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_tg_cols(tg_cols_fp=\"target_columns_list.csv\"):\n",
    "#     id_tg_cols = {}\n",
    "#     tg_df = pd.read_csv(tg_cols_fp)\n",
    "#     result_dict = tg_df.set_index('ID')['tg_columns'].to_dict()\n",
    "#     return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'page_count', 2: 'page_count', 3: 'event', 4: 'event', 5: 'event', 6: 'venue', 7: 'occasion', 8: 'occasion', 9: 'page_count, dish_count', 12: 'page_count, location', 13: 'sponsor, currency', 14: 'sponsor, dish_count', 15: 'sponsor, event', 16: 'sponsor, event', 17: 'sponsor, event', 18: 'sponsor, event', 31: 'Risk', 32: 'Results', 33: 'Facility Type', 34: 'Facility Type', 36: 'DBA Name, Results', 37: 'DBA Name, Results', 38: 'Facility Type, Risk', 39: 'Facility Type, Risk', 40: 'Facility Type, Risk', 41: 'Facility Type, Risk', 42: 'Facility Type, Risk', 49: 'Facility Type, Risk, Results', 52: 'Address, Risk, Results', 62: 'LoanAmount', 63: 'LoanAmount', 64: 'LoanAmount', 65: 'NAICSCode, JobsReported', 66: 'JobsReported, LoanAmount', 67: 'City', 68: 'BusinessType, LoanAmount', 69: 'BusinessType, LoanAmount', 70: 'BusinessType, LoanAmount', 71: 'BusinessType, Zip', 72: 'Zip, LoanAmount', 73: 'Zip, LoanAmount', 74: 'Gender, LoanAmount', 75: 'Gender, LoanAmount', 76: 'City, LoanAmount', 77: 'City, LoanAmount', 78: 'Zip, LoanAmount', 79: 'Zip, LoanAmount', 80: 'RaceEthnicity, LoanAmount', 81: 'RaceEthnicity, LoanAmount', 87: 'City, LoanAmount, JobsReported', 89: 'City, LoanAmount, State, Zip', 92: 'times_appeared', 93: 'name, first_appeared, last_appeared', 94: 'name, first_appeared, last_appeared', 98: 'name, lowest_price', 99: 'name, highest_price', 100: 'name, first_appeared', 101: 'name, first_appeared', 102: 'name, menus_appeared', 103: 'name, menus_appeared', 104: 'name, times_appeared, highest_price', 105: 'name, times_appeared, lowest_price', 106: 'name, highest_price, lowest_price', 107: 'name, highest_price, lowest_price', 108: 'name,  highest_price, lowest_price', 109: 'name, menus_appeared, times_appeared', 110: 'name, times_appeared, highest_price, \\r\\nlowest_price'}\n",
      "16 <-!=->  16.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "16 <-!=->  16.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "5 <-!=->  5.0\n",
      "3 <-!=->  3.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "6 <-!=->  6.0\n",
      "2 <-!=->  2.0\n",
      "5 <-!=->  5.0\n",
      "2 <-!=->  2.0\n",
      "11 <-!=->  11.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "5 <-!=->  5.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "14 <-!=->  14.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "12 <-!=->  12.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "20 <-!=->  20.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "22 <-!=->  22.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "6 <-!=->  6.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "5 <-!=->  5.0\n",
      "4 <-!=->  4.0\n",
      "8 <-!=->  8.0\n",
      "2 <-!=->  2.0\n",
      "BANQUET <-->  11TH ANNUAL BANQUET\n",
      "DINNER <-->  CHRISTMAS DINNER\n",
      "DINNER <-->  FOURTH ANNUSL DINNER\n",
      "LUNCHEON <-->  LUNCHEON TENDERED IMPERIAL COUNCIL\n",
      "DINNER <-->  LUNCH AND DINNER\n",
      "BANQUET <-->  PRIVATE BANQUET\n",
      "DINNER <-->  SECOND ANNUAL DINNER\n",
      "DINNER <-->  THANKSGIVING DINNER\n",
      "BREAKFAST <-->  BREAKFAST MENU\n",
      "BREAKFAST <-->  ZWEITES FRUHSTUCK\n",
      "DINNER <-->  DINNER (?)\n",
      "BREAKFAST <-->  FRUHSTUCK\n",
      "BANQUET <-->  BANQUET AND RECEPTION COMMEMORATING 50 YEARS SINCE THE ADMISSION OF HONORABLE JAMES TYNDALE MITCHELL,LL.D. CHIEF JUSTICE OF THE SUPREME COURT OF PA TO THE BAR OF PHILADELPHIA\n",
      "DINNER <-->  DINNER TO QUEEN ALEXANDRE & PRINCESS VICTORIA OF RUSSIA\n",
      "DINNER <-->  DAILY MENU, DINNER\n",
      "BANQUET <-->  THIRD ANNUAL BANQUET\n",
      "BANQUET <-->  FIRST ANNUAL BANQUET\n",
      "BANQUET <-->  ALL AMERICAN BANQUET IN HONOR OF EDWIN C. HALL\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "DINNER <-->  DINNER TO ABOVE\n",
      "BANQUET <-->  Unknown\n",
      "LUNCHEON <-->  BREAKFAST\n",
      "DINNER <-->  CHRISTMAS DINNER\n",
      "DINNER <-->  FOURTH ANNUSL DINNER\n",
      "LUNCHEON <-->  Unknown\n",
      "DINNER <-->  lunch and dinner\n",
      "BANQUET <-->  PRIVATE BANQUET\n",
      "DINNER <-->  SECOND ANNUAL DINNER\n",
      "DINNER <-->  THANKSGIVING DINNER\n",
      "MENU <-->  Unknown\n",
      "BREAKFAST <-->  BREAKFAST MENU\n",
      "BREAKFAST <-->  ZWEITES FRUHSTUCK\n",
      "LUNCH <-->  BREAKFAST\n",
      "BANQUET <-->  BANQUET AND RECEPTION COMMEMORATING 50 YEARS SINCE THE ADMISSION OF HONORABLE JAMES TYNDALE MITCHELL,LL.D. CHIEF JUSTICE OF THE SUPREME COURT OF PA TO THE BAR OF PHILADELPHIA\n",
      "TIFFIN <-->  BREAKFAST\n",
      "DINNER <-->  DINNER TO QUEEN ALEXANDRE & PRINCESS VICTORIA OF RUSSIA\n",
      "DINNER <-->  DAILY MENU, DINNER\n",
      "BANQUET <-->  Unknown\n",
      "LUNCH <-->  BREAKFAST\n",
      "TIFFIN <-->  BREAKFAST\n",
      "LUNCHEON <-->  BREAKFAST\n",
      "BANQUET <-->  FIRST ANNUAL BANQUET\n",
      "BANQUET <-->  Unknown\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "DINNER <-->  DINNER TO ABOVE\n",
      "DINNER <-->  Christmas Dinner\n",
      "DINNER <-->  FOURTH ANNUSL DINNER\n",
      "DINNER <-->  lunch and dinner\n",
      "DINNER <-->  SECOND ANNUAL DINNER\n",
      "DINNER <-->  THANKSGIVING DINNER\n",
      "BREAKFAST <-->  BREAKFAST MENU\n",
      "BREAKFAST <-->  FRUHSTUCK\n",
      "BANQUET <-->  BANQUET AND RECEPTION COMMEMORATING 50 YEARS SINCE THE ADMISSION OF HONORABLE JAMES TYNDALE MITCHELL,LL.D. CHIEF JUSTICE OF THE SUPREME COURT OF PA TO THE BAR OF PHILADELPHIA\n",
      "BANQUET <-->  THIRD ANNUAL BANQUET\n",
      "PERSONALLY CONDUCTED TOUR THROUGH MEXICO & CALIFORNIA <-->  Tour\n",
      "BANQUET <-->  FIRST ANNUAL BANQUET\n",
      "BANQUET <-->  ALL AMERICAN BANQUET IN HONOR OF EDWIN C. HALL\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "DINNER <-->  DINNER TO ABOVE\n",
      "PROF <-->  PROF;\n",
      "GOVT <-->  GOVT;\n",
      "PATR <-->  PATR;\n",
      "POL <-->  POL;\n",
      "SOC <-->  SOCIAL\n",
      "SOC <-->  SOCIAL\n",
      "PROF <-->  PROF;\n",
      "SOC <-->  SOCIAL\n",
      "GOVT <-->  GOV;\n",
      "SOC <-->  SOCIAL\n",
      "SOC <-->  SOCIAL\n",
      "PATR <-->  PATR;\n",
      "SOC <-->  SOCIAL\n",
      "POL <-->  POL;\n",
      "EDUC <-->  EDUC;\n",
      "SOC <-->  SOCIAL\n",
      "[SOC?] <-->  Unknown\n",
      "DAILY <-->  OTHER (DAILY MENU)\n",
      "DAILY <-->  Other\n",
      "OTHER (ANNIV) <-->  Other\n",
      "OTHER, [SOC?] <-->  OTHER, [SOC?];\n",
      "[SOC?] <-->  UNKNOWN\n",
      "UNKNOWN <-->  ?\n",
      "DAILY <-->  OTHER (DAILY);\n",
      "OTHER (ANNIV) <-->  Anniversary\n",
      "OTHER, [SOC?] <-->  OTHER, [SOC?];\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "16 <-!=->  16.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "5 <-!=->  5.0\n",
      "3 <-!=->  3.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "6 <-!=->  6.0\n",
      "2 <-!=->  2.0\n",
      "5 <-!=->  5.0\n",
      "2 <-!=->  2.0\n",
      "11 <-!=->  11.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "5 <-!=->  5.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "14 <-!=->  14.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "12 <-!=->  12.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "20 <-!=->  20.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "22 <-!=->  22.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "6 <-!=->  6.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "5 <-!=->  5.0\n",
      "4 <-!=->  4.0\n",
      "8 <-!=->  8.0\n",
      "2 <-!=->  2.0\n",
      "22 <-!=->  22.0\n",
      "546 <-!=->  546.0\n",
      "28 <-!=->  28.0\n",
      "23 <-!=->  23.0\n",
      "78 <-!=->  78.0\n",
      "55 <-!=->  55.0\n",
      "383 <-!=->  383.0\n",
      "416 <-!=->  416.0\n",
      "60 <-!=->  60.0\n",
      "34 <-!=->  34.0\n",
      "20 <-!=->  20.0\n",
      "6 <-!=->  6.0\n",
      "78 <-!=->  78.0\n",
      "227 <-!=->  227.0\n",
      "479 <-!=->  479.0\n",
      "13 <-!=->  13.0\n",
      "19 <-!=->  19.0\n",
      "188 <-!=->  188.0\n",
      "8 <-!=->  8.0\n",
      "17 <-!=->  17.0\n",
      "23 <-!=->  23.0\n",
      "12 <-!=->  12.0\n",
      "67 <-!=->  67.0\n",
      "47 <-!=->  47.0\n",
      "201 <-!=->  201.0\n",
      "43 <-!=->  43.0\n",
      "172 <-!=->  172.0\n",
      "27 <-!=->  27.0\n",
      "19 <-!=->  19.0\n",
      "22 <-!=->  22.0\n",
      "55 <-!=->  55.0\n",
      "92 <-!=->  92.0\n",
      "14 <-!=->  14.0\n",
      "378 <-!=->  378.0\n",
      "34 <-!=->  34.0\n",
      "26 <-!=->  26.0\n",
      "93 <-!=->  93.0\n",
      "9 <-!=->  9.0\n",
      "430 <-!=->  430.0\n",
      "14 <-!=->  14.0\n",
      "226 <-!=->  226.0\n",
      "25 <-!=->  25.0\n",
      "14 <-!=->  14.0\n",
      "93 <-!=->  93.0\n",
      "75 <-!=->  75.0\n",
      "11 <-!=->  11.0\n",
      "29 <-!=->  29.0\n",
      "218 <-!=->  218.0\n",
      "97 <-!=->  97.0\n",
      "33 <-!=->  33.0\n",
      "22 <-!=->  22.0\n",
      "37 <-!=->  37.0\n",
      "68 <-!=->  68.0\n",
      "13 <-!=->  13.0\n",
      "298 <-!=->  298.0\n",
      "125 <-!=->  125.0\n",
      "24 <-!=->  24.0\n",
      "11 <-!=->  11.0\n",
      "18 <-!=->  18.0\n",
      "43 <-!=->  43.0\n",
      "90 <-!=->  90.0\n",
      "151 <-!=->  151.0\n",
      "7 <-!=->  7.0\n",
      "65 <-!=->  65.0\n",
      "38 <-!=->  38.0\n",
      "22 <-!=->  22.0\n",
      "26 <-!=->  26.0\n",
      "170 <-!=->  170.0\n",
      "26 <-!=->  26.0\n",
      "17 <-!=->  17.0\n",
      "69 <-!=->  69.0\n",
      "70 <-!=->  70.0\n",
      "20 <-!=->  20.0\n",
      "13 <-!=->  13.0\n",
      "50 <-!=->  50.0\n",
      "113 <-!=->  113.0\n",
      "20 <-!=->  20.0\n",
      "12 <-!=->  12.0\n",
      "311 <-!=->  311.0\n",
      "186 <-!=->  186.0\n",
      "114 <-!=->  114.0\n",
      "48 <-!=->  48.0\n",
      "30 <-!=->  30.0\n",
      "13 <-!=->  13.0\n",
      "16 <-!=->  16.0\n",
      "81 <-!=->  81.0\n",
      "23 <-!=->  23.0\n",
      "16 <-!=->  16.0\n",
      "45 <-!=->  45.0\n",
      "254 <-!=->  254.0\n",
      "12 <-!=->  12.0\n",
      "18 <-!=->  18.0\n",
      "489 <-!=->  489.0\n",
      "43 <-!=->  43.0\n",
      "26 <-!=->  26.0\n",
      "164 <-!=->  164.0\n",
      "69 <-!=->  69.0\n",
      "76 <-!=->  76.0\n",
      "23 <-!=->  23.0\n",
      "22 <-!=->  22.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "16 <-!=->  16.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "5 <-!=->  5.0\n",
      "3 <-!=->  3.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "6 <-!=->  6.0\n",
      "2 <-!=->  2.0\n",
      "5 <-!=->  5.0\n",
      "2 <-!=->  2.0\n",
      "11 <-!=->  11.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "5 <-!=->  5.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "14 <-!=->  14.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "12 <-!=->  12.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "20 <-!=->  20.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "22 <-!=->  22.0\n",
      "2 <-!=->  2.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "3 <-!=->  3.0\n",
      "2 <-!=->  2.0\n",
      "6 <-!=->  6.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "8 <-!=->  8.0\n",
      "4 <-!=->  4.0\n",
      "5 <-!=->  5.0\n",
      "4 <-!=->  4.0\n",
      "8 <-!=->  8.0\n",
      "2 <-!=->  2.0\n",
      "ADAM'S RESTAURANT <-->  Adams' Restaurant\n",
      "S.S. NIEUW AMSTERDAM <-->  UNKNOWN\n",
      "UNKNOWN <-->  ?\n",
      "THE PENNSYLVANIA BAR ASSOCIATION ON BEHALF OF THE BAR OF THE COMMONWEALTH <-->  UNKNOWN\n",
      "GARDNER & SMITH <-->  UNKNOWN\n",
      "FRATERNAL UNION OF ANOINTED HIGH PRIESTS OF THE STATE OF NEW YORK <-->  UNKNOWN\n",
      "PENNSYLVANIA RAILROAD <-->  UNKNOWN\n",
      "UNKNOWN <-->  [Restaurant And/Or Location Not Given]\n",
      "S.S. NIEUW AMSTERDAM <-->  UNKNOWN\n",
      "T.N. \"CONTE DI SAVOIA\"\"\" <-->  UNKNOWN\n",
      "NOVIOMAGUS <-->  UNKNOWN\n",
      "BIRMINGHAM ALUMNI ASSOCIATION OF THE UNIVERSITY OF THE SOUTH <-->  UNKNOWN\n",
      "FREINDS OF WILLIAM CLAUSS <-->  UNKNOWN\n",
      "TRUSTEES OF THE MISSOURI BOTANICAL GARDEN <-->  Missouri Botanical Garden Trustees\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "THE MOUQUIN RESTAURANT AND WINE CO. <-->  Mouquin Restaurant & Wine Co.\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "THE BRASS RAIL <-->  Brass Rail\n",
      "TOPSIDE <-->  Topside Restaurant\n",
      "PARK LANE <-->  Park Lane Hotel\n",
      "R.M.S. PARTHIA <-->  RMS Parthia\n",
      "T.N. \"CONTE DI SAVOIA\"\"\" <-->  Conte di Savoia\n",
      "THE FOUR SEASONS <-->  Four Seasons\n",
      "PLAZA <-->  Plaza Hotel\n",
      "COEUR DE LION CAMMANDERY NUMBER TWENTY-THREE KNIGHTS TEMPLAR <-->  Coeur de Lion Commandery No. 23, Knights Templar\n",
      "ADAM'S RESTAURANT <-->  ADAMS' RESTAURANT\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  UNKNOWN\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  UNKNOWN\n",
      "HAMBURG-AMERIKA LINIE <-->  HAMBURG AMERICA LINE\n",
      "HAMBURG-AMERIKA LINIE <-->  HAMBURG AMERICA LINE\n",
      "NORDDEUTSCHERRR LLOYD BREMEN <-->  NORDDEUTSCHER LLOYD BREMEN\n",
      "HAMBURG-AMERIKA LINIE <-->  HAMBURG AMERICA LINE\n",
      "HAMBURG-AMERIKA LINIE <-->  HAMBURG AMERICA LINE\n",
      "R.M.S. PARTHIA <-->  RMS PARTHIA\n",
      "AMERICAN LINE TO MONTREAL <-->  AMERICAN LINE\n",
      "22 <-!=->  22.0\n",
      "546 <-!=->  546.0\n",
      "28 <-!=->  28.0\n",
      "23 <-!=->  23.0\n",
      "78 <-!=->  78.0\n",
      "55 <-!=->  55.0\n",
      "383 <-!=->  383.0\n",
      "416 <-!=->  416.0\n",
      "60 <-!=->  60.0\n",
      "34 <-!=->  34.0\n",
      "20 <-!=->  20.0\n",
      "6 <-!=->  6.0\n",
      "78 <-!=->  78.0\n",
      "227 <-!=->  227.0\n",
      "479 <-!=->  479.0\n",
      "13 <-!=->  13.0\n",
      "19 <-!=->  19.0\n",
      "188 <-!=->  188.0\n",
      "8 <-!=->  8.0\n",
      "17 <-!=->  17.0\n",
      "23 <-!=->  23.0\n",
      "12 <-!=->  12.0\n",
      "67 <-!=->  67.0\n",
      "47 <-!=->  47.0\n",
      "201 <-!=->  201.0\n",
      "43 <-!=->  43.0\n",
      "172 <-!=->  172.0\n",
      "27 <-!=->  27.0\n",
      "19 <-!=->  19.0\n",
      "22 <-!=->  22.0\n",
      "55 <-!=->  55.0\n",
      "92 <-!=->  92.0\n",
      "14 <-!=->  14.0\n",
      "378 <-!=->  378.0\n",
      "34 <-!=->  34.0\n",
      "26 <-!=->  26.0\n",
      "93 <-!=->  93.0\n",
      "9 <-!=->  9.0\n",
      "430 <-!=->  430.0\n",
      "14 <-!=->  14.0\n",
      "226 <-!=->  226.0\n",
      "25 <-!=->  25.0\n",
      "14 <-!=->  14.0\n",
      "93 <-!=->  93.0\n",
      "75 <-!=->  75.0\n",
      "11 <-!=->  11.0\n",
      "29 <-!=->  29.0\n",
      "218 <-!=->  218.0\n",
      "97 <-!=->  97.0\n",
      "33 <-!=->  33.0\n",
      "22 <-!=->  22.0\n",
      "37 <-!=->  37.0\n",
      "68 <-!=->  68.0\n",
      "13 <-!=->  13.0\n",
      "298 <-!=->  298.0\n",
      "125 <-!=->  125.0\n",
      "24 <-!=->  24.0\n",
      "11 <-!=->  11.0\n",
      "18 <-!=->  18.0\n",
      "43 <-!=->  43.0\n",
      "90 <-!=->  90.0\n",
      "151 <-!=->  151.0\n",
      "7 <-!=->  7.0\n",
      "65 <-!=->  65.0\n",
      "38 <-!=->  38.0\n",
      "22 <-!=->  22.0\n",
      "26 <-!=->  26.0\n",
      "170 <-!=->  170.0\n",
      "26 <-!=->  26.0\n",
      "17 <-!=->  17.0\n",
      "69 <-!=->  69.0\n",
      "70 <-!=->  70.0\n",
      "20 <-!=->  20.0\n",
      "13 <-!=->  13.0\n",
      "50 <-!=->  50.0\n",
      "113 <-!=->  113.0\n",
      "20 <-!=->  20.0\n",
      "12 <-!=->  12.0\n",
      "311 <-!=->  311.0\n",
      "186 <-!=->  186.0\n",
      "114 <-!=->  114.0\n",
      "48 <-!=->  48.0\n",
      "30 <-!=->  30.0\n",
      "13 <-!=->  13.0\n",
      "16 <-!=->  16.0\n",
      "81 <-!=->  81.0\n",
      "23 <-!=->  23.0\n",
      "16 <-!=->  16.0\n",
      "45 <-!=->  45.0\n",
      "254 <-!=->  254.0\n",
      "12 <-!=->  12.0\n",
      "18 <-!=->  18.0\n",
      "489 <-!=->  489.0\n",
      "43 <-!=->  43.0\n",
      "26 <-!=->  26.0\n",
      "164 <-!=->  164.0\n",
      "69 <-!=->  69.0\n",
      "76 <-!=->  76.0\n",
      "23 <-!=->  23.0\n",
      "22 <-!=->  22.0\n",
      "ADAM'S RESTAURANT <-->  Adams' Restaurant\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "BANQUET <-->  11TH ANNUAL BANQUET\n",
      "LUNCHEON <-->  Lunch\n",
      "DINNER <-->  CHRISTMAS DINNER\n",
      "DINNER <-->  FOURTH ANNUSL DINNER\n",
      "LUNCHEON <-->  LUNCHEON TENDERED IMPERIAL COUNCIL\n",
      "DINNER <-->  lunch and dinner\n",
      "BANQUET <-->  PRIVATE BANQUET\n",
      "DINNER <-->  SECOND ANNUAL DINNER\n",
      "DINNER <-->  THANKSGIVING DINNER\n",
      "BREAKFAST <-->  BREAKFAST MENU\n",
      "BREAKFAST <-->  ZWEITES FRUHSTUCK\n",
      "BANQUET <-->  BANQUET AND RECEPTION COMMEMORATING 50 YEARS SINCE THE ADMISSION OF HONORABLE JAMES TYNDALE MITCHELL,LL.D. CHIEF JUSTICE OF THE SUPREME COURT OF PA TO THE BAR OF PHILADELPHIA\n",
      "DINNER <-->  DINNER TO QUEEN ALEXANDRE & PRINCESS VICTORIA OF RUSSIA\n",
      "DINNER <-->  DAILY MENU, DINNER\n",
      "BANQUET <-->  THIRD ANNUAL BANQUET\n",
      "LUNCHEON <-->  Lunch\n",
      "BANQUET <-->  FIRST ANNUAL BANQUET\n",
      "BANQUET <-->  ALL AMERICAN BANQUET IN HONOR OF EDWIN C. HALL\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "DINNER <-->  DINNER TO ABOVE\n",
      "ADAM'S RESTAURANT <-->  Adams' Restaurant\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "THE PENNSYLVANIA BAR ASSOCIATION ON BEHALF OF THE BAR OF THE COMMONWEALTH <-->  Pennsylvania Bar Association\n",
      "COEUR DE LION CAMMANDERY NUMBER TWENTY-THREE KNIGHTS TEMPLAR <-->  Coeur de Lion Cammandery\n",
      "FREINDS OF WILLIAM CLAUSS <-->  Friends of William Clauss\n",
      "BANQUET <-->  11TH ANNUAL BANQUET\n",
      "LUNCHEON <-->  OTHER\n",
      "DINNER <-->  CHRISTMAS DINNER\n",
      "DINNER <-->  FOURTH ANNUSL DINNER\n",
      "LUNCHEON <-->  LUNCHEON TENDERED IMPERIAL COUNCIL\n",
      "DINNER <-->  LUNCH\n",
      "BANQUET <-->  PRIVATE BANQUET\n",
      "DINNER <-->  SECOND ANNUAL DINNER\n",
      "DINNER <-->  OTHER\n",
      "MENU <-->  OTHER\n",
      "BREAKFAST <-->  OTHER\n",
      "BREAKFAST <-->  ZWEITES FRUHSTUCK\n",
      "BREAKFAST <-->  FRUHSTUCK\n",
      "BANQUET <-->  BANQUET AND RECEPTION COMMEMORATING 50 YEARS SINCE THE ADMISSION OF HONORABLE JAMES TYNDALE MITCHELL,LL.D. CHIEF JUSTICE OF THE SUPREME COURT OF PA TO THE BAR OF PHILADELPHIA\n",
      "BANQUET <-->  OTHER\n",
      "LUNCHEON <-->  OTHER\n",
      "BANQUET <-->  OTHER\n",
      "BANQUET <-->  OTHER\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "DINNER <-->  DINNER TO ABOVE\n",
      "ADAM'S RESTAURANT <-->  Adams' Restaurant\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "BANQUET <-->  11TH ANNUAL BANQUET\n",
      "DINNER <-->  CHRISTMAS DINNER\n",
      "DINNER <-->  lunch and dinner\n",
      "BANQUET <-->  PRIVATE BANQUET\n",
      "15NTH BURNS ANNIVERSARY <-->  Burns Anniversary\n",
      "DINNER <-->  SECOND ANNUAL DINNER\n",
      "BREAKFAST <-->  Breakfast Menu\n",
      "BREAKFAST <-->  ZWEITES FRUHSTUCK\n",
      "BREAKFAST <-->  FRUHSTUCK\n",
      "BANQUET <-->  BANQUET AND RECEPTION COMMEMORATING 50 YEARS SINCE THE ADMISSION OF HONORABLE JAMES TYNDALE MITCHELL,LL.D. CHIEF JUSTICE OF THE SUPREME COURT OF PA TO THE BAR OF PHILADELPHIA\n",
      "BANQUET <-->  THIRD ANNUAL BANQUET\n",
      "BANQUET <-->  ALL AMERICAN BANQUET IN HONOR OF EDWIN C. HALL\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "DINNER <-->  DINNER TO ABOVE\n",
      "ADAM'S RESTAURANT <-->  Adams' Restaurant\n",
      "? <-->  Unknown\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "[RESTAURANT AND/OR LOCATION NOT GIVEN] <-->  [Restaurant name and/or location not given]\n",
      "HAMBURG-AMERIKA LINIE <-->  Hamburg America Line\n",
      "HAMBURG-AMERIKA LINIE <-->  Hamburg America Line\n",
      "NORDDEUTSCHERRR LLOYD BREMEN <-->  Norddeutscher Lloyd Bremen\n",
      "HAMBURG-AMERIKA LINIE <-->  Hamburg America Line\n",
      "HAMBURG-AMERIKA LINIE <-->  Hamburg America Line\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "LUNCHEON <-->  LUNCH\n",
      "DINNER <-->  CHRISTMAS DINNER\n",
      "DINNER <-->  FOURTH ANNUSL DINNER\n",
      "LUNCHEON <-->  LUNCH\n",
      "DINNER <-->  LUNCH AND DINNER\n",
      "BANQUET <-->  PRIVATE BANQUET\n",
      "DINNER <-->  ANNUAL DINNER\n",
      "DINNER <-->  THANKSGIVING DINNER\n",
      "BREAKFAST <-->  BREAKFAST MENU\n",
      "BREAKFAST <-->  ZWEITES FRUHSTUCK\n",
      "DINNER <-->  DINNER (?)\n",
      "BANQUET <-->  BANQUET AND RECEPTION\n",
      "TIFFIN <-->  lunch\n",
      "DINNER <-->  DINNER TO QUEEN ALEXANDRE & PRINCESS VICTORIA OF RUSSIA\n",
      "DINNER <-->  DAILY MENU, DINNER\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "TIFFIN <-->  lunch\n",
      "LUNCHEON <-->  LUNCH\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "BANQUET <-->  ALL AMERICAN BANQUET IN HONOR OF EDWIN C. HALL\n",
      "BANQUET <-->  ANNUAL BANQUET\n",
      "MOBILE FROZEN DESSERTS VENDOR <-->  Mobile Frozen Desserts\n",
      "MOBILE FROZEN DESSERTS VENDOR <-->  Mobile Frozen Desserts\n",
      "MOBILE FROZEN DESSERTS VENDOR <-->  Mobile Frozen Dessert\n",
      "MOBILE FROZEN DESSERTS VENDOR <-->  Mobile Frozen Dessert\n",
      "7-ELEVEN <-->  7-Eleven #37622B\n",
      "7-ELEVEN <-->  7-Eleven #37622B\n",
      "7-ELEVEN <-->  7-Eleven #37622A\n",
      "7-ELEVEN <-->  7-Eleven #37622A\n",
      "7-ELEVEN <-->  7-Eleven #37622A\n",
      "Pass <-->  PASSED\n",
      "Pass <-->  PASSED\n",
      "Pass <-->  PASSED\n",
      "Out of Business <-->  FAILED\n",
      "Pass <-->  PASSED\n",
      "Pass <-->  PASSED\n",
      "Pass <-->  PASSED\n",
      "Fail <-->  FAILED\n",
      "Out of Business <-->  FAILED\n",
      "Pass <-->  PASSED\n",
      "STARBUCKS COOFEE <-->  starbucks coffee\n",
      "STARBUCKS COOFEE <-->  starbucks coffee\n",
      "STARBUCKS COOFEE <-->  starbucks coffee\n",
      "STARBUCKS COOFEE <-->  starbucks coffee\n",
      "OUT OF BUSINESS <-->  Fail\n",
      "RESTAURANT <-->  Restaurants\n",
      "MFD TRUCK <-->  Mobile Food Dispenser\n",
      "RESTAURANT <-->  Restaurants\n",
      "RISK 1 (HIGH) <-->  Risk 1\n",
      "RISK 1 (HIGH) <-->  Risk 1\n",
      "RISK 3 (LOW) <-->  Risk 3\n",
      "RISK 2 (MEDIUM) <-->  Risk 2\n",
      "RISK 3 (LOW) <-->  Risk 3\n",
      "RISK 3 (LOW) <-->  Risk 3\n",
      "RISK 1 (HIGH) <-->  Risk 1\n",
      "RISK 1 (HIGH) <-->  Risk 1\n",
      "RISK 3 (LOW) <-->  Risk 3\n",
      "RISK 3 (LOW) <-->  Risk 3\n",
      "RISK 1 (MEDIUM) <-->  risk 2 (medium)\n",
      "RISK 1 (MEDIUM) <-->  risk 2 (medium)\n",
      "MOBILE PREPARED FOOD VENDOR <-->  Restaurant\n",
      "RISK 1 <-->  Risk 1 (High)\n",
      "RISK 3 <-->  Risk 3 (Low)\n",
      "RISK 3 <-->  Risk 3 (Low)\n",
      "RISK 1 <-->  Risk 1 (High)\n",
      "RISK 1 <-->  Risk 1 (High)\n",
      "RISK 2 <-->  Risk 2 (Medium)\n",
      "RISK 1 <-->  Risk 1 (High)\n",
      "RISK 1 <-->  Risk 1 (High)\n",
      "RISK 1 <-->  Risk 1 (High)\n",
      "RISK 1 <-->  Risk 1 (High)\n",
      "970 CRISS CIR <-->  970 Criss Circle\n",
      "RISK 1 (HIGH) <-->  Risk 1   (High)\n",
      "RISK 3 (LOW) <-->  Risk 3\n",
      "RISK 1 (HIGH) <-->  Risk 1\n",
      "RISK 1 (HIGH) <-->  Risk 1\n",
      "RISK 1 (HIGH) <-->  Risk 1\n",
      "RISK 3 (LOW) <-->  Risk 3\n",
      "RISK 1 (HIGH) <-->  Risk 1\n",
      "RISK 2 (MEDIUM) <-->  Risk 2\n",
      "RISK 3 (LOW) <-->  Risk 3\n",
      "PASS <-->  Fail\n",
      "NOT READY <-->  Fail\n",
      "OUT OF BUSINESS <-->  Unknown\n",
      "52600 <-!=->  52600.0\n",
      "12100 <-!=->  12100.0\n",
      "47250 <-!=->  47250.0\n",
      "73600 <-!=->  73600.0\n",
      "4400 <-!=->  4400.0\n",
      "60000 <-!=->  60000.0\n",
      "5000 <-!=->  5000.0\n",
      "26000 <-!=->  26000.0\n",
      "25800 <-!=->  25800.0\n",
      "9479 <-!=->  9479.0\n",
      "20800 <-!=->  20800.0\n",
      "104700 <-!=->  104700.0\n",
      "18912 <-!=->  18912.0\n",
      "7500 <-!=->  7500.0\n",
      "25267 <-!=->  25267.0\n",
      "39334 <-!=->  39334.0\n",
      "47400 <-!=->  47400.0\n",
      "25000 <-!=->  25000.0\n",
      "51750 <-!=->  51750.0\n",
      "83716 <-!=->  83716.0\n",
      "29375.0 <-!=->  29375.0\n",
      "3325.0 <-!=->  3325.0\n",
      "24455.0 <-!=->  24455.0\n",
      "17232.0 <-!=->  17232.0\n",
      "3300.0 <-!=->  3300.0\n",
      "45600.0 <-!=->  45600.0\n",
      "11908.0 <-!=->  11908.0\n",
      "19925.0 <-!=->  19925.0\n",
      "7250.0 <-!=->  7250.0\n",
      "138200.0 <-!=->  138200.0\n",
      "51262.5 <-!=->  51262.5\n",
      "39800.0 <-!=->  39800.0\n",
      "29200.0 <-!=->  29200.0\n",
      "6700.0 <-!=->  6700.0\n",
      "60000.0 <-!=->  60000.0\n",
      "20832.0 <-!=->  20832.0\n",
      "3925.0 <-!=->  3925.0\n",
      "140400.0 <-!=->  140400.0\n",
      "4750.0 <-!=->  4750.0\n",
      "20800.0 <-!=->  20800.0\n",
      "3700.0 <-!=->  3700.0\n",
      "9400.0 <-!=->  9400.0\n",
      "26700.0 <-!=->  26700.0\n",
      "2000.0 <-!=->  2000.0\n",
      "20800.0 <-!=->  20800.0\n",
      "49297.0 <-!=->  49297.0\n",
      "3310.0 <-!=->  3310.0\n",
      "9027.0 <-!=->  9027.0\n",
      "81500.0 <-!=->  81500.0\n",
      "69890.0 <-!=->  69890.0\n",
      "4700.0 <-!=->  4700.0\n",
      "2945.0 <-!=->  2945.0\n",
      "3109.0 <-!=->  3109.0\n",
      "27500.0 <-!=->  27500.0\n",
      "44700.0 <-!=->  44700.0\n",
      "5800.0 <-!=->  5800.0\n",
      "2450.0 <-!=->  2450.0\n",
      "2677.5 <-!=->  2677.5\n",
      "45200.0 <-!=->  45200.0\n",
      "15300.0 <-!=->  15300.0\n",
      "722513 <-!=->  722513.0\n",
      "531210 <-!=->  531210.0\n",
      "812199 <-!=->  812199.0\n",
      "541310 <-!=->  541310.0\n",
      "531190 <-!=->  531190.0\n",
      "812990 <-!=->  812990.0\n",
      "425110 <-!=->  425110.0\n",
      "621111 <-!=->  621111.0\n",
      "112910 <-!=->  112910.0\n",
      "339910 <-!=->  339910.0\n",
      "445120 <-!=->  445120.0\n",
      "722515 <-!=->  722515.0\n",
      "722511 <-!=->  722511.0\n",
      "453220 <-!=->  453220.0\n",
      "722511 <-!=->  722511.0\n",
      "237990 <-!=->  237990.0\n",
      "722513 <-!=->  722513.0\n",
      "812112 <-!=->  812112.0\n",
      "561599 <-!=->  561599.0\n",
      "711510 <-!=->  711510.0\n",
      "0.0 <-!=->  0.0\n",
      "1.0 <-!=->  1.0\n",
      "7.0 <-!=->  7.0\n",
      "6.0 <-!=->  6.0\n",
      "2.0 <-!=->  2.0\n",
      "8.0 <-!=->  8.0\n",
      "1.0 <-!=->  1.0\n",
      "8.0 <-!=->  8.0\n",
      "3.0 <-!=->  3.0\n",
      "2.0 <-!=->  2.0\n",
      "4.0 <-!=->  4.0\n",
      "15.0 <-!=->  15.0\n",
      "1.0 <-!=->  1.0\n",
      "7.0 <-!=->  7.0\n",
      "1.0 <-!=->  1.0\n",
      "7.0 <-!=->  7.0\n",
      "1.0 <-!=->  1.0\n",
      "0.0 <-!=->  0.0\n",
      "23 <-!=->  23.0\n",
      "10 <-!=->  10.0\n",
      "1 <-!=->  1.0\n",
      "0 <-!=->  0.0\n",
      "8 <-!=->  8.0\n",
      "1 <-!=->  1.0\n",
      "0 <-!=->  0.0\n",
      "1 <-!=->  1.0\n",
      "4 <-!=->  4.0\n",
      "2 <-!=->  2.0\n",
      "1 <-!=->  1.0\n",
      "2 <-!=->  2.0\n",
      "15 <-!=->  15.0\n",
      "1 <-!=->  1.0\n",
      "1 <-!=->  1.0\n",
      "5 <-!=->  5.0\n",
      "6 <-!=->  6.0\n",
      "6 <-!=->  6.0\n",
      "4 <-!=->  4.0\n",
      "5 <-!=->  5.0\n",
      "130800.0 <-!=->  130800.0\n",
      "140100.0 <-!=->  140100.0\n",
      "7200.0 <-!=->  7200.0\n",
      "1000.0 <-!=->  1000.0\n",
      "87100.0 <-!=->  87100.0\n",
      "20800.0 <-!=->  20800.0\n",
      "2700.0 <-!=->  2700.0\n",
      "3304.0 <-!=->  3304.0\n",
      "32500.0 <-!=->  32500.0\n",
      "21665.0 <-!=->  21665.0\n",
      "11300.0 <-!=->  11300.0\n",
      "19220.0 <-!=->  19220.0\n",
      "76000.0 <-!=->  76000.0\n",
      "8800.0 <-!=->  8800.0\n",
      "20000.0 <-!=->  20000.0\n",
      "23100.0 <-!=->  23100.0\n",
      "56690.0 <-!=->  56690.0\n",
      "31957.5 <-!=->  31957.5\n",
      "14900.0 <-!=->  14900.0\n",
      "29000.0 <-!=->  29000.0\n",
      "KAILUA <-->  honolulu\n",
      "EWA BEACH <-->  honolulu\n",
      "KAHULUI <-->  honolulu\n",
      "MILILANI <-->  other\n",
      "LAHANA <-->  honolulu\n",
      "KAILUA <-->  honolulu\n",
      "HILO <-->  other\n",
      "WAILUKU <-->  honolulu\n",
      "LIHUE <-->  other\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Independent Contractors <-->  Independent Contractor\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Independent Contractors <-->  Independent Contractor\n",
      "Subchapter S Corporation <-->  S Corporation\n",
      "Sole Proprietorship <-->  Sole Proprietorship]\n",
      "77500.0 <-!=->  77500.0\n",
      "6312.5 <-!=->  6312.5\n",
      "5296.0 <-!=->  5296.0\n",
      "20410.0 <-!=->  20410.0\n",
      "15000.0 <-!=->  15000.0\n",
      "31200.0 <-!=->  31200.0\n",
      "11400.0 <-!=->  11400.0\n",
      "86378.0 <-!=->  86378.0\n",
      "8238.69 <-!=->  8238.69\n",
      "62690.0 <-!=->  62690.0\n",
      "15965.0 <-!=->  15965.0\n",
      "39334.0 <-!=->  39334.0\n",
      "4078.0 <-!=->  4078.0\n",
      "63410.0 <-!=->  63410.0\n",
      "82500.0 <-!=->  82500.0\n",
      "20832.5 <-!=->  20832.5\n",
      "95900.0 <-!=->  95900.0\n",
      "65600.0 <-!=->  65600.0\n",
      "39202.5 <-!=->  39202.5\n",
      "14851.0 <-!=->  14851.0\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Independent Contractors <-->  Independent Contractor\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Subchapter S Corporation <-->  S Corporation\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Independent Contractors <-->  Independent Contractor\n",
      "Subchapter S Corporation <-->  S Corporation\n",
      "77500.0 <-!=->  77500.0\n",
      "6312.5 <-!=->  6312.5\n",
      "5296.0 <-!=->  5296.0\n",
      "20410.0 <-!=->  20410.0\n",
      "15000.0 <-!=->  15000.0\n",
      "31200.0 <-!=->  31200.0\n",
      "11400.0 <-!=->  11400.0\n",
      "86378.0 <-!=->  86378.0\n",
      "8238.69 <-!=->  8238.69\n",
      "62690.0 <-!=->  62690.0\n",
      "15965.0 <-!=->  15965.0\n",
      "39334.0 <-!=->  39334.0\n",
      "4078.0 <-!=->  4078.0\n",
      "63410.0 <-!=->  63410.0\n",
      "82500.0 <-!=->  82500.0\n",
      "20832.5 <-!=->  20832.5\n",
      "95900.0 <-!=->  95900.0\n",
      "65600.0 <-!=->  65600.0\n",
      "39202.5 <-!=->  39202.5\n",
      "14851.0 <-!=->  14851.0\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Independent Contractors <-->  Independent Contractor\n",
      "Self-Employed Individuals <-->  Self-Employed Individual\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Subchapter S Corporation <-->  S Corporation\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Limited Liability Company(LLC) <-->  Limited Liability Company\n",
      "Independent Contractors <-->  Independent Contractor\n",
      "Subchapter S Corporation <-->  S Corporation\n",
      "Sole Proprietorship <-->  Sole Proprietorship]\n",
      "77500.0 <-!=->  77500.0\n",
      "6312.5 <-!=->  6312.5\n",
      "5296.0 <-!=->  5296.0\n",
      "20410.0 <-!=->  20410.0\n",
      "15000.0 <-!=->  15000.0\n",
      "31200.0 <-!=->  31200.0\n",
      "11400.0 <-!=->  11400.0\n",
      "86378.0 <-!=->  86378.0\n",
      "8238.69 <-!=->  8238.69\n",
      "62690.0 <-!=->  62690.0\n",
      "15965.0 <-!=->  15965.0\n",
      "39334.0 <-!=->  39334.0\n",
      "4078.0 <-!=->  4078.0\n",
      "63410.0 <-!=->  63410.0\n",
      "82500.0 <-!=->  82500.0\n",
      "20832.5 <-!=->  20832.5\n",
      "95900.0 <-!=->  95900.0\n",
      "65600.0 <-!=->  65600.0\n",
      "39202.5 <-!=->  39202.5\n",
      "14851.0 <-!=->  14851.0\n",
      "Subchapter S Corporation <-->  S Corp\n",
      "Subchapter S Corporation <-->  S Corp\n",
      "Limited Liability Company(LLC) <-->  LLC\n",
      "Limited Liability Company(LLC) <-->  LLC\n",
      "Independent Contractors <-->  Independent Contractor\n",
      "Subchapter S Corporation <-->  S Corp\n",
      "Limited Liability Company(LLC) <-->  LLC\n",
      "Subchapter S Corporation <-->  S Corp\n",
      "Subchapter S Corporation <-->  S Corp\n",
      "Independent Contractors <-->  Independent Contractor\n",
      "Limited Liability Company(LLC) <-->  LLC\n",
      "96821 <-!=->  96821\n",
      "96701 <-!=->  96701\n",
      "96749 <-!=->  96749\n",
      "96817 <-!=->  96817\n",
      "96707 <-!=->  96707\n",
      "96708 <-!=->  96708\n",
      "96814 <-!=->  96814\n",
      "96825 <-!=->  96825\n",
      "96791 <-!=->  96791\n",
      "96815 <-!=->  96815\n",
      "96816 <-!=->  96816\n",
      "96813 <-!=->  96813\n",
      "96704 <-!=->  96704\n",
      "96750 <-!=->  96750\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96754 <-!=->  96754\n",
      "96826 <-!=->  96826\n",
      "96816 <-!=->  96816\n",
      "96821 <-!=->  96821\n",
      "96701 <-!=->  96701\n",
      "96749 <-!=->  96749\n",
      "96817 <-!=->  96817\n",
      "96707 <-!=->  96707\n",
      "96708 <-!=->  96708\n",
      "96814 <-!=->  96814\n",
      "96825 <-!=->  96825\n",
      "96791 <-!=->  96791\n",
      "96815 <-!=->  96815\n",
      "96816 <-!=->  96816\n",
      "96813 <-!=->  96813\n",
      "96704 <-!=->  96704\n",
      "96750 <-!=->  96750\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96754 <-!=->  96754\n",
      "96826 <-!=->  96826\n",
      "96816 <-!=->  96816\n",
      "4300 <-!=->  4300.0\n",
      "5000 <-!=->  5000.0\n",
      "6400 <-!=->  6400.0\n",
      "30000 <-!=->  30000.0\n",
      "4122 <-!=->  4122.0\n",
      "23615 <-!=->  23615.0\n",
      "11631 <-!=->  11631.0\n",
      "7500 <-!=->  7500.0\n",
      "32500 <-!=->  32500.0\n",
      "20000 <-!=->  20000.0\n",
      "20000 <-!=->  20000.0\n",
      "3300 <-!=->  3300.0\n",
      "15700 <-!=->  15700.0\n",
      "15636 <-!=->  15636.0\n",
      "5150 <-!=->  5150.0\n",
      "44000 <-!=->  44000.0\n",
      "73600 <-!=->  73600.0\n",
      "27400 <-!=->  27400.0\n",
      "40000 <-!=->  40000.0\n",
      "96100 <-!=->  96100.0\n",
      "96821 <-!=->  96821\n",
      "96701 <-!=->  96701\n",
      "96749 <-!=->  96749\n",
      "96817 <-!=->  96817\n",
      "96707 <-!=->  96707\n",
      "96708 <-!=->  96708\n",
      "96814 <-!=->  96814\n",
      "96825 <-!=->  96825\n",
      "96791 <-!=->  96791\n",
      "96815 <-!=->  96815\n",
      "96816 <-!=->  96816\n",
      "96813 <-!=->  96813\n",
      "96704 <-!=->  96704\n",
      "96750 <-!=->  96750\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96754 <-!=->  96754\n",
      "96826 <-!=->  96826\n",
      "96816 <-!=->  96816\n",
      "4300 <-!=->  4300.0\n",
      "5000 <-!=->  5000.0\n",
      "6400 <-!=->  6400.0\n",
      "30000 <-!=->  30000.0\n",
      "4122 <-!=->  4122.0\n",
      "23615 <-!=->  23615.0\n",
      "11631 <-!=->  11631.0\n",
      "7500 <-!=->  7500.0\n",
      "32500 <-!=->  32500.0\n",
      "20000 <-!=->  20000.0\n",
      "20000 <-!=->  20000.0\n",
      "3300 <-!=->  3300.0\n",
      "15700 <-!=->  15700.0\n",
      "15636 <-!=->  15636.0\n",
      "5150 <-!=->  5150.0\n",
      "44000 <-!=->  44000.0\n",
      "73600 <-!=->  73600.0\n",
      "27400 <-!=->  27400.0\n",
      "40000 <-!=->  40000.0\n",
      "96100 <-!=->  96100.0\n",
      "Male Owned <-->  Male\n",
      "Unanswered <-->  Unknown\n",
      "Male Owned <-->  Male\n",
      "Female Owned <-->  Female\n",
      "Unanswered <-->  Unknown\n",
      "Male Owned <-->  Male\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Female Owned <-->  Female\n",
      "Unanswered <-->  Unknown\n",
      "Female Owned <-->  Female\n",
      "Female Owned <-->  Female\n",
      "Male Owned <-->  Male\n",
      "23100.0 <-!=->  23100.0\n",
      "12700.0 <-!=->  12700.0\n",
      "19000.0 <-!=->  19000.0\n",
      "29553.7 <-!=->  29553.7\n",
      "102865.0 <-!=->  102865.0\n",
      "907.0 <-!=->  907.0\n",
      "21500.0 <-!=->  21500.0\n",
      "3725.0 <-!=->  3725.0\n",
      "89554.0 <-!=->  89554.0\n",
      "12249.0 <-!=->  12249.0\n",
      "3241.92 <-!=->  3241.92\n",
      "12712.0 <-!=->  12712.0\n",
      "35000.0 <-!=->  35000.0\n",
      "12347.0 <-!=->  12347.0\n",
      "5502.26 <-!=->  5502.26\n",
      "34600.0 <-!=->  34600.0\n",
      "7140.83 <-!=->  7140.83\n",
      "5437.0 <-!=->  5437.0\n",
      "70557.0 <-!=->  70557.0\n",
      "20800.0 <-!=->  20800.0\n",
      "Male Owned <-->  Male\n",
      "Male Owned <-->  Male\n",
      "Female Owned <-->  Female\n",
      "Male Owned <-->  Male\n",
      "Female Owned <-->  Female\n",
      "Female Owned <-->  Female\n",
      "Female Owned <-->  Female\n",
      "Male Owned <-->  Male\n",
      "23100.0 <-!=->  23100.0\n",
      "12700.0 <-!=->  12700.0\n",
      "19000.0 <-!=->  19000.0\n",
      "29553.7 <-!=->  29553.7\n",
      "102865.0 <-!=->  102865.0\n",
      "907.0 <-!=->  907.0\n",
      "21500.0 <-!=->  21500.0\n",
      "3725.0 <-!=->  3725.0\n",
      "89554.0 <-!=->  89554.0\n",
      "12249.0 <-!=->  12249.0\n",
      "3241.92 <-!=->  3241.92\n",
      "12712.0 <-!=->  12712.0\n",
      "35000.0 <-!=->  35000.0\n",
      "12347.0 <-!=->  12347.0\n",
      "5502.26 <-!=->  5502.26\n",
      "34600.0 <-!=->  34600.0\n",
      "7140.83 <-!=->  7140.83\n",
      "5437.0 <-!=->  5437.0\n",
      "70557.0 <-!=->  70557.0\n",
      "20800.0 <-!=->  20800.0\n",
      "KAILUA <-->  kailua kona\n",
      "123300.0 <-!=->  123300.0\n",
      "85000.0 <-!=->  85000.0\n",
      "7400.0 <-!=->  7400.0\n",
      "20800.0 <-!=->  20800.0\n",
      "24779.0 <-!=->  24779.0\n",
      "52300.0 <-!=->  52300.0\n",
      "2099.31 <-!=->  2099.31\n",
      "39800.0 <-!=->  39800.0\n",
      "57832.0 <-!=->  57832.0\n",
      "6357.0 <-!=->  6357.0\n",
      "79582.0 <-!=->  79582.0\n",
      "20800.0 <-!=->  20800.0\n",
      "20800.0 <-!=->  20800.0\n",
      "29200.0 <-!=->  29200.0\n",
      "15000.0 <-!=->  15000.0\n",
      "44173.07 <-!=->  44173.07\n",
      "29078.0 <-!=->  29078.0\n",
      "27500.0 <-!=->  27500.0\n",
      "8800.0 <-!=->  8800.0\n",
      "11041.0 <-!=->  11041.0\n",
      "KAILUA <-->  Kailua-Kona\n",
      "123300.0 <-!=->  123300.0\n",
      "85000.0 <-!=->  85000.0\n",
      "7400.0 <-!=->  7400.0\n",
      "20800.0 <-!=->  20800.0\n",
      "24779.0 <-!=->  24779.0\n",
      "52300.0 <-!=->  52300.0\n",
      "2099.31 <-!=->  2099.31\n",
      "39800.0 <-!=->  39800.0\n",
      "57832.0 <-!=->  57832.0\n",
      "6357.0 <-!=->  6357.0\n",
      "79582.0 <-!=->  79582.0\n",
      "20800.0 <-!=->  20800.0\n",
      "20800.0 <-!=->  20800.0\n",
      "29200.0 <-!=->  29200.0\n",
      "15000.0 <-!=->  15000.0\n",
      "44173.07 <-!=->  44173.07\n",
      "29078.0 <-!=->  29078.0\n",
      "27500.0 <-!=->  27500.0\n",
      "8800.0 <-!=->  8800.0\n",
      "11041.0 <-!=->  11041.0\n",
      "96821 <-!=->  96821\n",
      "96701 <-!=->  96701\n",
      "96749 <-!=->  96749\n",
      "96817 <-!=->  96817\n",
      "96707 <-!=->  96707\n",
      "96708 <-!=->  96708\n",
      "96814 <-!=->  96814\n",
      "96825 <-!=->  96825\n",
      "96791 <-!=->  96791\n",
      "96815 <-!=->  96815\n",
      "96816 <-!=->  96816\n",
      "96813 <-!=->  96813\n",
      "96704 <-!=->  96704\n",
      "96750 <-!=->  96750\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96754 <-!=->  96754\n",
      "96826 <-!=->  96826\n",
      "96816 <-!=->  96816\n",
      "4300 <-!=->  4300.0\n",
      "5000 <-!=->  5000.0\n",
      "6400 <-!=->  6400.0\n",
      "30000 <-!=->  30000.0\n",
      "4122 <-!=->  4122.0\n",
      "23615 <-!=->  23615.0\n",
      "11631 <-!=->  11631.0\n",
      "7500 <-!=->  7500.0\n",
      "32500 <-!=->  32500.0\n",
      "20000 <-!=->  20000.0\n",
      "20000 <-!=->  20000.0\n",
      "3300 <-!=->  3300.0\n",
      "15700 <-!=->  15700.0\n",
      "15636 <-!=->  15636.0\n",
      "5150 <-!=->  5150.0\n",
      "44000 <-!=->  44000.0\n",
      "73600 <-!=->  73600.0\n",
      "27400 <-!=->  27400.0\n",
      "40000 <-!=->  40000.0\n",
      "96100 <-!=->  96100.0\n",
      "96821 <-!=->  96821\n",
      "96701 <-!=->  96701\n",
      "96749 <-!=->  96749\n",
      "96817 <-!=->  96817\n",
      "96707 <-!=->  96707\n",
      "96708 <-!=->  96708\n",
      "96814 <-!=->  96814\n",
      "96825 <-!=->  96825\n",
      "96791 <-!=->  96791\n",
      "96815 <-!=->  96815\n",
      "96816 <-!=->  96816\n",
      "96813 <-!=->  96813\n",
      "96704 <-!=->  96704\n",
      "96750 <-!=->  96750\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96707 <-!=->  96707\n",
      "96754 <-!=->  96754\n",
      "96826 <-!=->  96826\n",
      "96816 <-!=->  96816\n",
      "4300 <-!=->  4300.0\n",
      "5000 <-!=->  5000.0\n",
      "6400 <-!=->  6400.0\n",
      "30000 <-!=->  30000.0\n",
      "4122 <-!=->  4122.0\n",
      "23615 <-!=->  23615.0\n",
      "11631 <-!=->  11631.0\n",
      "7500 <-!=->  7500.0\n",
      "32500 <-!=->  32500.0\n",
      "20000 <-!=->  20000.0\n",
      "20000 <-!=->  20000.0\n",
      "3300 <-!=->  3300.0\n",
      "15700 <-!=->  15700.0\n",
      "15636 <-!=->  15636.0\n",
      "5150 <-!=->  5150.0\n",
      "44000 <-!=->  44000.0\n",
      "73600 <-!=->  73600.0\n",
      "27400 <-!=->  27400.0\n",
      "40000 <-!=->  40000.0\n",
      "96100 <-!=->  96100.0\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "Unanswered <-->  Unknown\n",
      "102000.0 <-!=->  102000.0\n",
      "18525.0 <-!=->  18525.0\n",
      "20900.0 <-!=->  20900.0\n",
      "3241.92 <-!=->  3241.92\n",
      "17200.0 <-!=->  17200.0\n",
      "6700.0 <-!=->  6700.0\n",
      "2281.0 <-!=->  2281.0\n",
      "109100.0 <-!=->  109100.0\n",
      "39200.0 <-!=->  39200.0\n",
      "13700.0 <-!=->  13700.0\n",
      "28800.0 <-!=->  28800.0\n",
      "10000.0 <-!=->  10000.0\n",
      "1400.0 <-!=->  1400.0\n",
      "9500.0 <-!=->  9500.0\n",
      "2500.0 <-!=->  2500.0\n",
      "23501.0 <-!=->  23501.0\n",
      "8600.0 <-!=->  8600.0\n",
      "7377.5 <-!=->  7377.5\n",
      "57600.0 <-!=->  57600.0\n",
      "4535.0 <-!=->  4535.0\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "Unanswered <-->  Not Specified\n",
      "102000.0 <-!=->  102000.0\n",
      "18525.0 <-!=->  18525.0\n",
      "20900.0 <-!=->  20900.0\n",
      "3241.92 <-!=->  3241.92\n",
      "17200.0 <-!=->  17200.0\n",
      "6700.0 <-!=->  6700.0\n",
      "2281.0 <-!=->  2281.0\n",
      "109100.0 <-!=->  109100.0\n",
      "39200.0 <-!=->  39200.0\n",
      "13700.0 <-!=->  13700.0\n",
      "28800.0 <-!=->  28800.0\n",
      "10000.0 <-!=->  10000.0\n",
      "1400.0 <-!=->  1400.0\n",
      "9500.0 <-!=->  9500.0\n",
      "2500.0 <-!=->  2500.0\n",
      "23501.0 <-!=->  23501.0\n",
      "8600.0 <-!=->  8600.0\n",
      "7377.5 <-!=->  7377.5\n",
      "57600.0 <-!=->  57600.0\n",
      "4535.0 <-!=->  4535.0\n",
      "123300.0 <-!=->  123300.0\n",
      "85000.0 <-!=->  85000.0\n",
      "7400.0 <-!=->  7400.0\n",
      "20800.0 <-!=->  20800.0\n",
      "24779.0 <-!=->  24779.0\n",
      "52300.0 <-!=->  52300.0\n",
      "2099.31 <-!=->  2099.31\n",
      "39800.0 <-!=->  39800.0\n",
      "57832.0 <-!=->  57832.0\n",
      "6357.0 <-!=->  6357.0\n",
      "79582.0 <-!=->  79582.0\n",
      "20800.0 <-!=->  20800.0\n",
      "20800.0 <-!=->  20800.0\n",
      "29200.0 <-!=->  29200.0\n",
      "15000.0 <-!=->  15000.0\n",
      "44173.07 <-!=->  44173.07\n",
      "29078.0 <-!=->  29078.0\n",
      "27500.0 <-!=->  27500.0\n",
      "8800.0 <-!=->  8800.0\n",
      "11041.0 <-!=->  11041.0\n",
      "8.0 <-!=->  8.0\n",
      "1.0 <-!=->  1.0\n",
      "1.0 <-!=->  1.0\n",
      "7.0 <-!=->  7.0\n",
      "0.0 <-!=->  0.0\n",
      "4.0 <-!=->  4.0\n",
      "7.0 <-!=->  7.0\n",
      "1.0 <-!=->  1.0\n",
      "15.0 <-!=->  15.0\n",
      "1.0 <-!=->  1.0\n",
      "1.0 <-!=->  1.0\n",
      "5.0 <-!=->  5.0\n",
      "3.0 <-!=->  3.0\n",
      "0.0 <-!=->  0.0\n",
      "4.0 <-!=->  4.0\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "9.0 <-!=->  9.0\n",
      "KAILUA <-->  KAILUA-KONA\n",
      "123300.0 <-!=->  123300.0\n",
      "85000.0 <-!=->  85000.0\n",
      "7400.0 <-!=->  7400.0\n",
      "20800.0 <-!=->  20800.0\n",
      "24779.0 <-!=->  24779.0\n",
      "52300.0 <-!=->  52300.0\n",
      "2099.31 <-!=->  2099.31\n",
      "39800.0 <-!=->  39800.0\n",
      "57832.0 <-!=->  57832.0\n",
      "6357.0 <-!=->  6357.0\n",
      "79582.0 <-!=->  79582.0\n",
      "20800.0 <-!=->  20800.0\n",
      "20800.0 <-!=->  20800.0\n",
      "29200.0 <-!=->  29200.0\n",
      "15000.0 <-!=->  15000.0\n",
      "44173.07 <-!=->  44173.07\n",
      "29078.0 <-!=->  29078.0\n",
      "27500.0 <-!=->  27500.0\n",
      "8800.0 <-!=->  8800.0\n",
      "11041.0 <-!=->  11041.0\n",
      "96744 <-!=->  96744\n",
      "96814 <-!=->  96814\n",
      "96701 <-!=->  96701\n",
      "96825 <-!=->  96825\n",
      "96822 <-!=->  96822\n",
      "96741 <-!=->  96741\n",
      "96825 <-!=->  96825\n",
      "96741 <-!=->  96741\n",
      "96725 <-!=->  96725\n",
      "96816 <-!=->  96816\n",
      "96815 <-!=->  96815\n",
      "96734 <-!=->  96734\n",
      "96815 <-!=->  96815\n",
      "96816 <-!=->  96816\n",
      "96720 <-!=->  96720\n",
      "96740 <-!=->  96740\n",
      "96725 <-!=->  96725\n",
      "96766 <-!=->  96766\n",
      "96746 <-!=->  96746\n",
      "96818 <-!=->  96818\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "11 <-!=->  11\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "103 <-!=->  103\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "138 <-!=->  138\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "16 <-!=->  16\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "BEEF PEPPER STEAK SERVED WITH VEGETABLE, SALAD, ROLL, AND CHOICE OF POTATO OR RICE <-->  BEEF PEPPER STEAK.  Served with vegetable salad roll and choice of potato or rice\n",
      "CORNED BEEFON RUSSIAN RYE BREAD <-->  Corned Beef...On Russian Rye Bread\n",
      "STEAMED CLAMS, DRAWN BUTTER, PICKLED CABBAGE, SALTINES, CLAM BROTH <-->  Steamed Clams Drawn Butter Pickled Cabbage Saltines Clam Broth\n",
      "BROILED SWORDFISH STEAK FLORIDA, FRENCH FRIED POTATOES <-->  BROILED SWORDFISH STEAK FLORIDA French Fried Potatoes\n",
      "ROAST HOT HOUSE BABY LAMB, MINT SAUCE <-->  Roast Hot House Baby Lamb Mint Sauce\n",
      "BOILED FRESH BRISKET OF BEEF, HORSERADISH SAUCE, BOUILLON POTATOES <-->  Boiled Fresh Brisket of Beef Horseradish Sauce Bouillon Potatoes\n",
      "SALAD, BRAZILIENNE <-->  Salad Brazilienne\n",
      "RINDERZUNGE ROASTBEEF <-->  Rinderzunge  Roastbeef\n",
      "SARDINE, WHOLE <-->  Sardine Whole\n",
      "COFFEE ICE CREAM, CARAMEL SAUCE <-->  Coffee Ice Cream caramel sauce\n",
      "BAKED-STUFFED MT TROUT FROM THE COLD GLACIER WATERS OF COLORADO <-->  Baked-STuffed Mt. Trout From the Cold Glacier Waters of Colorado\n",
      "FRESH SELECT FISH, DU JOUR <-->  Fresh Select fish du Jour\n",
      "REUBEN'S SPECIAL TURKEY, ROAST VIRGINIA HAM, SWISS CHEESE, COLE SLAW, RUSSIAN DRESSING <-->  REUBEN'S SPECIAL Turkey Roast Virginia Ham Swiss Cheese Cole Slaw Russian Dressing\n",
      "CIGARS, MANUEL GARCIA, INVENCIBLE <-->  Cigars Manuel Garcia Invencible\n",
      "CANARD MALLARD, ROTI, <-->  Canard Mallard roti\n",
      "LOBSTER, FULL ORDER <-->  lobster full order\n",
      "ORANGE YOU GLAD? YOU WILL BE WHEN YOU TASTE THIS SPECIAL BLEND OF MANDARIN ORANGE SHERBET, ORANGE JUICE AND GINGER <-->  ORANGE YOU GLAD? You will be when you taste this special blend of mandarin orange sherbet orange juice and ginger.\n",
      "LE GATEAU MAISON (RUM CAKE) <-->  le gateau maison                (rum cake)\n",
      "SADDLE OF BABY LAMB SARDALAISE, JELLY OR MINT SAUCE <-->  SADDLE OF BABY LAMB SARDALAISE JELLY OR MINT SAUCE\n",
      "OYSTERS HALF SHELL, CAPE CODS <-->  Oysters Half Shell Cape Cods\n",
      "SAVENNIERES, CHATEAU DE CHAMBOUREAU <-->  SAVENNIERES Chateau de Chamboureau\n",
      "CANVAS BACK DUCK, WITH FRIED HOMINY <-->  Canvas Back Duck with Fried Hominy\n",
      "HEARTS OF LETTUCE, FRENCH DRESSING <-->  Hearts of Lettuce French Dressing\n",
      "BAKED FRESH MACKEREL, CREOLE <-->  Baked Fresh Mackerel Creole\n",
      "SLOE GIN FIZZ, IMP <-->  Sloe Gin Fizz Imp.\n",
      "COUNTRY SAUSAGES, FRIED EGG AND BROILED BACON <-->  Country sausages fried egg and broiled bacon\n",
      "1955 <-!=->  1955\n",
      "1988 <-!=->  1988\n",
      "1901 <-!=->  1901\n",
      "1965 <-!=->  1965\n",
      "1941 <-!=->  1941\n",
      "1905 <-!=->  1905\n",
      "1948 <-!=->  1948\n",
      "1985 <-!=->  1985\n",
      "1918 <-!=->  1918\n",
      "1953 <-!=->  1953\n",
      "1907 <-!=->  1907\n",
      "1899 <-!=->  1899\n",
      "1919 <-!=->  1919\n",
      "1933 <-!=->  1933\n",
      "1969 <-!=->  1969\n",
      "1944 <-!=->  1944\n",
      "1943 <-!=->  1943\n",
      "1969 <-!=->  1969\n",
      "1900 <-!=->  1900\n",
      "0 <-!=->  0\n",
      "1913 <-!=->  1913\n",
      "0 <-!=->  0\n",
      "1901 <-!=->  1901\n",
      "1916 <-!=->  1916\n",
      "1913 <-!=->  1913\n",
      "1912 <-!=->  1912\n",
      "1958 <-!=->  1958\n",
      "1944 <-!=->  1944\n",
      "1987 <-!=->  1987\n",
      "0 <-!=->  0\n",
      "0 <-!=->  0\n",
      "1937 <-!=->  1937\n",
      "1957 <-!=->  1957\n",
      "1973 <-!=->  1973\n",
      "1917 <-!=->  1917\n",
      "1938 <-!=->  1938\n",
      "1900 <-!=->  1900\n",
      "1913 <-!=->  1913\n",
      "1905 <-!=->  1905\n",
      "1969 <-!=->  1969\n",
      "1937 <-!=->  1937\n",
      "1900 <-!=->  1900\n",
      "1966 <-!=->  1966\n",
      "1907 <-!=->  1907\n",
      "1947 <-!=->  1947\n",
      "1917 <-!=->  1917\n",
      "1900 <-!=->  1900\n",
      "1935 <-!=->  1935\n",
      "1913 <-!=->  1913\n",
      "1939 <-!=->  1939\n",
      "1961 <-!=->  1961\n",
      "1988 <-!=->  1988\n",
      "1901 <-!=->  1901\n",
      "1965 <-!=->  1965\n",
      "1941 <-!=->  1941\n",
      "1905 <-!=->  1905\n",
      "1948 <-!=->  1948\n",
      "1985 <-!=->  1985\n",
      "1918 <-!=->  1918\n",
      "1953 <-!=->  1953\n",
      "1907 <-!=->  1907\n",
      "1899 <-!=->  1899\n",
      "1919 <-!=->  1919\n",
      "1933 <-!=->  1933\n",
      "1969 <-!=->  1969\n",
      "1944 <-!=->  1944\n",
      "1946 <-!=->  1946\n",
      "1969 <-!=->  1969\n",
      "1917 <-!=->  1917\n",
      "0 <-!=->  0\n",
      "1913 <-!=->  1913\n",
      "0 <-!=->  0\n",
      "1901 <-!=->  1901\n",
      "1916 <-!=->  1916\n",
      "1913 <-!=->  1913\n",
      "1912 <-!=->  1912\n",
      "1958 <-!=->  1958\n",
      "1944 <-!=->  1944\n",
      "1987 <-!=->  1987\n",
      "0 <-!=->  0\n",
      "0 <-!=->  0\n",
      "1948 <-!=->  1948\n",
      "1957 <-!=->  1957\n",
      "1973 <-!=->  1973\n",
      "1918 <-!=->  1918\n",
      "1938 <-!=->  1938\n",
      "1900 <-!=->  1900\n",
      "1964 <-!=->  1964\n",
      "1905 <-!=->  1905\n",
      "1969 <-!=->  1969\n",
      "1937 <-!=->  1937\n",
      "1901 <-!=->  1901\n",
      "1966 <-!=->  1966\n",
      "1921 <-!=->  1921\n",
      "1947 <-!=->  1947\n",
      "1917 <-!=->  1917\n",
      "1900 <-!=->  1900\n",
      "1935 <-!=->  1935\n",
      "1913 <-!=->  1913\n",
      "1948 <-!=->  1948\n",
      "BEEF PEPPER STEAK SERVED WITH VEGETABLE, SALAD, ROLL, AND CHOICE OF POTATO OR RICE <-->  BEEF PEPPER STEAK  SERVED WITH VEGETABLE, SALAD, ROLL, AND CHOICE OF POTATO OR RICE\n",
      "RINDERZUNGE ROASTBEEF <-->  RINDERZUNGE  ROASTBEEF\n",
      "LE GATEAU MAISON (RUM CAKE) <-->  LE GATEAU MAISON                (RUM CAKE)\n",
      "1955 <-!=->  1955\n",
      "1988 <-!=->  1988\n",
      "1901 <-!=->  1901\n",
      "1965 <-!=->  1965\n",
      "1941 <-!=->  1941\n",
      "1905 <-!=->  1905\n",
      "1948 <-!=->  1948\n",
      "1985 <-!=->  1985\n",
      "1918 <-!=->  1918\n",
      "1953 <-!=->  1953\n",
      "1907 <-!=->  1907\n",
      "1899 <-!=->  1899\n",
      "1919 <-!=->  1919\n",
      "1933 <-!=->  1933\n",
      "1969 <-!=->  1969\n",
      "1944 <-!=->  1944\n",
      "1943 <-!=->  1943\n",
      "1969 <-!=->  1969\n",
      "1900 <-!=->  1900\n",
      "0 <-!=->  0\n",
      "1913 <-!=->  1913\n",
      "0 <-!=->  0\n",
      "1901 <-!=->  1901\n",
      "1916 <-!=->  1916\n",
      "1913 <-!=->  1913\n",
      "1912 <-!=->  1912\n",
      "1958 <-!=->  1958\n",
      "1944 <-!=->  1944\n",
      "1987 <-!=->  1987\n",
      "0 <-!=->  0\n",
      "0 <-!=->  0\n",
      "1937 <-!=->  1937\n",
      "1957 <-!=->  1957\n",
      "1973 <-!=->  1973\n",
      "1917 <-!=->  1917\n",
      "1938 <-!=->  1938\n",
      "1900 <-!=->  1900\n",
      "1913 <-!=->  1913\n",
      "1905 <-!=->  1905\n",
      "1969 <-!=->  1969\n",
      "1937 <-!=->  1937\n",
      "1900 <-!=->  1900\n",
      "1966 <-!=->  1966\n",
      "1907 <-!=->  1907\n",
      "1947 <-!=->  1947\n",
      "1917 <-!=->  1917\n",
      "1900 <-!=->  1900\n",
      "1935 <-!=->  1935\n",
      "1913 <-!=->  1913\n",
      "1939 <-!=->  1939\n",
      "1961 <-!=->  1961\n",
      "1988 <-!=->  1988\n",
      "1901 <-!=->  1901\n",
      "1965 <-!=->  1965\n",
      "1941 <-!=->  1941\n",
      "1905 <-!=->  1905\n",
      "1948 <-!=->  1948\n",
      "1985 <-!=->  1985\n",
      "1918 <-!=->  1918\n",
      "1953 <-!=->  1953\n",
      "1907 <-!=->  1907\n",
      "1899 <-!=->  1899\n",
      "1919 <-!=->  1919\n",
      "1933 <-!=->  1933\n",
      "1969 <-!=->  1969\n",
      "1944 <-!=->  1944\n",
      "1946 <-!=->  1946\n",
      "1969 <-!=->  1969\n",
      "1917 <-!=->  1917\n",
      "0 <-!=->  0\n",
      "1913 <-!=->  1913\n",
      "0 <-!=->  0\n",
      "1901 <-!=->  1901\n",
      "1916 <-!=->  1916\n",
      "1913 <-!=->  1913\n",
      "1912 <-!=->  1912\n",
      "1958 <-!=->  1958\n",
      "1944 <-!=->  1944\n",
      "1987 <-!=->  1987\n",
      "0 <-!=->  0\n",
      "0 <-!=->  0\n",
      "1948 <-!=->  1948\n",
      "1957 <-!=->  1957\n",
      "1973 <-!=->  1973\n",
      "1918 <-!=->  1918\n",
      "1938 <-!=->  1938\n",
      "1900 <-!=->  1900\n",
      "1964 <-!=->  1964\n",
      "1905 <-!=->  1905\n",
      "1969 <-!=->  1969\n",
      "1937 <-!=->  1937\n",
      "1901 <-!=->  1901\n",
      "1966 <-!=->  1966\n",
      "1921 <-!=->  1921\n",
      "1947 <-!=->  1947\n",
      "1917 <-!=->  1917\n",
      "1900 <-!=->  1900\n",
      "1935 <-!=->  1935\n",
      "1913 <-!=->  1913\n",
      "1948 <-!=->  1948\n",
      "CHATEAUNEUF DU PAPE 1933 <-->  CHATEAUNEUF DU PAPE [1933]\n",
      "MACEDOINE DE FRUITS AU MARASQUIN <-->  FRUIT SALAD\n",
      "FRESH FRUIT COCKTAIL EIRE STYLE <-->  FRUIT COCKTAIL\n",
      "PEA PODS WITH WATER CHESNUTS AND PORK <-->  PEA PODS WITH PORK\n",
      "SANTA CLARA CABERNET <-->  CABERNET\n",
      "BROILED CALF'S LIVER WITH BACON OR ONIONS, MASHED POTATOES <-->  BROILED CALF'S LIVER\n",
      "BACON WITH EGGS <-->  BACON AND EGGS\n",
      "GRAVAD STROMMING MAYONAISE? <-->  GRAVLAX WITH MAYONNAISE\n",
      "BRANDY (DOMESTIC) <-->  BRANDY\n",
      "GALANTINE DE VOLAILLE EN BELLE-VUE <-->  GALANTINE  DE VOLAILLE EN BELLE-VUE\n",
      "CONCH STEW WITH PEAS & RICE, COLESLAW, POTATO SALAD, VEGETABLES OR BAKE POTATO <-->  CONCH STEW\n",
      "HNSEKOD, ASPARGES, CHAMPIGNONS, AGURK I MAYONNAISE <-->  CHICKEN SALAD\n",
      "SAUMON BOUILLI <-->  SAUMON BOUILLI.\n",
      "SLOE GIN FIZZ, IMP <-->  SLOE GIN FIZZ, IMP.\n",
      "FRIED RICE WITH PORK <-->  FRIED RICE\n",
      "HOMINY FRITTERS CURRANT SAUCE <-->  HOMINY FRITTERS\n",
      "STRAWBERRY, PEACH OR RASPBERRY JAM <-->  JAM\n",
      "SURPRISE OF FRUIT <-->  FRUIT SURPRISE\n",
      "BROILED LAMP CHOPS, TWO <-->  BROILED LAMB CHOPS\n",
      "NEW-LAID EGGS <-->  EGGS\n",
      "COFFEE SUNDAE() <-->  COFFEE SUNDAE(;)\n",
      "BROILED OR FRIED GREEN BLUEFISH <-->  BROILED OR FRIED BLUEFISH\n",
      "BAYERISCHE CREME <-->  BAVARIAN CREAM\n",
      "BACON WITH EGGS <-->  BACON AND EGGS\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.38 <-!=->  0.38\n",
      "0.0 <-!=->  0.0\n",
      "15.0 <-!=->  15.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.75 <-!=->  0.75\n",
      "0.0 <-!=->  0.0\n",
      "3.95 <-!=->  3.95\n",
      "0.0 <-!=->  0.0\n",
      "0.95 <-!=->  0.95\n",
      "0.0 <-!=->  0.0\n",
      "0.7 <-!=->  0.7\n",
      "0.15 <-!=->  0.15\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.1 <-!=->  0.1\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.45 <-!=->  0.45\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.75 <-!=->  2.75\n",
      "1910.0 <-!=->  1910.0\n",
      "1948.0 <-!=->  1948.0\n",
      "0.0 <-!=->  0.0\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "1933.0 <-!=->  1933.0\n",
      "1939.0 <-!=->  1939.0\n",
      "FRIED 3 OYSTERS <-->  FRIED  OYSTERS\n",
      "OX-TONGUE MIKADO <-->  MIKADO\n",
      "SALADE DE BETTERAVE <-->  BEET SALAD\n",
      "CHATEAUNEUF DU PAPE 1933 <-->  CHATEAUNEUF DU PAPE\n",
      "FRESH FRUIT COCKTAIL EIRE STYLE <-->  FRUIT COCKTAIL\n",
      "BROILED CALF'S LIVER WITH BACON OR ONIONS, MASHED POTATOES <-->  BROILED CALFS LIVER WITH BACON OR ONIONS MASHED POTATOES\n",
      "BACON WITH EGGS <-->  BACON AND EGGS\n",
      "GRAVAD STROMMING MAYONAISE? <-->  GRAVAD STROMMING MAYONAISE\n",
      "GALANTINE DE VOLAILLE EN BELLE-VUE <-->  GALANTINE\n",
      "CONCH STEW WITH PEAS & RICE, COLESLAW, POTATO SALAD, VEGETABLES OR BAKE POTATO <-->  CONCH STEW WITH PEAS  RICE COLESLAW POTATO SALAD VEGETABLES OR BAKE POTATO\n",
      "HNSEKOD, ASPARGES, CHAMPIGNONS, AGURK I MAYONNAISE <-->  HNSEKOD ASPARGES CHAMPIGNONS AGURK I MAYONNAISE\n",
      "SLOE GIN FIZZ, IMP <-->  SLOE GIN FIZZ\n",
      "MADRE <-->  MADEIRA\n",
      "POTATOES OR POT CHEESE WITH SOUR CREAM <-->  POTATOES\n",
      "KEY WEST TURTLE SOUP <-->  TURTLE SOUP\n",
      "LOBSTER, FULL ORDER <-->  LOBSTER\n",
      "ZITI WITH CALABRESE SAUCE <-->  ZITI\n",
      "GEBACKENE EIER \"AMERICAINE\" MIT GEGRILLTEM SPECK <-->  GEBACKENE EIER AMERICAINE MIT GEGRILLTEM SPECK\n",
      "HOMINY FRITTERS CURRANT SAUCE <-->  HOMINY FRITTERS\n",
      "STRAWBERRY, PEACH OR RASPBERRY JAM <-->  JAM\n",
      "GRAPE FRUIT YOGHURT-MISCHGETRANKE <-->  GRAPE FRUIT YOGHURTMISCHGETRANKE\n",
      "HAMBURGER ROAST TOMATO SAUCE <-->  HAMBURGER\n",
      "VINTAGE PORT MARTINEZ 1963 <-->  MARTINEZ\n",
      "CALF'S BRAINS FRIED, TOMATO SAUCE <-->  CALFS BRAINS\n",
      "SURPRISE OF FRUIT <-->  FRUIT SURPRISE\n",
      "REUBEN'S SPECIAL TURKEY, ROAST VIRGINIA HAM, SWISS CHEESE, COLE SLAW, RUSSIAN DRESSING <-->  REUBEN SPECIAL\n",
      "BROILED LAMP CHOPS, TWO <-->  BROILED LAMB CHOPS\n",
      "NEW-LAID EGGS <-->  NEWLAID EGGS\n",
      "BROILED OR FRIED GREEN BLUEFISH <-->  BROILED   OR FRIED GREEN BLUEFISH\n",
      "SOLE GRILLEE BEURRE MAITRE-D HOTEL <-->  SOLE GRILLEE BEURRE MAITRED HOTEL\n",
      "HOLLANDAISE-SALAT <-->  HOLLANDAISE SALAD\n",
      "BAYERISCHE CREME <-->  BAVARIAN CREAM\n",
      "TOASTED ROLLS WITH WITH A SMALL PITCHER OF CREAM AND WITH BUTTER <-->  ROLLS\n",
      "COFFEE ICE CREAM, CARAMEL SAUCE <-->  COFFEE ICE CREAM CARAMEL SAUCE\n",
      "BACON WITH EGGS <-->  BACON AND EGGS\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.8 <-!=->  0.8\n",
      "0.0 <-!=->  0.0\n",
      "15.0 <-!=->  15.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.75 <-!=->  0.75\n",
      "0.0 <-!=->  0.0\n",
      "3.95 <-!=->  3.95\n",
      "0.0 <-!=->  0.0\n",
      "0.95 <-!=->  0.95\n",
      "0.0 <-!=->  0.0\n",
      "0.7 <-!=->  0.7\n",
      "0.15 <-!=->  0.15\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "1.5 <-!=->  1.5\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.45 <-!=->  0.45\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.75 <-!=->  2.75\n",
      "0.0 <-!=->  0.0\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "BRANDY, MARTEL XXX <-->  Not a Dish\n",
      "CREPE SUZETTE <-->  Not a Dish\n",
      "PAN ROAST, LITTLE NECKS <-->  Not a Dish\n",
      "MEXICAN TAMALES <-->  Not a Dish\n",
      "VEAL CUTLET BREADED, TOMATO <-->  Not a Dish\n",
      "LOBSTER SALAD, CHICKEN <-->  Not a Dish\n",
      "CRAB GUMBO, CREOLE <-->  Not a Dish\n",
      "BEEF STEAK, FRIED ONIONS <-->  Not a Dish\n",
      "KRUMBLES <-->  Not a Dish\n",
      "TRENETTE WITH TOMATO SAUCE <-->  Not a Dish\n",
      "SPARKLING BURGUNDY <-->  Not a Dish\n",
      "VERSCHIEDENE GEFULLTE EIER, GARNIERT, BUTTER UND BROT <-->  Not a Dish\n",
      "MIGNARDISES <-->  Not a Dish\n",
      "UFS CARLTON <-->  Not a Dish\n",
      "VEAL FILLETS WITH FRESH GRAPES IN MUSHROOM AND CREAM SAUCE (VITELLO 'WHITE ELEPHANT') <-->  Not a Dish\n",
      "1954ER PCKFENER BECKSTEIN <-->  Dish\n",
      "? AND COLD DISHES <-->  Not a Dish\n",
      "OYSTER OMELETTE WITH CREAMED POTATOES <-->  Not a Dish\n",
      "BROILED LOBSTER DAINTIES, DENMARK, DRAWN BUTTER, BROCCOLI, FRENCH FRIED POTATOES <-->  Not a Dish\n",
      "SCOTCH HIGHBALLS <-->  Not a Dish\n",
      "TWO BROILED PORK CHOPS * FF POTATO <-->  Not a Dish\n",
      "LITTLE NECK CLAMS, ROASTED IN SHELL <-->  Not a Dish\n",
      "LE COQ DE CHOIX A LA CREME ET AU FOIE GRAS, FLAMBE AU COGNAC <-->  Not a Dish\n",
      "SWEETBREAD, TZARINE <-->  Not a Dish\n",
      "GNOCCHI DI PATATE ALLA VENETA <-->  Not a Dish\n",
      "1964ER CHATEAU LA TOUR GAYET, COTES DE BLAYE AC <-->  Dish\n",
      "BAVAROIS AUX FRAMBOISES CHANTILLY <-->  Not a Dish\n",
      "JULIENUE <-->  Not a Dish\n",
      "SALADE DE BETTERAVE <-->  Not a Dish\n",
      "BROILED SMALL STEAK WITH POTATOES <-->  Not a Dish\n",
      "MONDAINE <-->  Not a Dish\n",
      "EGGS, SCRAMBLED WITH TOMATO <-->  Not a Dish\n",
      "SCHWESERPASTETEN <-->  Not a Dish\n",
      "COLD PICKLED PORK <-->  Not a Dish\n",
      "MANUEL GARCIA, PURITANOS <-->  Not a Dish\n",
      "FROGS' LEGS, AMERICAN STYLE <-->  Not a Dish\n",
      "TRIPE IN CREAM WITH ONIONS, SHANLEY <-->  Not a Dish\n",
      "BORDEAUX ROUGE SAUTERNES CLOS MERCIER 1966 <-->  Dish\n",
      "SLICE ROAST <-->  Not a Dish\n",
      "TOMATOES OR CUCUMBERS AND LETTUCE <-->  Not a Dish\n",
      "SLOE GIN FIZZ, IMP <-->  Not a Dish\n",
      "COFFEE SUNDAE <-->  Not a Dish\n",
      "BROILED LAMP CHOPS, TWO <-->  Not a Dish\n",
      "CHINESE MUSHROOMS AND PORK CHOW MEIN (PAN FRIED NOODLES, SOFT OR CRISP) <-->  Not a Dish\n",
      "MONKS BEARD SALAD <-->  Not a Dish\n",
      "CREAM FRESH TOMATOES SOUP? WITH TAPIOCA <-->  Not a Dish\n",
      "SOUP, PUREE JACKSON WITH LEEKS AND CELERY <-->  Not a Dish\n",
      "FR OCHSENBRUST \"FLAMISCH\" MIT BOUILLONKARTOFFELN UND SAHNEMEERRETTICH <-->  Not a Dish\n",
      "BOWL OF COLD RICE AND MILK <-->  Not a Dish\n",
      "GREEN GODDESS <-->  Not a Dish\n",
      "1892 <-!=->  1892\n",
      "1931 <-!=->  1931\n",
      "1900 <-!=->  1900\n",
      "1901 <-!=->  1901\n",
      "0 <-!=->  0\n",
      "1943 <-!=->  1943\n",
      "1914 <-!=->  1914\n",
      "1901 <-!=->  1901\n",
      "1921 <-!=->  1921\n",
      "1963 <-!=->  1963\n",
      "1913 <-!=->  1913\n",
      "1958 <-!=->  1958\n",
      "1905 <-!=->  1905\n",
      "1961 <-!=->  1961\n",
      "1972 <-!=->  1972\n",
      "0 <-!=->  0\n",
      "1901 <-!=->  1901\n",
      "1914 <-!=->  1914\n",
      "1962 <-!=->  1962\n",
      "1912 <-!=->  1912\n",
      "1961 <-!=->  1961\n",
      "1900 <-!=->  1900\n",
      "1944 <-!=->  1944\n",
      "1912 <-!=->  1912\n",
      "1980 <-!=->  1980\n",
      "0 <-!=->  0\n",
      "1966 <-!=->  1966\n",
      "1900 <-!=->  1900\n",
      "1962 <-!=->  1962\n",
      "0 <-!=->  0\n",
      "1914 <-!=->  1914\n",
      "0 <-!=->  0\n",
      "1891 <-!=->  1891\n",
      "1901 <-!=->  1901\n",
      "1900 <-!=->  1900\n",
      "0 <-!=->  0\n",
      "1900 <-!=->  1900\n",
      "1971 <-!=->  1971\n",
      "1935 <-!=->  1935\n",
      "1913 <-!=->  1913\n",
      "1947 <-!=->  1947\n",
      "1939 <-!=->  1939\n",
      "1957 <-!=->  1957\n",
      "0 <-!=->  0\n",
      "1916 <-!=->  1916\n",
      "1 <-!=->  1\n",
      "1927 <-!=->  1927\n",
      "1973 <-!=->  1973\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "BRANDY, MARTEL XXX <-->  BRANDY, MARTEL XXX:\n",
      "CREPE SUZETTE <-->  [CREPE SUZETTE]\n",
      "TRENETTE WITH TOMATO SAUCE <-->  TRENETTE   WITH TOMATO SAUCE\n",
      "? AND COLD DISHES <-->  ? AND COLD DISHES.\n",
      "BROILED LOBSTER DAINTIES, DENMARK, DRAWN BUTTER, BROCCOLI, FRENCH FRIED POTATOES <-->  BROILED LOBSTER DAINTIES, [DENMARK], DRAWN BUTTER, BROCCOLI, FRENCH FRIED POTATOES\n",
      "SCOTCH HIGHBALLS <-->  SCOTCH    HIGHBALLS\n",
      "1964ER CHATEAU LA TOUR GAYET, COTES DE BLAYE AC <-->  1964ER CHATEAU LA TOUR GAYET, COTES DE BLAYE A.C.\n",
      "COLD PICKLED PORK <-->  COLD: PICKLED PORK\n",
      "BORDEAUX ROUGE SAUTERNES CLOS MERCIER 1966 <-->  BORDEAUX ROUGE: SAUTERNES CLOS MERCIER 1966\n",
      "SLOE GIN FIZZ, IMP <-->  SLOE GIN FIZZ, IMP.\n",
      "MONKS BEARD SALAD <-->  MONKS BEARD [SALAD]\n",
      "CREAM FRESH TOMATOES SOUP? WITH TAPIOCA <-->  CREAM FRESH [TOMATOES SOUP]? WITH TAPIOCA\n",
      "BOWL OF COLD RICE AND MILK <-->  BOWL OF COLD RICE AND MILK;\n",
      "1892 <-!=->  1892\n",
      "1931 <-!=->  1931\n",
      "1900 <-!=->  1900\n",
      "1901 <-!=->  1901\n",
      "0 <-!=->  0\n",
      "1943 <-!=->  1943\n",
      "1914 <-!=->  1914\n",
      "1901 <-!=->  1901\n",
      "1921 <-!=->  1921\n",
      "1963 <-!=->  1963\n",
      "1913 <-!=->  1913\n",
      "1958 <-!=->  1958\n",
      "1905 <-!=->  1905\n",
      "1961 <-!=->  1961\n",
      "1972 <-!=->  1972\n",
      "0 <-!=->  0\n",
      "1901 <-!=->  1901\n",
      "1914 <-!=->  1914\n",
      "1962 <-!=->  1962\n",
      "1912 <-!=->  1912\n",
      "1961 <-!=->  1961\n",
      "1900 <-!=->  1900\n",
      "1944 <-!=->  1944\n",
      "1912 <-!=->  1912\n",
      "1980 <-!=->  1980\n",
      "0 <-!=->  0\n",
      "1966 <-!=->  1966\n",
      "1900 <-!=->  1900\n",
      "1962 <-!=->  1962\n",
      "0 <-!=->  0\n",
      "1914 <-!=->  1914\n",
      "0 <-!=->  0\n",
      "1891 <-!=->  1891\n",
      "1901 <-!=->  1901\n",
      "1900 <-!=->  1900\n",
      "0 <-!=->  0\n",
      "1900 <-!=->  1900\n",
      "1971 <-!=->  1971\n",
      "1935 <-!=->  1935\n",
      "1913 <-!=->  1913\n",
      "1947 <-!=->  1947\n",
      "1939 <-!=->  1939\n",
      "1957 <-!=->  1957\n",
      "0 <-!=->  0\n",
      "1916 <-!=->  1916\n",
      "1927 <-!=->  1927\n",
      "1973 <-!=->  1973\n",
      "0 <-!=->  0\n",
      "COFFEE ICE CREAM, CARAMEL SAUCE <-->  coffee Ice Cream caramel sauce\n",
      "\"HIS EYE BEGETS OCCASION FOR HIS WIT\" <-->  HIS EYE BEGETS OCCASION FOR HIS WIT\n",
      "CHICKEN FRICASSEE WITH BOILED RICE <-->  Chicken Fricassee\n",
      "BROILED FRESH POMPANO FILET IN LEMON BUTTER <-->  Broiled Pompano\n",
      "CH DILLON, N JOHNSTON <-->  Ch Dillon N Johnston\n",
      "SWEETBREAD, TZARINE <-->  Sweetbread Tzarine\n",
      "ROAST SPRING LAMB, MINT SAUCE (READY) <-->  Roast spring lamb mint sauce (ready)\n",
      "VEAL CUTLET BROILED, FRIED OR BREADED <-->  Veal Cutlet\n",
      "JOHANNISBERG CLAUSS '86 <-->  Johannisberg Clauss 86\n",
      "MADRE <-->  Madeira\n",
      "INDIVIDUAL WEDDING CAKES FOR EVERYBODY <-->  Wedding Cake\n",
      "SCHILDKROTENSUPPE ECHT, \"LACROIX\" <-->  Turtle Soup\n",
      "KONIGSBERGER KLOPS IN KAPERNSAUCE, ROTE BETE, KARTOFFELN <-->  Knigsberger Klopse\n",
      "BEEF PEPPER STEAK SERVED WITH VEGETABLE, SALAD, ROLL, AND CHOICE OF POTATO OR RICE <-->  Beef Pepper Steak\n",
      "TOMATOES OR CUCUMBERS AND LETTUCE <-->  Salad\n",
      "MEXICAN TAMALES <-->  Tamales\n",
      "EISBEIN MIT ERBSENBREI UND SAUERKOHL <-->  Eisbein with Pea Puree and Sauerkraut\n",
      "\"SOUTHER COLADA\" - SOUTHERN COMFORT, ANANASSAFT, KOKOSNUSSCREME <-->  Southern Comfort Cocktail\n",
      "BUTTER SERVED FREE WITH ORDERS AMOUNTING TO 40C <-->  Butter\n",
      "HOLLANDAISE-SALAT <-->  Hollandaise Salad\n",
      "SCOTCH, KING WILLIAM IV <-->  Scotch\n",
      "FRIED HAM AND ONE FRIED EGG <-->  Fried Ham and Eggs\n",
      "CHICKEN SAUTE CHASSEUR, WHITE WINE SAUCE, PARSLTY POTATO AND GREEN PEAS <-->  Chicken Saute Chasseur White Wine Sauce Parslty Potato and Green Peas\n",
      "OYSTER STEW, PLAIN <-->  Oyster stew plain\n",
      "ROAST TAME DUCK & JELLY <-->  Roast Duck\n",
      "NEW BEETS FINES HERBES <-->  Beets\n",
      "HOT WAGON SERVICE <-->  Hot Wagon\n",
      "COLD LOBSTER, MAYONNAISE SAUCE, HALF <-->  Cold Lobster\n",
      "OMELETTE \"KNIGIN-ART\" <-->  Omelette\n",
      "HOT + BUNS <-->  Hot Buns\n",
      "UNJOINTED FRIED HALF SPRING CHICKEN ON TOAST, COUNTRY GRAVY <-->  Fried Chicken\n",
      "EISCHAUM-NOCKEN <-->  Whipped Cream Dumplings\n",
      "SEA FOOD A LA MIRAMAR <-->  Seafood Miramar\n",
      "VEAL CUTLET BREADED, TOMATO <-->  Veal Cutlet Breaded Tomato\n",
      "VOL AU VENT OF CHICKEN, FRESH STRING BEANS, STRAW POTATOES, CHOICE OF SALAD OR DESSERT, COFFEE OR TEA <-->  Vol au Vent\n",
      "SAUMON GRILLE, BEURRE MAITRE D'HOTEL <-->  Saumon grille beurre Maitre dhotel\n",
      "WEHLENER ROSENBERG, 1907, 1/2 BOTTLE, BOTTLE <-->  Wehlener Rosenberg 1907 1/2 Bottle Bottle\n",
      "? LONDON BROIL ON TOAST, TOMATO SAUCE <-->  London Broil\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "6 <-!=->  6\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "8 <-!=->  8\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "25 <-!=->  25\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "5 <-!=->  5\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "\"HIS EYE BEGETS OCCASION FOR HIS WIT\" <-->  HIS EYE BEGETS OCCASION FOR HIS WIT.\n",
      "BROILED FRESH POMPANO FILET IN LEMON BUTTER <-->  Broiled Pompano\n",
      "SWEETBREAD, TZARINE <-->  Sweetbreads Tzarine\n",
      "ROAST SPRING LAMB, MINT SAUCE (READY) <-->  Roast Spring Lamb With Mint Sauce\n",
      "VEAL CUTLET BROILED, FRIED OR BREADED <-->  Veal Cutlet\n",
      "JOHANNISBERG CLAUSS '86 <-->  Johannisberg Wine\n",
      "MADRE <-->  Madeira\n",
      "TAVERNE ROSE PINK, BRUT <-->  Taverne Rose Pink Brut\n",
      "KONIGSBERGER KLOPS IN KAPERNSAUCE, ROTE BETE, KARTOFFELN <-->  Konigsberger Klops\n",
      "BEEF PEPPER STEAK SERVED WITH VEGETABLE, SALAD, ROLL, AND CHOICE OF POTATO OR RICE <-->  Beef Pepper Steak\n",
      "EISBEIN MIT ERBSENBREI UND SAUERKOHL <-->  Eisbein\n",
      "\"SOUTHER COLADA\" - SOUTHERN COMFORT, ANANASSAFT, KOKOSNUSSCREME <-->  Souther Colada - Southern comfort, Ananassaft, Kokosnucreme\n",
      "HOLLANDAISE-SALAT <-->  Hollandaise Salad\n",
      "SCOTCH, KING WILLIAM IV <-->  Scotch\n",
      "FRIED HAM AND ONE FRIED EGG <-->  Ham And Eggs\n",
      "CHICKEN SAUTE CHASSEUR, WHITE WINE SAUCE, PARSLTY POTATO AND GREEN PEAS <-->  Chicken Chasseur\n",
      "OYSTER STEW, PLAIN <-->  Oyster Stew\n",
      "ROAST TAME DUCK & JELLY <-->  Roast Tame Duck With Jelly\n",
      "COLD LOBSTER, MAYONNAISE SAUCE, HALF <-->  Lobster Salad\n",
      "FILET OF BEEF WITH MUSHROOMS <-->  Filet of Beef\n",
      "OMELETTE \"KNIGIN-ART\" <-->  Omelette Knigin Art\n",
      "HOT + BUNS <-->  [Hot + Buns]\n",
      "UNJOINTED FRIED HALF SPRING CHICKEN ON TOAST, COUNTRY GRAVY <-->  Fried Chicken\n",
      "SEA FOOD A LA MIRAMAR <-->  Sea Food a la Miramar.\n",
      "VEAL CUTLET BREADED, TOMATO <-->  Veal Cutlet\n",
      "VOL AU VENT OF CHICKEN, FRESH STRING BEANS, STRAW POTATOES, CHOICE OF SALAD OR DESSERT, COFFEE OR TEA <-->  Vol au Vent of Chicken\n",
      "? LONDON BROIL ON TOAST, TOMATO SAUCE <-->  London Broil\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "6 <-!=->  6\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "8 <-!=->  8\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "25 <-!=->  25\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "5 <-!=->  5\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "MIGNARDISES <-->  Mignardises Assortment\n",
      "SALADE MONEGASQUE <-->  Salad\n",
      "SHORE DINNER, LESS CRAB AND CHICKEN <-->  Seafood Platter\n",
      "FRIED (3) OYSTERS <-->  Oysters\n",
      "MCCALLUM'S PERFECT SCOTCH WHISKEY <-->  Whiskey\n",
      "VEAL BRAINS, AU BEURRE NOIR <-->  Veal Brains\n",
      "MONDAINE <-->  Mondaine Dish\n",
      "OLD NAVY SCOTCH WHISKEY <-->  Scotch Whiskey\n",
      "BEEF TAMALE <-->  Beef  Tamale\n",
      "TWO BROILED PORK CHOPS * FF POTATO <-->  Pork Chops\n",
      "FRIED CODFISH CAKES TOMATOE SCE <-->  Fish Cakes\n",
      "ICE CREAM - PAPPAGALLO'S SPECIALITY <-->  Ice Cream\n",
      "HOT OATMEAL AND CREAM <-->  Hot Oatmeal with Cream\n",
      "MACEDOINE DE FRUITS AU MARASQUIN <-->  Fruit Salad\n",
      "GREEN RIVER WHISKY <-->  Green River Whiskey\n",
      "FRECCIAROSSA <-->  Pasta\n",
      "HOT + BUNS <-->  Hot Dog\n",
      "SCHWEINSKOTELETTE VOM GRILL, POMMES FRITES UND TOMATENSALAT <-->  Grilled Pork Chop with French Fries and Tomato Salad\n",
      "ROOT BEER BLUE SKY SODA <-->  Soda\n",
      "VEAL CUTLET BREADED, TOMATO <-->  Breaded Veal Cutlet with Tomato\n",
      "PINOT GRIGIO, SANTA MARGHERITA <-->  Wine\n",
      "SHRIMP RICE CURRY <-->  Curry\n",
      "BISCUIT GLACE MCALPIN <-->  Cookie\n",
      "CONSUMME (LIQUIDE OR JELLY) OKRA <-->  Soup\n",
      "KARTOFFELN, GEBACKENE <-->  Potatoes\n",
      "SPARKLING BURGUNDY <-->  Sparkling Wine\n",
      "ASSORTED FRENCH CHEESE <-->  French Cheese Assortment\n",
      "BACON AND EGGS (BEECHNUT) <-->  bacon and Eggs (beechnut)[.]\n",
      "VEUVE CLICQOUT, GOLD LABEL, BRUT <-->  veuve Clicqout,   Gold Label, Brut\n",
      "103 <-!=->  103\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "8 <-!=->  8\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "5 <-!=->  5\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "5 <-!=->  5\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "17 <-!=->  17\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0.5 <-!=->  0.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.2 <-!=->  0.2\n",
      "0.65 <-!=->  0.65\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "9.25 <-!=->  9.25\n",
      "0.75 <-!=->  0.75\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.5 <-!=->  0.5\n",
      "0.0 <-!=->  0.0\n",
      "2.5 <-!=->  2.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.5 <-!=->  0.5\n",
      "0.5 <-!=->  0.5\n",
      "0.4 <-!=->  0.4\n",
      "0.0 <-!=->  0.0\n",
      "0.5 <-!=->  0.5\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.15 <-!=->  0.15\n",
      "0.0 <-!=->  0.0\n",
      "5.0 <-!=->  5.0\n",
      "1.5 <-!=->  1.5\n",
      "0.05 <-!=->  0.05\n",
      "0.0 <-!=->  0.0\n",
      "1.0 <-!=->  1.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "12.5 <-!=->  12.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "3.5 <-!=->  3.5\n",
      "1.0 <-!=->  1.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.35 <-!=->  0.35\n",
      "2.5 <-!=->  2.5\n",
      "3.75 <-!=->  3.75\n",
      "0.0 <-!=->  0.0\n",
      "FLANNEL CAKES WITH GENUINE MAPLE SYRUP <-->  Flannel Cakes\n",
      "BOWL OF COLD RICE AND MILK <-->  Dish\n",
      "BOILED SMOKED (OX-TONGUE) <-->  Dish\n",
      "TOMME DE SAVOIE CHEESE <-->  Dish\n",
      "LOIN LAMB CHOP, BRUSSELS SPROUTS (15 MIN) <-->  Loin lamb chop, Brussels sprouts (15 min.)\n",
      "SLICED LONDON BROIL AU JUS <-->  Dish\n",
      "BACON WITH EGGS <-->  Dish\n",
      "ARTICHAUTS A LA RUSSE <-->  Dish\n",
      "FRIED FILET OF ENGLISH SOLE, SAUCE VERTE, JULIENNE POTATOES <-->  Fried Sole\n",
      "TOMATO, STUFFED A LA MEYER (1) <-->  Dish\n",
      "VERMOUTH NOILLY PRAT OU TURIN <-->  Dish\n",
      "BAKED FRESH MACKEREL, CREOLE <-->  Baked Fresh Mackerel\n",
      "BAKED-STUFFED MT TROUT FROM THE COLD GLACIER WATERS OF COLORADO <-->  [Baked-STuffed] Mt. Trout; From the Cold Glacier Waters of Colorado\n",
      "CANADA MUTTON CHOP <-->  Mutton Chop\n",
      "CIGARS, MANUEL GARCIA, INVENCIBLE <-->  Dish\n",
      "STRAWBERRY, PEACH OR RASPBERRY JAM <-->  Dish\n",
      "ICE CREAM AND ICES, COFFEE <-->  Dish\n",
      "ICE CREAM - PAPPAGALLO'S SPECIALITY <-->  Dish\n",
      "VERMOUTH, FRANZ <-->  Dish\n",
      "CALIFORNIA FRESH FRUIT SALAD, WITH COTTAGE CHEESE, SOUR CREAM <-->  Dish\n",
      "FISH CAKES, WITH ONE FRIED EGG, AND COFFEE, TEA OR COCOA <-->  Fish Cakes\n",
      "TOASTED ROLLS WITH WITH A SMALL PITCHER OF CREAM AND WITH BUTTER <-->  Toasted Rolls\n",
      "SAVENNIERES, CHATEAU DE CHAMBOUREAU <-->  Savennieres\n",
      "ROAST FANCY CAPON, CELERY DRESSING, COMPOTE <-->  Roast Capon\n",
      "MUNCHNER SAUERKRAUTPLATTE REICH GARNIERT <-->  Dish\n",
      "1952 ZELTINGER HIMMELREICH, SPATLESE, NATURREIN, WACHSTUM BERNHARD SCHEER, ORIGINALKELLERABZUG, KORKBRAND <-->  Dish\n",
      "OYSTER MORNAY (6) <-->  Dish\n",
      "CHINESE MUSHROOMS AND PORK CHOW MEIN (PAN FRIED NOODLES, SOFT OR CRISP) <-->  Dish\n",
      "GRENADINE COCKTAIL <-->  Dish\n",
      "COFFEE, PER POT OR CUP <-->  Dish\n",
      "BEEF BOURGUIGNONNE - CUBES OF BEEF PREPARED WITH ONIONS AND BURGUNDY WINE <-->  Beef Bourguignon\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "71 <-!=->  71\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "33 <-!=->  33\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "20 <-!=->  20\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "8 <-!=->  8\n",
      "1 <-!=->  1\n",
      "11 <-!=->  11\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0.0 <-!=->  0.0\n",
      "0.7 <-!=->  0.7\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "3.75 <-!=->  3.75\n",
      "0.1 <-!=->  0.1\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.45 <-!=->  0.45\n",
      "11.99 <-!=->  11.99\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.35 <-!=->  0.35\n",
      "0.35 <-!=->  0.35\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.1 <-!=->  0.1\n",
      "2.75 <-!=->  2.75\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.5 <-!=->  0.5\n",
      "3.75 <-!=->  3.75\n",
      "0.65 <-!=->  0.65\n",
      "0.3 <-!=->  0.3\n",
      "0.2 <-!=->  0.2\n",
      "0.1 <-!=->  0.1\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.15 <-!=->  0.15\n",
      "6.5 <-!=->  6.5\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.15 <-!=->  0.15\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.7 <-!=->  0.7\n",
      "0.0 <-!=->  0.0\n",
      "22.0 <-!=->  22.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "24.0 <-!=->  24.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "VINTNER'S SAUTERNE <-->  vintners sauterne\n",
      "EGG, TETRAZINI <-->  egg tetrazini\n",
      "ROAST HOT HOUSE BABY LAMB, MINT SAUCE <-->  roast hot house baby lamb mint sauce\n",
      "POUDING A L'IMPERATRIX <-->  pouding a limperatrix\n",
      "CREAM OF FOWL, SOUFFLE <-->  cream of fowl souffle\n",
      "SAINT-MARCEAUX VERY DRY <-->  saintmarceaux very dry\n",
      "1964ER CHATEAU LA TOUR GAYET, COTES DE BLAYE AC <-->  1964er chateau la tour gayet cotes de blaye ac\n",
      "KALBSSCHNITZEL MIT BRAUNEM KNOBLAUCH, TOMATENNUDELN UND SALAT - ESCALOPE DE VEAU GOUSSE D'AIL AVEC NOUILLES AUX HERBES ET SALADE - EXCALOPE OF VEAL WITH GARLIC, NOODLES WITH HERBS AND SALAD <-->  kalbsschnitzel mit braunem knoblauch tomatennudeln und salat  escalope de veau gousse dail avec nouilles aux herbes et salade  excalope of veal with garlic noodles with herbs and salad\n",
      "UNJOINTED FRIED HALF SPRING CHICKEN ON TOAST, COUNTRY GRAVY <-->  unjointed fried half spring chicken on toast country gravy\n",
      "TENDERLOIN STEAK, WITH TRUFFLES <-->  tenderloin steak with truffles\n",
      "\" SOUTHER COLADA\" - SOUTHERN COMFORT, ANANASSAFT, KOKOSNUSSCREME <-->  souther colada  southern comfort ananassaft kokosnusscreme\n",
      "FRESH HOME=MADE RHUBARB PIE <-->  fresh homemade rhubarb pie\n",
      "UFS? CARLTON <-->  ufs carlton\n",
      "MALTESER REIS-CREME <-->  malteser reiscreme\n",
      "BOILED FRESH BRISKET OF BEEF, HORSERADISH SAUCE, BOUILLON POTATOES <-->  boiled fresh brisket of beef horseradish sauce bouillon potatoes\n",
      "COFFEE, PER POT OR CUP <-->  coffee per pot or cup\n",
      "CALIFORNIA FRESH FRUIT SALAD, WITH COTTAGE CHEESE, SOUR CREAM <-->  california fresh fruit salad with cottage cheese sour cream\n",
      "STRAWBERRY, PEACH OR RASPBERRY JAM <-->  strawberry peach or raspberry jam\n",
      "CHATEAU LATOUR BLANCHE B & G SAUTERNES <-->  chateau latour blanche b  g sauternes\n",
      "OLD SEAL BRANDY, PONY <-->  old seal brandy pony\n",
      "SWEETBREAD CUTLETS, PARISIAN FASHION <-->  sweetbread cutlets parisian fashion\n",
      "2 EGGS, ANY STYLE, SERVED WITH HASHBROWNS & HOT BUTTERED TOAST <-->  2 eggs any style served with hashbrowns  hot buttered toast\n",
      "POTATOES, SAUTEES OR STEWED <-->  potatoes sautees or stewed\n",
      "CREME D'ASPERGES NOUVELLES AUX FLEURONS <-->  creme dasperges nouvelles aux fleurons\n",
      "BROILED SWEETBREADS, GREEN PEAS <-->  broiled sweetbreads green peas\n",
      "FR OCHSENBRUST \"FLAMISCH\" MIT BOUILLONKARTOFFELN UND SAHNEMEERRETTICH <-->  fr ochsenbrust flamisch mit bouillonkartoffeln und sahnemeerrettich\n",
      "FRESH FRUIT SALAD, COUNTRY COTTAGE CHEESE, SOUR CREAM SALAD DRESSING <-->  fresh fruit salad country cottage cheese sour cream salad dressing\n",
      "THEE, KAFFEE, HAFERCACAO <-->  thee kaffee hafercacao\n",
      "0.0 <-!=->  0.0\n",
      "3.75 <-!=->  3.75\n",
      "0.15 <-!=->  0.15\n",
      "0.3 <-!=->  0.3\n",
      "0.3 <-!=->  0.3\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.4 <-!=->  0.4\n",
      "0.85 <-!=->  0.85\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "0.05 <-!=->  0.05\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.35 <-!=->  0.35\n",
      "5.0 <-!=->  5.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "6.5 <-!=->  6.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "25.0 <-!=->  25.0\n",
      "0.0 <-!=->  0.0\n",
      "2.5 <-!=->  2.5\n",
      "0.15 <-!=->  0.15\n",
      "0.0 <-!=->  0.0\n",
      "0.6 <-!=->  0.6\n",
      "0.0 <-!=->  0.0\n",
      "1.95 <-!=->  1.95\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "3.75 <-!=->  3.75\n",
      "0.15 <-!=->  0.15\n",
      "0.3 <-!=->  0.3\n",
      "0.3 <-!=->  0.3\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.4 <-!=->  0.4\n",
      "0.85 <-!=->  0.85\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "0.05 <-!=->  0.05\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.35 <-!=->  0.35\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "6.5 <-!=->  6.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "5.0 <-!=->  5.0\n",
      "0.0 <-!=->  0.0\n",
      "2.5 <-!=->  2.5\n",
      "0.1 <-!=->  0.1\n",
      "0.0 <-!=->  0.0\n",
      "0.6 <-!=->  0.6\n",
      "0.0 <-!=->  0.0\n",
      "1.95 <-!=->  1.95\n",
      "0.0 <-!=->  0.0\n",
      "BLUEFORT CHEESE AND CRACKERS <-->  Bluefort Cheese\n",
      "BREAD AND BUTTER WHITE <-->  Butter\n",
      "EGG, TETRAZINI <-->  Pasta\n",
      "CONSOMME BELLE FERMIERE <-->  Consomme\n",
      "ROAST HOT HOUSE BABY LAMB, MINT SAUCE <-->  Lamb\n",
      "POUDING A L'IMPERATRIX <-->  Empress Pudding\n",
      "CREAM OF FOWL, SOUFFLE <-->  Souffle\n",
      "SAINT-MARCEAUX VERY DRY <-->  Saint-Marceaux\n",
      "1964ER CHATEAU LA TOUR GAYET, COTES DE BLAYE AC <-->  Wine\n",
      "SAUMON BOUILLI <-->  Salmon\n",
      "KALBSSCHNITZEL MIT BRAUNEM KNOBLAUCH, TOMATENNUDELN UND SALAT - ESCALOPE DE VEAU GOUSSE D'AIL AVEC NOUILLES AUX HERBES ET SALADE - EXCALOPE OF VEAL WITH GARLIC, NOODLES WITH HERBS AND SALAD <-->  Kalbsschnitzel mit braunem Knoblauch Tomatennudeln und Salat - Escalope de veau gousse d'ail avec nouilles aux herbes et salade - Excalope of veal with garlic noodles with herbs and salad\n",
      "1954ER OCKFENER BECKSTEIN <-->  Wine\n",
      "BROILED OR FRIED GREEN BLUEFISH <-->  Bluefish\n",
      "UNJOINTED FRIED HALF SPRING CHICKEN ON TOAST, COUNTRY GRAVY <-->  Fried Chicken\n",
      "MACEDOINE DE FRUITS AU MARASQUIN <-->  Macedonian Fruit Salad\n",
      "TENDERLOIN STEAK, WITH TRUFFLES <-->  Steak\n",
      "\" SOUTHER COLADA\" - SOUTHERN COMFORT, ANANASSAFT, KOKOSNUSSCREME <-->    Souther Colada - Southern comfort Ananassaft Kokosnucreme\n",
      "FRESH HOME=MADE RHUBARB PIE <-->  Pie\n",
      "SCHWESERPASTETEN <-->  Pasteties\n",
      "GRAN FRITTO DI MISTO MARE <-->  Fried Mixed Seafood\n",
      "MALTESER REIS-CREME <-->  Maltesers\n",
      "BOILED FRESH BRISKET OF BEEF, HORSERADISH SAUCE, BOUILLON POTATOES <-->  Boiled Fresh Brisket of Beef\n",
      "SELECTED DELICACIES FROM VARIOUS COUNTRIES <-->  Delicacies\n",
      "ROAST LEG OF MUTTON CURRANT JELLY <-->  Roast Leg of Mutton with Currant Jelly\n",
      "FRECCIAROSSA <-->  Pasta\n",
      "CREAM CAROLINE SOUP <-->  Soup\n",
      "COFFEE, PER POT OR CUP <-->  Coffee\n",
      "CALIFORNIA FRESH FRUIT SALAD, WITH COTTAGE CHEESE, SOUR CREAM <-->  California Fresh Fruit Salad\n",
      "BOURBON WHISKY FOUR ROSES 4 CL <-->  Bourbon Whisky\n",
      "SQUAB CASSEROLE <-->  Casserole\n",
      "STRAWBERRY, PEACH OR RASPBERRY JAM <-->  Jam\n",
      "TIMBALES DE RIZ A LA MILANAISE <-->  Timbales\n",
      "INDIVIDUAL WEDDING CAKES FOR EVERYBODY <-->  Wedding Cakes\n",
      "CHATEAU LATOUR BLANCHE B & G SAUTERNES <-->  Chateau Latour Blanche B. & G. Sauternes\n",
      "OLD SEAL BRANDY, PONY <-->  Brandy\n",
      "SWEETBREAD CUTLETS, PARISIAN FASHION <-->  Sweetbread Cutlets\n",
      "2 EGGS, ANY STYLE, SERVED WITH HASHBROWNS & HOT BUTTERED TOAST <-->  2  Any Style served with hashbrowns & hot buttered toast\n",
      "POTATOES, SAUTEES OR STEWED <-->  Potatoes sautees or stewed\n",
      "CREME D'ASPERGES NOUVELLES AUX FLEURONS <-->  Asparagus Creme\n",
      "BROILED SWEETBREADS, GREEN PEAS <-->  Sweetbreads\n",
      "FR OCHSENBRUST \"FLAMISCH\" MIT BOUILLONKARTOFFELN UND SAHNEMEERRETTICH <-->  Ox Breast\n",
      "FRESH FRUIT SALAD, COUNTRY COTTAGE CHEESE, SOUR CREAM SALAD DRESSING <-->  Salad\n",
      "THEE, KAFFEE, HAFERCACAO <-->  Thee Kaffee Hafercacao\n",
      "0.0 <-!=->  0.0\n",
      "3.75 <-!=->  3.75\n",
      "0.15 <-!=->  0.15\n",
      "0.3 <-!=->  0.3\n",
      "0.3 <-!=->  0.3\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.4 <-!=->  0.4\n",
      "0.85 <-!=->  0.85\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "0.05 <-!=->  0.05\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.35 <-!=->  0.35\n",
      "5.0 <-!=->  5.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "6.5 <-!=->  6.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "25.0 <-!=->  25.0\n",
      "0.0 <-!=->  0.0\n",
      "2.5 <-!=->  2.5\n",
      "0.15 <-!=->  0.15\n",
      "0.0 <-!=->  0.0\n",
      "0.6 <-!=->  0.6\n",
      "0.0 <-!=->  0.0\n",
      "1.95 <-!=->  1.95\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "3.75 <-!=->  3.75\n",
      "0.15 <-!=->  0.15\n",
      "0.3 <-!=->  0.3\n",
      "0.3 <-!=->  0.3\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.4 <-!=->  0.4\n",
      "0.85 <-!=->  0.85\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "0.05 <-!=->  0.05\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.35 <-!=->  0.35\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "6.5 <-!=->  6.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "5.0 <-!=->  5.0\n",
      "0.0 <-!=->  0.0\n",
      "2.5 <-!=->  2.5\n",
      "0.1 <-!=->  0.1\n",
      "0.0 <-!=->  0.0\n",
      "0.6 <-!=->  0.6\n",
      "0.0 <-!=->  0.0\n",
      "1.95 <-!=->  1.95\n",
      "0.0 <-!=->  0.0\n",
      "BLUEFORT CHEESE AND CRACKERS <-->  BLUEFORT CHEESE\n",
      "BREAD AND BUTTER WHITE <-->  BREAD AND BUTTER\n",
      "VINTNER'S SAUTERNE <-->  SAUTERNE\n",
      "EGG, TETRAZINI <-->  TETRAZINI\n",
      "CONSOMME BELLE FERMIERE <-->  CONSOMME\n",
      "ROAST HOT HOUSE BABY LAMB, MINT SAUCE <-->  ROAST LAMB\n",
      "POUDING A L'IMPERATRIX <-->  POUDING A LIMPERATRIX\n",
      "CREAM OF FOWL, SOUFFLE <-->  CREAM OF FOWL SOUFFLE\n",
      "SAINT-MARCEAUX VERY DRY <-->  SAINT-MARCEAUX\n",
      "1964ER CHATEAU LA TOUR GAYET, COTES DE BLAYE AC <-->  ER CHATEAU LA TOUR GAYET COTES DE BLAYE AC\n",
      "KALBSSCHNITZEL MIT BRAUNEM KNOBLAUCH, TOMATENNUDELN UND SALAT - ESCALOPE DE VEAU GOUSSE D'AIL AVEC NOUILLES AUX HERBES ET SALADE - EXCALOPE OF VEAL WITH GARLIC, NOODLES WITH HERBS AND SALAD <-->  WIENER SCHNITZEL\n",
      "1954ER OCKFENER BECKSTEIN <-->  OCKFENER BECKSTEIN\n",
      "BROILED OR FRIED GREEN BLUEFISH <-->  BLUEFISH\n",
      "UNJOINTED FRIED HALF SPRING CHICKEN ON TOAST, COUNTRY GRAVY <-->  FRIED CHICKEN\n",
      "TENDERLOIN STEAK, WITH TRUFFLES <-->  TENDERLOIN STEAK\n",
      "\" SOUTHER COLADA\" - SOUTHERN COMFORT, ANANASSAFT, KOKOSNUSSCREME <-->  SOUTHERN COMFORT COCKTAIL\n",
      "FRESH HOME=MADE RHUBARB PIE <-->  FRESH HOMEMADE RHUBARB PIE\n",
      "UFS? CARLTON <-->  UFS CARLTON\n",
      "MALTESER REIS-CREME <-->  MALTESERS\n",
      "BOILED FRESH BRISKET OF BEEF, HORSERADISH SAUCE, BOUILLON POTATOES <-->  BOILED BRISKET\n",
      "SELECTED DELICACIES FROM VARIOUS COUNTRIES <-->  DELICACIES\n",
      "CREAM CAROLINE SOUP <-->  CAROLINE SOUP\n",
      "COFFEE, PER POT OR CUP <-->  PER POT OR CUP\n",
      "CALIFORNIA FRESH FRUIT SALAD, WITH COTTAGE CHEESE, SOUR CREAM <-->  FRUIT SALAD\n",
      "BOURBON WHISKY FOUR ROSES 4 CL <-->  FOUR ROSES BOURBON\n",
      "STRAWBERRY, PEACH OR RASPBERRY JAM <-->  JAM\n",
      "INDIVIDUAL WEDDING CAKES FOR EVERYBODY <-->  WEDDING CAKE\n",
      "CHATEAU LATOUR BLANCHE B & G SAUTERNES <-->  CHATEAU LATOUR\n",
      "OLD SEAL BRANDY, PONY <-->  OLD SEAL BRANDY PONY\n",
      "SWEETBREAD CUTLETS, PARISIAN FASHION <-->  SWEETBREAD CUTLETS\n",
      "2 EGGS, ANY STYLE, SERVED WITH HASHBROWNS & HOT BUTTERED TOAST <-->  ANY STYLE SERVED WITH HASHBROWNS  HOT BUTTERED TOAST\n",
      "POTATOES, SAUTEES OR STEWED <-->  POTATOES SAUTEES OR STEWED\n",
      "CREME D'ASPERGES NOUVELLES AUX FLEURONS <-->  ASPARAGUS CREAM SOUP\n",
      "BROILED SWEETBREADS, GREEN PEAS <-->  BROILED SWEETBREADS GREEN\n",
      "FR OCHSENBRUST \"FLAMISCH\" MIT BOUILLONKARTOFFELN UND SAHNEMEERRETTICH <-->  OX BREAST\n",
      "FRESH FRUIT SALAD, COUNTRY COTTAGE CHEESE, SOUR CREAM SALAD DRESSING <-->  FRESH FRUIT SALAD COUNTRY COTTAGE CHEESE SOUR CREAM SALAD DRESSING\n",
      "THEE, KAFFEE, HAFERCACAO <-->  THEE KAFFEE HAFERCACAO\n",
      "0.0 <-!=->  0.0\n",
      "3.75 <-!=->  3.75\n",
      "0.15 <-!=->  0.15\n",
      "0.3 <-!=->  0.3\n",
      "0.3 <-!=->  0.3\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.4 <-!=->  0.4\n",
      "0.85 <-!=->  0.85\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "0.05 <-!=->  0.05\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.35 <-!=->  0.35\n",
      "5.0 <-!=->  5.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "6.5 <-!=->  6.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "25.0 <-!=->  25.0\n",
      "0.0 <-!=->  0.0\n",
      "2.5 <-!=->  2.5\n",
      "0.15 <-!=->  0.15\n",
      "0.0 <-!=->  0.0\n",
      "0.6 <-!=->  0.6\n",
      "0.0 <-!=->  0.0\n",
      "1.95 <-!=->  1.95\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "3.75 <-!=->  3.75\n",
      "0.15 <-!=->  0.15\n",
      "0.3 <-!=->  0.3\n",
      "0.3 <-!=->  0.3\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.4 <-!=->  0.4\n",
      "0.85 <-!=->  0.85\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "0.05 <-!=->  0.05\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.35 <-!=->  0.35\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "6.5 <-!=->  6.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "5.0 <-!=->  5.0\n",
      "0.0 <-!=->  0.0\n",
      "2.5 <-!=->  2.5\n",
      "0.1 <-!=->  0.1\n",
      "0.0 <-!=->  0.0\n",
      "0.6 <-!=->  0.6\n",
      "0.0 <-!=->  0.0\n",
      "1.95 <-!=->  1.95\n",
      "0.0 <-!=->  0.0\n",
      "ATLANTIC SWORDFISH STEAK CENTER CUT, CORIANDER BUTTER SAUCE <-->  ATLANTIC SWORDFISH STEAK Center cut Coriander Butter Sauce\n",
      "SUPREME OF CHICKEN, SAUTE CACCIATORA <-->  Chicken Supreme\n",
      "BEATRICE CAKE, PER LB <-->  beatrice cake per lb\n",
      "MONKS BEARD SALAD <-->  Monk's Beard Salad\n",
      "HOT SLICED TURKEY SANDWICH MORNAY, IN POTATO BORDURE, WITH FRESH ASPARAGUS <-->  Hot Turkey Sandwich Mornay with Asparagus\n",
      "ECARLATE <-->  Wine\n",
      "SCOTCH, KING WILLIAM IV <-->  Scotch King William IV\n",
      "COUNTRY SAUSAGES, FRIED BANANAS <-->  Fried Bananas\n",
      "FRIED MACKEREL, MUSTARD SAUCE <-->  Fried Mackerel Mustard sauce\n",
      "COLD FERRIS HAM <-->  Ham\n",
      "WEHLENER ROSENBERG, 1907, 1/2 BOTTLE, BOTTLE <-->  Wehlener Rosenberg Wine\n",
      "BROILED PORK CHOPS, APPLE SAUCE, VEGETABLE, POTATO <-->  Broiled Pork Chops Apple Sauce Vegetable Potato\n",
      "REUBEN'S SPECIAL TURKEY, ROAST VIRGINIA HAM, SWISS CHEESE, COLE SLAW, RUSSIAN DRESSING <-->  Reuben Sandwich\n",
      "OMELETS, VARIES <-->  Omelettes\n",
      "BREAD AND BUTTER WHITE? <-->  bread and Butter white\n",
      "CANADA MUTTON CHOP <-->  Mutton Chop\n",
      "CAFE PUDDING <-->  Pudding\n",
      "LOBSTER SALAD, CHICKEN <-->  Chicken Salad\n",
      "PEIXE ESPADA GRELHADO, MAITRE D'HOTEL <-->  Grilled Swordfish Maitre d'Hotel\n",
      "STUFFED TURKEY, CRANBERRY SAUCE <-->  Stuffed Turkey with Cranberry Sauce\n",
      "(BEEF STEAK), FRIED ONIONS <-->  Beef Steak fried onions\n",
      "BREAST OF LAMB, JARDINIERE <-->  Breast of lamb Jardiniere\n",
      "MACEDOINE DE FRUITS AU MARASQUIN <-->  Fruit Salad\n",
      "(BEEF) TAMALE <-->  Beef Tamale\n",
      "OYSTER MORNAY (6) <-->  Oyster Mornay\n",
      "*FILET OF SOLE WITH FRESH SPINACH FLORENTINE <-->  Sole Fillet with Spinach Florentine\n",
      "VEUVE CLICQOUT, GOLD LABEL, BRUT <-->  Veuve Clicqout Gold Label Brut\n",
      "L'ENTRECOTE A LA BERCY - NEW YORK STRIP STEAK, WITH SHALLOTS, AND FRENCH FRIED POTATOES <-->  LEntrecote a la Bercy  New York strip steak with shallots and French fried potatoes\n",
      "SHAD ROE SAUTE MEUNIERE <-->  Sauteed Shad Roe Meuniere\n",
      "POTATOES, SAUTEES OR STEWED <-->  Potatoes sautees or stewed\n",
      "BROILED SMALL STEAK WITH POTATOES <-->  Broiled Small Steak with   Potatoes\n",
      "BLATTSALATE MIT HANDGESCHPFTEM SCHAFSKSE <-->  Blattsalate mit handgeschpftem Schafskse\n",
      "MADRE <-->  Madre\n",
      "BRANDY (DOMESTIC) <-->  Brandy\n",
      "CIGARS, MANUEL GARCIA, INVENCIBLE <-->  Cigars\n",
      "COFFEE ICE CREAM, CARAMEL SAUCE <-->  Coffee Ice Cream caramel sauce\n",
      "VINTAGE PORT MARTINEZ 1963 <-->  Port\n",
      "ROAST SPRING LAMB, MINT SAUCE (READY) <-->  Roast spring lamb mint sauce ready\n",
      "BAKED FRESH MACKEREL, CREOLE <-->  Baked Fresh Mackerel Creole\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "33 <-!=->  33\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "9 <-!=->  9\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "13 <-!=->  13\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "4 <-!=->  4\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "2 <-!=->  2\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "33 <-!=->  33\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "9 <-!=->  9\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "14 <-!=->  14\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "4 <-!=->  4\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "2 <-!=->  2\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "ATLANTIC SWORDFISH STEAK CENTER CUT, CORIANDER BUTTER SAUCE <-->  ATLANTIC SWORDFISH STEAK Center cut Coriander Butter Sauce\n",
      "SUPREME OF CHICKEN, SAUTE CACCIATORA <-->  Chicken Supreme Cacciatora\n",
      "BEATRICE CAKE, PER LB <-->  beatrice cake per lb\n",
      "HOT SLICED TURKEY SANDWICH MORNAY, IN POTATO BORDURE, WITH FRESH ASPARAGUS <-->  Turkey Sandwich Mornay\n",
      "SCOTCH, KING WILLIAM IV <-->  Scotch    King William IV\n",
      "COUNTRY SAUSAGES, FRIED BANANAS <-->  Country Sausages Fried Bananas\n",
      "FRIED MACKEREL, MUSTARD SAUCE <-->  Fried Mackerel Mustard sauce\n",
      "COLD FERRIS HAM <-->  Ham\n",
      "BRANDY PEACHES PRESERVES <-->  Brandy Peaches\n",
      "WEHLENER ROSENBERG, 1907, 1/2 BOTTLE, BOTTLE <-->  Wehlener Rosenberg 1907\n",
      "BROILED PORK CHOPS, APPLE SAUCE, VEGETABLE, POTATO <-->  Pork Chops\n",
      "REUBEN'S SPECIAL TURKEY, ROAST VIRGINIA HAM, SWISS CHEESE, COLE SLAW, RUSSIAN DRESSING <-->  REUBENS SPECIAL Turkey Roast Virginia Ham Swiss Cheese Cole Slaw Russian Dressing\n",
      "OMELETS, VARIES <-->  omelets varies\n",
      "BREAD AND BUTTER WHITE? <-->  bread and Butter white\n",
      "CAFE PUDDING <-->  Caf Pudding\n",
      "FRICANDEAU VEAL AND OLIVES <-->  Veal Fricandeau with Olives\n",
      "LOBSTER SALAD, CHICKEN <-->  Lobster Salad Chicken\n",
      "PEIXE ESPADA GRELHADO, MAITRE D'HOTEL <-->  Peixe Espada Grelhado Maitre dHotel\n",
      "STUFFED TURKEY, CRANBERRY SAUCE <-->  Stuffed turkey cranberry sauce\n",
      "(BEEF STEAK), FRIED ONIONS <-->  fried onions\n",
      "BREAST OF LAMB, JARDINIERE <-->  Breast of lamb Jardiniere\n",
      "(BEEF) TAMALE <-->  Tamale\n",
      "OYSTER MORNAY (6) <-->  Oyster Mornay\n",
      "*FILET OF SOLE WITH FRESH SPINACH FLORENTINE <-->  Sole Florentine\n",
      "VEUVE CLICQOUT, GOLD LABEL, BRUT <-->  Veuve Clicqout Gold Label Brut\n",
      "L'ENTRECOTE A LA BERCY - NEW YORK STRIP STEAK, WITH SHALLOTS, AND FRENCH FRIED POTATOES <-->  LEntrecote a la Bercy  New York strip steak with shallots and French fried potatoes\n",
      "KALBFLEISCH FRICASSEE <-->  Veal Fricassee\n",
      "SHAD ROE SAUTE MEUNIERE <-->  Shad Roe Meunire\n",
      "POTATOES, SAUTEES OR STEWED <-->  Potatoes sautees or stewed\n",
      "BROILED SMALL STEAK WITH POTATOES <-->  Steak with Potatoes\n",
      "BLATTSALATE MIT HANDGESCHPFTEM SCHAFSKSE <-->  Blattsalate mit handgeschpftem Schafskse\n",
      "HEAD LETTUCE WITH THOUSAND ISLAND DRESSING <-->  Lettuce with Thousand Island Dressing\n",
      "MADRE <-->  Madre\n",
      "BRANDY (DOMESTIC) <-->  Brandy\n",
      "CIGARS, MANUEL GARCIA, INVENCIBLE <-->  Cigars\n",
      "COFFEE ICE CREAM, CARAMEL SAUCE <-->  Coffee Ice Cream caramel sauce\n",
      "VINTAGE PORT MARTINEZ 1963 <-->  Vintage Port\n",
      "ROAST SPRING LAMB, MINT SAUCE (READY) <-->  Roast spring lamb mint sauce\n",
      "BAKED FRESH MACKEREL, CREOLE <-->  Baked Mackerel Creole\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "0 <-!=->  0\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "33 <-!=->  33\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "9 <-!=->  9\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "14 <-!=->  14\n",
      "2 <-!=->  2\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "2 <-!=->  2\n",
      "4 <-!=->  4\n",
      "3 <-!=->  3\n",
      "2 <-!=->  2\n",
      "2 <-!=->  2\n",
      "4 <-!=->  4\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "1 <-!=->  1\n",
      "3 <-!=->  3\n",
      "1 <-!=->  1\n",
      "17.0 <-!=->  17.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.4 <-!=->  0.4\n",
      "1.65 <-!=->  1.65\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.75 <-!=->  0.75\n",
      "0.5 <-!=->  0.5\n",
      "1.5 <-!=->  1.5\n",
      "1.75 <-!=->  1.75\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.15 <-!=->  0.15\n",
      "1.7 <-!=->  1.7\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "1.5 <-!=->  1.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "1.3 <-!=->  1.3\n",
      "0.0 <-!=->  0.0\n",
      "0.5 <-!=->  0.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "3.7 <-!=->  3.7\n",
      "3.75 <-!=->  3.75\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "1.35 <-!=->  1.35\n",
      "0.15 <-!=->  0.15\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.8 <-!=->  0.8\n",
      "6.5 <-!=->  6.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.9 <-!=->  0.9\n",
      "0.6 <-!=->  0.6\n",
      "0.4 <-!=->  0.4\n",
      "17.0 <-!=->  17.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.4 <-!=->  0.4\n",
      "1.65 <-!=->  1.65\n",
      "0.2 <-!=->  0.2\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.75 <-!=->  0.75\n",
      "0.3 <-!=->  0.3\n",
      "0.8 <-!=->  0.8\n",
      "1.75 <-!=->  1.75\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.15 <-!=->  0.15\n",
      "0.65 <-!=->  0.65\n",
      "0.25 <-!=->  0.25\n",
      "0.0 <-!=->  0.0\n",
      "1.5 <-!=->  1.5\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "1.3 <-!=->  1.3\n",
      "0.0 <-!=->  0.0\n",
      "0.3 <-!=->  0.3\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "2.75 <-!=->  2.75\n",
      "2.0 <-!=->  2.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "1.25 <-!=->  1.25\n",
      "0.1 <-!=->  0.1\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.38 <-!=->  0.38\n",
      "0.3 <-!=->  0.3\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.0 <-!=->  0.0\n",
      "0.9 <-!=->  0.9\n",
      "0.25 <-!=->  0.25\n",
      "0.4 <-!=->  0.4\n"
     ]
    }
   ],
   "source": [
    "result_dict = retrieve_tg_cols(\"/projects/bces/lanl2/LLM4DC/evaluation/target_columns_list.csv\")\n",
    "print(result_dict)\n",
    "model = \"gemma2\"\n",
    "# model = \"dirty\"\n",
    "data_gt_folder = \"/projects/bces/lanl2/LLM4DC/datasets\"\n",
    "ratio_list = []\n",
    "for query_id in range(111):\n",
    "    # print(query_id)\n",
    "    tg_cols = result_dict.get(query_id)\n",
    "    if tg_cols:\n",
    "        if model == \"llama3.1\":\n",
    "            llm_folder = f\"CoT.response/{model}/datasets_llm\"\n",
    "            pred_fp = f'/projects/bces/lanl2/LLM4DC/{llm_folder}'\n",
    "            if query_id >= 62 and query_id <= 91:\n",
    "                target_path = f'{data_gt_folder}/ppp_datasets/cleaned_tables/ppp_sample_p{query_id}.csv'\n",
    "                table_preds_path = f'{pred_fp}/ppp_test_{query_id}.csv'\n",
    "\n",
    "            elif query_id >= 92:\n",
    "                target_path = f'{data_gt_folder}/dish_datasets/cleaned_tables/dish_sample_p{query_id}.csv'\n",
    "                table_preds_path = f'{pred_fp}/dish_test_{query_id}.csv'\n",
    "\n",
    "            elif query_id >= 31 and query_id <= 61:\n",
    "                target_path = f'{data_gt_folder}/chi_food_inspection_datasets/cleaned_tables/chi_sample_p{query_id}.csv'\n",
    "                table_preds_path = f'{pred_fp}/chi_test_{query_id}.csv'\n",
    "\n",
    "            elif query_id <31:\n",
    "                target_path = f'{data_gt_folder}/purpose-prepared-datasets/menu/menu_p{query_id}.csv'\n",
    "                table_preds_path = f'{pred_fp}/menu_test_{query_id}.csv'\n",
    "        elif model==\"dirty\":\n",
    "            if query_id >= 62 and query_id <= 91:\n",
    "                target_path = f'{data_gt_folder}/ppp_datasets/cleaned_tables/ppp_sample_p{query_id}.csv'\n",
    "                table_preds_path =  f'/projects/bces/lanl2/LLM4DC/datasets/ppp_datasets/ppp_data_p{query_id}.csv'\n",
    "            elif query_id >= 92:\n",
    "                target_path = f'{data_gt_folder}/dish_datasets/cleaned_tables/dish_sample_p{query_id}.csv'\n",
    "                table_preds_path = f'/projects/bces/lanl2/LLM4DC/datasets/dish_datasets/dish_data_p{query_id}.csv'\n",
    "            elif query_id >= 31 and query_id <= 61:\n",
    "                target_path = f'{data_gt_folder}/chi_food_inspection_datasets/cleaned_tables/chi_sample_p{query_id}.csv'\n",
    "                table_preds_path = f'/projects/bces/lanl2/LLM4DC/datasets/chi_food_inspection_datasets/chi_food_data_p{query_id}.csv'\n",
    "            elif query_id <31:\n",
    "                target_path = f'{data_gt_folder}/purpose-prepared-datasets/menu/menu_p{query_id}.csv'\n",
    "                table_preds_path = f'/projects/bces/lanl2/LLM4DC/datasets/purpose-prepared-datasets/menu/menu_data.csv'\n",
    "        else:\n",
    "\n",
    "            llm_folder = f\"CoT.response/{model}/datasets_llm\"\n",
    "            data_gt_folder = \"/projects/bces/lanl2/LLM4DC/datasets\"\n",
    "            pred_fp = f'/projects/bces/lanl2/LLM4DC/{llm_folder}'\n",
    "            if query_id >= 62 and query_id <= 91:\n",
    "                target_path = f'{data_gt_folder}/ppp_datasets/cleaned_tables/ppp_sample_p{query_id}.csv'\n",
    "                table_preds_path = f'{pred_fp}/{model}_ppp_test_{query_id}.csv'\n",
    "\n",
    "            elif query_id >= 92:\n",
    "                target_path = f'{data_gt_folder}/dish_datasets/cleaned_tables/dish_sample_p{query_id}.csv'\n",
    "                table_preds_path = f'{pred_fp}/{model}_dish_test_{query_id}.csv'\n",
    "\n",
    "            elif query_id >= 31 and query_id <= 61:\n",
    "                target_path = f'{data_gt_folder}/chi_food_inspection_datasets/cleaned_tables/chi_sample_p{query_id}.csv'\n",
    "                table_preds_path = f'{pred_fp}/{model}_chi_test_{query_id}.csv'\n",
    "\n",
    "            elif query_id <31:\n",
    "                target_path = f'{data_gt_folder}/purpose-prepared-datasets/menu/menu_p{query_id}.csv'\n",
    "                table_preds_path = f'{pred_fp}/{model}_menu_test_{query_id}.csv'\n",
    "        gt_df = pd.read_csv(target_path)\n",
    "        preds_df = pd.read_csv(table_preds_path)\n",
    "        # print(gt_df.head(5), preds_df.head(5))\n",
    "        res = average_match_ratio(gt_df, preds_df, tg_cols)\n",
    "        ratio_list.append({'pp_id': query_id, 'ratio': res})\n",
    "dt_result = pd.DataFrame(ratio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma2'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_result.to_csv(f'evaluation/{model}_table_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp_id</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pp_id  ratio\n",
       "0      1   0.30\n",
       "1      2   1.00\n",
       "2      3   0.26\n",
       "3      4   0.26\n",
       "4      5   0.26"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.733834237901402\n",
      "0.24074387348355658\n",
      "0.21\n",
      "1.0\n",
      "0.5925\n",
      "0.775\n",
      "0.9708333333333333\n"
     ]
    }
   ],
   "source": [
    "stat = dt_result['ratio'].describe()\n",
    "for idx in ['mean', 'std',\t'min',\t'max',\t'25%',\t'50%',\t'75%']:\n",
    "    print(stat.loc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8672348484848484\n",
      "0.16225457379430547\n",
      "0.5\n",
      "1.0\n",
      "0.7375\n",
      "0.9708333333333333\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577642/1140604443.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ppp_dt_results = dt_result[dt_result['pp_id'] >= 62][dt_result['pp_id'] <=91]\n"
     ]
    }
   ],
   "source": [
    "ppp_dt_results = dt_result[dt_result['pp_id'] >= 62][dt_result['pp_id'] <=91]\n",
    "stat = ppp_dt_results['ratio'].describe()\n",
    "for idx in ['mean', 'std',\t'min',\t'max',\t'25%',\t'50%',\t'75%']:\n",
    "    print(stat.loc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7523958333333333\n",
      "0.12962048413506025\n",
      "0.5\n",
      "1.0\n",
      "0.6725\n",
      "0.7566666666666666\n",
      "0.8066666666666666\n"
     ]
    }
   ],
   "source": [
    "dish_dt_result =dt_result[dt_result['pp_id'] >= 92]\n",
    "stat = dish_dt_result['ratio'].describe()\n",
    "for idx in ['mean', 'std',\t'min',\t'max',\t'25%',\t'50%',\t'75%']:\n",
    "    print(stat.loc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6607226107226107\n",
      "0.2738546155369595\n",
      "0.25\n",
      "1.0\n",
      "0.45\n",
      "0.7727272727272727\n",
      "0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577642/3331208062.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  chi_dt_result =dt_result[dt_result['pp_id'] >= 31][dt_result['pp_id'] <=61]\n"
     ]
    }
   ],
   "source": [
    "chi_dt_result =dt_result[dt_result['pp_id'] >= 31][dt_result['pp_id'] <=61]\n",
    "stat = chi_dt_result['ratio'].describe()\n",
    "for idx in ['mean', 'std',\t'min',\t'max',\t'25%',\t'50%',\t'75%']:\n",
    "    print(stat.loc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59125\n",
      "0.2976099236696698\n",
      "0.21\n",
      "1.0\n",
      "0.315\n",
      "0.5925\n",
      "0.935\n"
     ]
    }
   ],
   "source": [
    "menu_dt_result =dt_result[dt_result['pp_id'] < 31]\n",
    "\n",
    "stat = menu_dt_result['ratio'].describe()\n",
    "for idx in ['mean', 'std',\t'min',\t'max',\t'25%',\t'50%',\t'75%']:\n",
    "    print(stat.loc[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table eval ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# answer eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path = '/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_gt.json'\n",
    "data = []\n",
    "with open(datafile_path, 'r') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/lirif2/.conda/envs/llm4dc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union, List, Dict, Any\n",
    "from difflib import SequenceMatcher\n",
    "from math import isclose\n",
    "\n",
    "# Define a utility to convert JSON strings to Python objects\n",
    "def parse_input(answer: Union[str, float, List, Dict]) -> Any:\n",
    "    if isinstance(answer, str):\n",
    "        try:\n",
    "            # Try to parse JSON strings into Python objects\n",
    "            return json.loads(answer)\n",
    "        except json.JSONDecodeError:\n",
    "            return answer.lower().strip()  # Normalize strings for comparison\n",
    "    elif isinstance(answer, float):\n",
    "        return round(answer, 2)  # Round floats to two decimal places if needed\n",
    "    return answer  # If already in desired format\n",
    "\n",
    "# Calculate exact match accuracy\n",
    "def accuracy_metric(gt: Any, pred: Any) -> float:\n",
    "    return 1.0 if gt == pred else 0.0\n",
    "\n",
    "# Calculate precision, recall, and F1 for lists (assuming items are unique)\n",
    "def precision_recall_f1(gt: List, pred: List) -> Dict[str, float]:\n",
    "    gt_set, pred_set = set(gt), set(pred)\n",
    "    true_positives = len(gt_set & pred_set)\n",
    "    precision = true_positives / len(pred_set) if pred_set else 0\n",
    "    recall = true_positives / len(gt_set) if gt_set else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1_score}\n",
    "\n",
    "# Calculate semantic distance for string answers using sequence matching\n",
    "def semantic_similarity(gt: str, pred: str) -> float:\n",
    "    return SequenceMatcher(None, gt, pred).ratio()  # Returns a ratio between 0 and 1\n",
    "\n",
    "# Evaluate an answer based on the ground truth\n",
    "def calculate_answer_metrics(gt: Any, pred: Any) -> Dict[str, float]:\n",
    "    # Parse inputs\n",
    "    gt, pred = parse_input(gt), parse_input(pred)\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {\"accuracy\": 0, \"semantic_similarity\": 0, \"precision\": 0, \"recall\":0, \"f1\":0}\n",
    "    \n",
    "    # Check type and apply appropriate metrics\n",
    "    if isinstance(gt, float) and isinstance(pred, float):\n",
    "        results[\"accuracy\"] = 1.0 if isclose(gt, pred, rel_tol=1e-2) else 0.0  # Accuracy for floats with tolerance\n",
    "        precision, recall = results[\"accuracy\"], results[\"accuracy\"]\n",
    "        results.update({\"precision\": precision, \"recall\": recall, \"f1\": 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0})\n",
    "        # results['bertscore'] = score([f\"{pred}\"], [f\"{gt}\"], lang='en', verbose=True)\n",
    "        results[\"semantic_similarity\"] = semantic_similarity(str(gt), str(pred))\n",
    "    elif isinstance(gt, int) and isinstance(pred, int):\n",
    "        results[\"accuracy\"] = 1.0 if isclose(gt, pred, rel_tol=1e-2) else 0.0  # Accuracy for floats with tolerance\n",
    "        precision, recall = results[\"accuracy\"], results[\"accuracy\"]\n",
    "        results.update({\"precision\": precision, \"recall\": recall, \"f1\": 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0})\n",
    "        # results['bertscore'] = score([f\"{pred}\"], [f\"{gt}\"], lang='en', verbose=True)\n",
    "        results[\"semantic_similarity\"] = semantic_similarity(str(gt), str(pred))\n",
    "\n",
    "\n",
    "    elif isinstance(gt, str) and isinstance(pred, str):\n",
    "        results[\"accuracy\"] = accuracy_metric(gt, pred)\n",
    "        precision, recall = results[\"accuracy\"], results[\"accuracy\"]\n",
    "        results.update({\"precision\": precision, \"recall\": recall, \"f1\": 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0})\n",
    "        # results['bertscore'] = score([pred], [gt], lang='en', verbose=True)\n",
    "        results[\"semantic_similarity\"] = semantic_similarity(gt, pred)\n",
    "\n",
    "    \n",
    "    elif isinstance(gt, list) and isinstance(pred, list):\n",
    "        metrics = precision_recall_f1(gt, pred)\n",
    "        results.update(metrics)\n",
    "        results[\"accuracy\"] = accuracy_metric(gt, pred)\n",
    "        # results['bertscore'] = score([f\"{pred}\"], [f\"{gt}\"], lang='en', verbose=True)\n",
    "        similarity = semantic_similarity(f\"{gt}\", f\"{pred}\")\n",
    "        results[\"semantic_similarity\"] = similarity\n",
    "\n",
    "    \n",
    "    elif isinstance(gt, dict) and isinstance(pred, dict):\n",
    "        gt_keys, pred_keys = list(gt.keys()), list(pred.keys())\n",
    "        if type(gt[gt_keys[0]]) == dict:\n",
    "            precision_recall_f1_results = [precision_recall_f1(gt[k].values(), pred[k].values()) for k in gt_keys]\n",
    "            precision = sum([x['precision'] for x in precision_recall_f1_results])/len([x['precision'] for x in precision_recall_f1_results])\n",
    "            recall = sum([x['recall'] for x in precision_recall_f1_results])/len([x['recall'] for x in precision_recall_f1_results])\n",
    "            f1 =sum([x['f1'] for x in precision_recall_f1_results])/len([x['f1'] for x in precision_recall_f1_results])\n",
    "            results.update({'precision': precision, 'recall':recall, 'f1': f1})  # Precision/Recall on keys\n",
    "\n",
    "        elif type(gt[gt_keys[0]]) == list:\n",
    "            precision_recall_f1_results = [precision_recall_f1(gt[k], pred[k]) for k in gt_keys]\n",
    "            precision = sum([x['precision'] for x in precision_recall_f1_results])/len([x['precision'] for x in precision_recall_f1_results])\n",
    "            recall = sum([x['recall'] for x in precision_recall_f1_results])/len([x['recall'] for x in precision_recall_f1_results])\n",
    "            f1 =sum([x['f1'] for x in precision_recall_f1_results])/len([x['f1'] for x in precision_recall_f1_results])\n",
    "            results.update({'precision': precision, 'recall':recall, 'f1': f1})  # Precision/Recall on keys\n",
    "        \n",
    "\n",
    "        results[\"accuracy\"] = accuracy_metric(gt, pred)\n",
    "        # Check semantic similarity for each key-value pair\n",
    "        similarity = [semantic_similarity(str(gt[k]), str(pred.get(k, \"\"))) for k in gt_keys]\n",
    "        results[\"semantic_similarity\"] = sum(similarity) / len(similarity) if similarity else 0\n",
    "        \n",
    "        # results['bertscore'] = score([f\"{pred}\"], [f\"{gt}\"], lang='en', verbose=True)\n",
    "    p, r, f1 = score([f\"{pred}\"], [f\"{gt}\"], lang='en', verbose=True)\n",
    "    results.update({'bertscore_p': p.detach().cpu().tolist(),\n",
    "    'bertscore_r': r.detach().cpu().tolist(),\n",
    "    'bertscore_f1': f1.detach().cpu().tolist()})\n",
    "    # print(results)\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json = \"{\\\"Zip\\\":{\\\"0\\\":96701,\\\"1\\\":96704,\\\"2\\\":96707,\\\"3\\\":96708,\\\"4\\\":96749,\\\"5\\\":96750,\\\"6\\\":96754,\\\"7\\\":96791,\\\"8\\\":96813,\\\"9\\\":96814,\\\"10\\\":96815,\\\"11\\\":96816,\\\"12\\\":96817,\\\"13\\\":96821,\\\"14\\\":96825,\\\"15\\\":96826},\\\"LoanCount\\\":{\\\"0\\\":1,\\\"1\\\":1,\\\"2\\\":4,\\\"3\\\":1,\\\"4\\\":1,\\\"5\\\":1,\\\"6\\\":1,\\\"7\\\":1,\\\"8\\\":1,\\\"9\\\":1,\\\"10\\\":1,\\\"11\\\":2,\\\"12\\\":1,\\\"13\\\":1,\\\"14\\\":1,\\\"15\\\":1}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json = parse_input(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([96701, 96704, 96707, 96708, 96749, 96750, 96754, 96791, 96813, 96814, 96815, 96816, 96817, 96821, 96825, 96826])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_json.keys()\n",
    "test_json.get('Zip').values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-based history update solution\n",
    "import importlib.util\n",
    "import inspect\n",
    "from typing import List\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import difflib\n",
    "from collections import Counter\n",
    "# from spellchecker import SpellChecker\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "import logging \n",
    "# from history_update_problem.call_or import export_rows\n",
    "from call_or import *\n",
    "\n",
    "# from evaluation.data_compare import calculate_answer_metrics\n",
    "\n",
    "\n",
    "def load_answer_dataset(datafile_path):\n",
    "    \"\"\"\n",
    "    load json file, each line is a json dictionary\n",
    "\n",
    "    datafile_path: str\n",
    "    return: data:  list_of_dictionary\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(datafile_path, 'r') as f:\n",
    "        for l in f:\n",
    "            data.append(json.loads(l))\n",
    "    return data\n",
    "\n",
    "def eval_answers(answer_gt_path, answer_preds_llama):\n",
    "    answer_gt = load_answer_dataset(answer_gt_path)\n",
    "    answer_gt = pd.DataFrame(answer_gt)\n",
    "    answer_preds_llama = load_answer_dataset(answer_preds_llama)\n",
    "    answer_preds_llama = pd.DataFrame(answer_preds_llama)\n",
    "    answer_compare = answer_gt.merge(answer_preds_llama[['pp_id', 'answer']], on='pp_id', how='left', suffixes=('_gt', '_preds'))\n",
    "\n",
    "    results = []\n",
    "    for i, row in answer_compare.iterrows():\n",
    "        gt = row['answer_gt']\n",
    "        preds = row['answer_preds']\n",
    "        single_result = calculate_answer_metrics(gt, preds)\n",
    "        single_result['pp_id'] = row['pp_id']\n",
    "        results.append(single_result)\n",
    "        # break\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 92.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 891.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.96 sentences/sec\n",
      "22 <class 'int'>\n",
      "22 <class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0000004768371582]</td>\n",
       "      <td>[1.0000004768371582]</td>\n",
       "      <td>[1.0000004768371582]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  semantic_similarity  precision  recall   f1  \\\n",
       "0       1.0                  1.0        1.0     1.0  1.0   \n",
       "\n",
       "            bertscore_p           bertscore_r          bertscore_f1  pp_id  \n",
       "0  [1.0000004768371582]  [1.0000004768371582]  [1.0000004768371582]      1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title single eexample\n",
    "answer_gt_path = '/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_gt.json'\n",
    "answer_gt = load_answer_dataset(answer_gt_path)\n",
    "answer_gt = pd.DataFrame(answer_gt)\n",
    "answer_preds_llama = '/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_llama3.1.json'\n",
    "answer_preds_llama = load_answer_dataset(answer_preds_llama)\n",
    "answer_preds_llama = pd.DataFrame(answer_preds_llama)\n",
    "answer_compare = answer_gt.merge(answer_preds_llama[['pp_id', 'answer']], on='pp_id', how='left', suffixes=('_gt', '_preds'))\n",
    "\n",
    "results = []\n",
    "for i, row in answer_compare.iterrows():\n",
    "    gt = row['answer_gt']\n",
    "    preds = row['answer_preds']\n",
    "    single_result = calculate_answer_metrics(gt, preds)\n",
    "    single_result['pp_id'] = row['pp_id']\n",
    "    print(gt, type(gt))\n",
    "    print(preds, type(preds))\n",
    "    results.append(single_result)\n",
    "    break\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isclose(22,22, rel_tol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 99.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 712.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.51 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 89.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 909.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 45.74 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 89.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 910.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.20 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 94.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 911.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.40 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 92.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 911.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.71 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 90.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 909.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.85 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 47.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 860.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 36.08 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 97.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 884.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 37.15 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 94.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 854.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 57.16 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 96.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 915.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.10 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 722.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.06 seconds, 17.88 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 79.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 896.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 46.14 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 852.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 37.40 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 85.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 895.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.34 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 45.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 824.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 32.56 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 84.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 883.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 47.97 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 52.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 865.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 39.24 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 88.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 910.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.92 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 97.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 917.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 53.90 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 81.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 872.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 46.59 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 82.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 917.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 47.08 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 85.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 855.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 54.68 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 813.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.09 seconds, 11.19 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 79.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 877.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 38.66 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 57.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 812.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 38.63 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 81.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 894.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 45.76 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 89.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 909.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 45.43 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 80.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 902.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.58 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 62.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 887.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 39.67 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 88.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 880.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.74 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 71.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 900.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 41.81 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 93.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 902.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 51.13 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 78.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 864.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 47.04 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 95.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 911.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 52.74 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 99.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 909.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 54.27 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 69.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 848.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.54 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 63.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 848.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.55 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 42.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 873.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.04 seconds, 24.22 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 98.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 905.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.67 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 58.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 785.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 38.77 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 34.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 764.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.04 seconds, 23.68 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 74.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 912.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 36.90 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 32.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 886.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.05 seconds, 19.73 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 88.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 904.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 47.48 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 95.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 910.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 52.79 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 75.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 910.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 39.07 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 87.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 811.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 47.73 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 95.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 914.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 53.02 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 89.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 904.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.55 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 35.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 762.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.04 seconds, 25.44 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 89.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 902.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.62 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 46.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 896.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 35.72 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 658.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.09 seconds, 11.64 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 86.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 881.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.04 seconds, 25.43 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 86.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 871.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.10 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 86.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 909.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 43.57 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 91.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 904.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.35 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 50.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 839.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 34.56 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 83.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 908.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 48.79 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 89.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 907.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.43 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 50.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 795.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 34.88 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 41.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 791.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.03 seconds, 29.04 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 84.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 914.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 49.08 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 92.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 907.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.12 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 90.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 909.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 50.41 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 77.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 859.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.02 seconds, 44.99 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 35.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 763.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.04 seconds, 25.14 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer_gt_path = '/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_gt.json'\n",
    "answer_preds_llama = '/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_llama3.1.json'\n",
    "# model = 'gemma2'\n",
    "# model = 'dirty'\n",
    "# model = 'llama3.1'\n",
    "model = 'mistral'\n",
    "answer_preds = f'/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_{model}.json'\n",
    "# answer_preds = f'/projects/bces/lanl2/LLM4DC/evaluation/answer_1-110_dirty.json'\n",
    "eval_answer_results = eval_answers(answer_gt_path, answer_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[0.9511916637420654]</td>\n",
       "      <td>[0.8949240446090698]</td>\n",
       "      <td>[0.9222003221511841]</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[0.9999998211860657]</td>\n",
       "      <td>[0.9999998211860657]</td>\n",
       "      <td>[0.9999998211860657]</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[0.874943733215332]</td>\n",
       "      <td>[0.7801971435546875]</td>\n",
       "      <td>[0.824858546257019]</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356275</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[0.9047510623931885]</td>\n",
       "      <td>[0.8725006580352783]</td>\n",
       "      <td>[0.8883332014083862]</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990506</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>[0.9872503876686096]</td>\n",
       "      <td>[0.988763689994812]</td>\n",
       "      <td>[0.9880064129829407]</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  semantic_similarity  precision  recall      f1  \\\n",
       "62       0.0             0.808511     0.0000  0.0000  0.0000   \n",
       "63       1.0             1.000000     1.0000  1.0000  1.0000   \n",
       "64       0.0             0.000000     0.0000  0.0000  0.0000   \n",
       "65       0.0             0.356275     0.0000  0.0000  0.0000   \n",
       "66       0.0             0.990506     0.8375  0.8375  0.8375   \n",
       "\n",
       "             bertscore_p           bertscore_r          bertscore_f1  pp_id  \n",
       "62  [0.9511916637420654]  [0.8949240446090698]  [0.9222003221511841]    106  \n",
       "63  [0.9999998211860657]  [0.9999998211860657]  [0.9999998211860657]    107  \n",
       "64   [0.874943733215332]  [0.7801971435546875]   [0.824858546257019]    108  \n",
       "65  [0.9047510623931885]  [0.8725006580352783]  [0.8883332014083862]    109  \n",
       "66  [0.9872503876686096]   [0.988763689994812]  [0.9880064129829407]    110  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_answer_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistral'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_answer_results['bertscore_p'] = eval_answer_results['bertscore_p'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else None)\n",
    "eval_answer_results['bertscore_r'] = eval_answer_results['bertscore_r'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else None)\n",
    "eval_answer_results['bertscore_f1'] = eval_answer_results['bertscore_f1'].apply(lambda x: sum(x)/len(x) if len(x) > 0 else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3.1'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_answer_results.to_csv(f'/projects/bces/lanl2/LLM4DC/evaluation/{model}_answer_result.csv')\n",
    "# eval_answer_results.to_csv(f'/projects/bces/lanl2/LLM4DC/evaluation/dirty_answer_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'llama3.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_answer_results = pd.read_csv(f'/projects/bces/lanl2/LLM4DC/evaluation/{model}_answer_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.742243</td>\n",
       "      <td>0.615287</td>\n",
       "      <td>0.622741</td>\n",
       "      <td>0.610498</td>\n",
       "      <td>0.950686</td>\n",
       "      <td>0.947142</td>\n",
       "      <td>0.948540</td>\n",
       "      <td>58.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.485037</td>\n",
       "      <td>0.501017</td>\n",
       "      <td>0.354760</td>\n",
       "      <td>0.459467</td>\n",
       "      <td>0.454278</td>\n",
       "      <td>0.451074</td>\n",
       "      <td>0.131489</td>\n",
       "      <td>0.135712</td>\n",
       "      <td>0.132678</td>\n",
       "      <td>35.047290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944181</td>\n",
       "      <td>0.942289</td>\n",
       "      <td>0.939296</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995349</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   accuracy  semantic_similarity  precision     recall  \\\n",
       "count   67.000000  67.000000            67.000000  67.000000  67.000000   \n",
       "mean    33.000000   0.447761             0.742243   0.615287   0.622741   \n",
       "std     19.485037   0.501017             0.354760   0.459467   0.454278   \n",
       "min      0.000000   0.000000             0.000000   0.000000   0.000000   \n",
       "25%     16.500000   0.000000             0.500585   0.000000   0.000000   \n",
       "50%     33.000000   0.000000             0.995349   0.939394   0.950000   \n",
       "75%     49.500000   1.000000             1.000000   1.000000   1.000000   \n",
       "max     66.000000   1.000000             1.000000   1.000000   1.000000   \n",
       "\n",
       "              f1  bertscore_p  bertscore_r  bertscore_f1       pp_id  \n",
       "count  67.000000    67.000000    67.000000     67.000000   67.000000  \n",
       "mean    0.610498     0.950686     0.947142      0.948540   58.074627  \n",
       "std     0.451074     0.131489     0.135712      0.132678   35.047290  \n",
       "min     0.000000     0.000000     0.000000      0.000000    1.000000  \n",
       "25%     0.000000     0.944181     0.942289      0.939296   31.500000  \n",
       "50%     0.900000     0.999803     0.999803      0.999803   66.000000  \n",
       "75%     1.000000     1.000000     1.000000      1.000000   88.000000  \n",
       "max     1.000000     1.000000     1.000000      1.000000  110.000000  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_answer_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577642/2424205661.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ppp_results = eval_answer_results[eval_answer_results['pp_id'] >= 62][eval_answer_results['pp_id'] <=91]\n"
     ]
    }
   ],
   "source": [
    "ppp_results = eval_answer_results[eval_answer_results['pp_id'] >= 62][eval_answer_results['pp_id'] <=91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_results = eval_answer_results[eval_answer_results['pp_id'] >= 92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577642/3367146683.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  chi_results = eval_answer_results[eval_answer_results['pp_id'] >= 31][eval_answer_results['pp_id'] <=61]\n"
     ]
    }
   ],
   "source": [
    "chi_results = eval_answer_results[eval_answer_results['pp_id'] >= 31][eval_answer_results['pp_id'] <=61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_results = eval_answer_results[eval_answer_results['pp_id'] < 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.876176</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>0.721861</td>\n",
       "      <td>0.716450</td>\n",
       "      <td>0.975988</td>\n",
       "      <td>0.976735</td>\n",
       "      <td>0.976117</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.493587</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.219952</td>\n",
       "      <td>0.428810</td>\n",
       "      <td>0.422058</td>\n",
       "      <td>0.425785</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>0.041219</td>\n",
       "      <td>7.438638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800825</td>\n",
       "      <td>0.887636</td>\n",
       "      <td>0.857735</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.821821</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.972412</td>\n",
       "      <td>0.972412</td>\n",
       "      <td>0.972412</td>\n",
       "      <td>67.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   accuracy  semantic_similarity  precision     recall  \\\n",
       "count   22.000000  22.000000            22.000000  22.000000  22.000000   \n",
       "mean    39.500000   0.636364             0.876176   0.713120   0.721861   \n",
       "std      6.493587   0.492366             0.219952   0.428810   0.422058   \n",
       "min     29.000000   0.000000             0.266667   0.000000   0.000000   \n",
       "25%     34.250000   0.000000             0.821821   0.397436   0.541667   \n",
       "50%     39.500000   1.000000             1.000000   1.000000   1.000000   \n",
       "75%     44.750000   1.000000             1.000000   1.000000   1.000000   \n",
       "max     50.000000   1.000000             1.000000   1.000000   1.000000   \n",
       "\n",
       "              f1  bertscore_p  bertscore_r  bertscore_f1      pp_id  \n",
       "count  22.000000    22.000000    22.000000     22.000000  22.000000  \n",
       "mean    0.716450     0.975988     0.976735      0.976117  73.000000  \n",
       "std     0.425785     0.047341     0.038679      0.041219   7.438638  \n",
       "min     0.000000     0.800825     0.887636      0.857735  62.000000  \n",
       "25%     0.452381     0.972412     0.972412      0.972412  67.250000  \n",
       "50%     1.000000     1.000000     1.000000      1.000000  72.500000  \n",
       "75%     1.000000     1.000000     1.000000      1.000000  77.750000  \n",
       "max     1.000000     1.000000     1.000000      1.000000  89.000000  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppp_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>58.500000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.803480</td>\n",
       "      <td>0.641427</td>\n",
       "      <td>0.627812</td>\n",
       "      <td>0.633603</td>\n",
       "      <td>0.903831</td>\n",
       "      <td>0.902170</td>\n",
       "      <td>0.902739</td>\n",
       "      <td>101.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.760952</td>\n",
       "      <td>0.478714</td>\n",
       "      <td>0.348544</td>\n",
       "      <td>0.450720</td>\n",
       "      <td>0.447672</td>\n",
       "      <td>0.448163</td>\n",
       "      <td>0.246193</td>\n",
       "      <td>0.251014</td>\n",
       "      <td>0.248221</td>\n",
       "      <td>5.65059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.815027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929033</td>\n",
       "      <td>0.951412</td>\n",
       "      <td>0.940082</td>\n",
       "      <td>98.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995650</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.989155</td>\n",
       "      <td>102.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>106.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   accuracy  semantic_similarity  precision     recall  \\\n",
       "count   16.000000  16.000000            16.000000  16.000000  16.000000   \n",
       "mean    58.500000   0.312500             0.803480   0.641427   0.627812   \n",
       "std      4.760952   0.478714             0.348544   0.450720   0.447672   \n",
       "min     51.000000   0.000000             0.000000   0.000000   0.000000   \n",
       "25%     54.750000   0.000000             0.815027   0.000000   0.000000   \n",
       "50%     58.500000   0.000000             0.995650   0.887500   0.887500   \n",
       "75%     62.250000   1.000000             1.000000   1.000000   1.000000   \n",
       "max     66.000000   1.000000             1.000000   1.000000   1.000000   \n",
       "\n",
       "              f1  bertscore_p  bertscore_r  bertscore_f1      pp_id  \n",
       "count  16.000000    16.000000    16.000000     16.000000   16.00000  \n",
       "mean    0.633603     0.903831     0.902170      0.902739  101.93750  \n",
       "std     0.448163     0.246193     0.251014      0.248221    5.65059  \n",
       "min     0.000000     0.000000     0.000000      0.000000   92.00000  \n",
       "25%     0.000000     0.929033     0.951412      0.940082   98.75000  \n",
       "50%     0.887500     0.987596     0.990719      0.989155  102.50000  \n",
       "75%     1.000000     1.000000     1.000000      1.000000  106.25000  \n",
       "max     1.000000     1.000000     1.000000      1.000000  110.00000  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dish_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.561882</td>\n",
       "      <td>0.532670</td>\n",
       "      <td>0.596731</td>\n",
       "      <td>0.536699</td>\n",
       "      <td>0.973148</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>0.977065</td>\n",
       "      <td>9.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.760952</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.442968</td>\n",
       "      <td>0.484167</td>\n",
       "      <td>0.488279</td>\n",
       "      <td>0.465394</td>\n",
       "      <td>0.061415</td>\n",
       "      <td>0.038492</td>\n",
       "      <td>0.048293</td>\n",
       "      <td>5.667157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.815612</td>\n",
       "      <td>0.885391</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995815</td>\n",
       "      <td>0.996442</td>\n",
       "      <td>0.996128</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.565951</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  accuracy  semantic_similarity  precision     recall  \\\n",
       "count   16.000000    16.000            16.000000  16.000000  16.000000   \n",
       "mean     7.500000     0.375             0.561882   0.532670   0.596731   \n",
       "std      4.760952     0.500             0.442968   0.484167   0.488279   \n",
       "min      0.000000     0.000             0.000000   0.000000   0.000000   \n",
       "25%      3.750000     0.000             0.000000   0.000000   0.000000   \n",
       "50%      7.500000     0.000             0.565951   0.636364   0.984375   \n",
       "75%     11.250000     1.000             1.000000   1.000000   1.000000   \n",
       "max     15.000000     1.000             1.000000   1.000000   1.000000   \n",
       "\n",
       "              f1  bertscore_p  bertscore_r  bertscore_f1      pp_id  \n",
       "count  16.000000    16.000000    16.000000     16.000000  16.000000  \n",
       "mean    0.536699     0.973148     0.981845      0.977065   9.375000  \n",
       "std     0.465394     0.061415     0.038492      0.048293   5.667157  \n",
       "min     0.000000     0.815612     0.885391      0.853846   1.000000  \n",
       "25%     0.000000     0.995815     0.996442      0.996128   4.750000  \n",
       "50%     0.616667     0.999808     0.999808      0.999808   8.500000  \n",
       "75%     1.000000     1.000000     1.000000      1.000000  14.250000  \n",
       "max     1.000000     1.000000     1.000000      1.000000  18.000000  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.616404</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.357692</td>\n",
       "      <td>0.370879</td>\n",
       "      <td>0.945635</td>\n",
       "      <td>0.922062</td>\n",
       "      <td>0.933221</td>\n",
       "      <td>38.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.438529</td>\n",
       "      <td>0.344286</td>\n",
       "      <td>0.473665</td>\n",
       "      <td>0.438675</td>\n",
       "      <td>0.442612</td>\n",
       "      <td>0.065947</td>\n",
       "      <td>0.095499</td>\n",
       "      <td>0.080116</td>\n",
       "      <td>6.260376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.734762</td>\n",
       "      <td>0.773377</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905686</td>\n",
       "      <td>0.861316</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967485</td>\n",
       "      <td>0.963320</td>\n",
       "      <td>0.965398</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  semantic_similarity  precision     recall         f1  \\\n",
       "count  13.000000            13.000000  13.000000  13.000000  13.000000   \n",
       "mean    0.230769             0.616404   0.403846   0.357692   0.370879   \n",
       "std     0.438529             0.344286   0.473665   0.438675   0.442612   \n",
       "min     0.000000             0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.000000             0.363636   0.000000   0.000000   0.000000   \n",
       "50%     0.000000             0.666667   0.000000   0.000000   0.000000   \n",
       "75%     0.000000             0.918919   1.000000   0.750000   0.750000   \n",
       "max     1.000000             1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "       bertscore_p  bertscore_r  bertscore_f1      pp_id  \n",
       "count    13.000000    13.000000     13.000000  13.000000  \n",
       "mean      0.945635     0.922062      0.933221  38.769231  \n",
       "std       0.065947     0.095499      0.080116   6.260376  \n",
       "min       0.816275     0.734762      0.773377  31.000000  \n",
       "25%       0.905686     0.861316      0.904977  34.000000  \n",
       "50%       0.967485     0.963320      0.965398  38.000000  \n",
       "75%       0.999451     0.999451      0.999451  41.000000  \n",
       "max       1.000000     1.000000      1.000000  52.000000  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_answer_results = pd.DataFrame(eval_answer_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(21.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_answer_results['accuracy'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444066</td>\n",
       "      <td>0.442419</td>\n",
       "      <td>0.442747</td>\n",
       "      <td>58.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.461057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485182</td>\n",
       "      <td>0.484086</td>\n",
       "      <td>0.483975</td>\n",
       "      <td>35.047290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  semantic_similarity  precision     recall         f1  \\\n",
       "count  67.000000                 67.0  67.000000  67.000000  67.000000   \n",
       "mean    0.298507                  0.0   0.444066   0.442419   0.442747   \n",
       "std     0.461057                  0.0   0.485182   0.484086   0.483975   \n",
       "min     0.000000                  0.0   0.000000   0.000000   0.000000   \n",
       "25%     0.000000                  0.0   0.000000   0.000000   0.000000   \n",
       "50%     0.000000                  0.0   0.000000   0.000000   0.000000   \n",
       "75%     1.000000                  0.0   1.000000   1.000000   1.000000   \n",
       "max     1.000000                  0.0   1.000000   1.000000   1.000000   \n",
       "\n",
       "            pp_id  \n",
       "count   67.000000  \n",
       "mean    58.074627  \n",
       "std     35.047290  \n",
       "min      1.000000  \n",
       "25%     31.500000  \n",
       "50%     66.000000  \n",
       "75%     88.000000  \n",
       "max    110.000000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_answer_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer eval ttest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_answer_result = pd.read_csv('/projects/bces/lanl2/LLM4DC/evaluation/dirty_answer_result.csv')\n",
    "gemma2_answer_result = pd.read_csv('/projects/bces/lanl2/LLM4DC/evaluation/gemma2_answer_result.csv')\n",
    "llama_answer_result = pd.read_csv('/projects/bces/lanl2/LLM4DC/evaluation/llama3.1_answer_result.csv')\n",
    "mistral_answer_result = pd.read_csv('/projects/bces/lanl2/LLM4DC/evaluation/mistral_answer_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_result = llama_answer_result.merge(gemma2_answer_result, on='pp_id', how='left', suffixes=('_llama', '_gemma2')).merge(mistral_answer_result, on='pp_id', how='left', suffixes=('', '_mistral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_result = answer_result.merge(dirty_answer_result, on='pp_id', how='left', suffixes=('', '_dirty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_llama</th>\n",
       "      <th>accuracy_llama</th>\n",
       "      <th>semantic_similarity_llama</th>\n",
       "      <th>precision_llama</th>\n",
       "      <th>recall_llama</th>\n",
       "      <th>f1_llama</th>\n",
       "      <th>bertscore_p_llama</th>\n",
       "      <th>bertscore_r_llama</th>\n",
       "      <th>bertscore_f1_llama</th>\n",
       "      <th>pp_id</th>\n",
       "      <th>...</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>Unnamed: 0_dirty</th>\n",
       "      <th>accuracy_dirty</th>\n",
       "      <th>semantic_similarity_dirty</th>\n",
       "      <th>precision_dirty</th>\n",
       "      <th>recall_dirty</th>\n",
       "      <th>f1_dirty</th>\n",
       "      <th>bertscore_p_dirty</th>\n",
       "      <th>bertscore_r_dirty</th>\n",
       "      <th>bertscore_f1_dirty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998309</td>\n",
       "      <td>0.998309</td>\n",
       "      <td>0.998309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.999349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_llama  accuracy_llama  semantic_similarity_llama  \\\n",
       "0                 0             1.0                        1.0   \n",
       "1                 1             1.0                        1.0   \n",
       "2                 2             0.0                        0.0   \n",
       "3                 3             0.0                        0.0   \n",
       "4                 4             0.0                        0.0   \n",
       "\n",
       "   precision_llama  recall_llama  f1_llama  bertscore_p_llama  \\\n",
       "0              1.0           1.0       1.0           1.000000   \n",
       "1              1.0           1.0       1.0           1.000000   \n",
       "2              0.0           0.0       0.0           0.999803   \n",
       "3              0.0           0.0       0.0           0.999268   \n",
       "4              0.0           0.0       0.0           0.999813   \n",
       "\n",
       "   bertscore_r_llama  bertscore_f1_llama  pp_id  ...  bertscore_f1  \\\n",
       "0           1.000000            1.000000      1  ...      1.000000   \n",
       "1           1.000000            1.000000      2  ...      1.000000   \n",
       "2           0.999803            0.999803      3  ...      0.999477   \n",
       "3           0.999268            0.999268      4  ...      0.999349   \n",
       "4           0.999813            0.999813      5  ...      0.999813   \n",
       "\n",
       "   Unnamed: 0_dirty  accuracy_dirty  semantic_similarity_dirty  \\\n",
       "0                 0             1.0                        1.0   \n",
       "1                 1             1.0                        1.0   \n",
       "2                 2             0.0                        0.0   \n",
       "3                 3             0.0                        0.5   \n",
       "4                 4             0.0                        0.0   \n",
       "\n",
       "   precision_dirty  recall_dirty  f1_dirty  bertscore_p_dirty  \\\n",
       "0              1.0           1.0       1.0           1.000000   \n",
       "1              1.0           1.0       1.0           1.000000   \n",
       "2              0.0           0.0       0.0           0.998309   \n",
       "3              0.0           0.0       0.0           0.999349   \n",
       "4              0.0           0.0       0.0           0.999813   \n",
       "\n",
       "   bertscore_r_dirty  bertscore_f1_dirty  \n",
       "0           1.000000            1.000000  \n",
       "1           1.000000            1.000000  \n",
       "2           0.998309            0.998309  \n",
       "3           0.999349            0.999349  \n",
       "4           0.999813            0.999813  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = ['accuracy','semantic_similarity', 'precision', 'recall', 'f1', 'bertscore_p', 'bertscore_r','bertscore_f1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_result = []\n",
    "for m in metric_names:\n",
    "    model_list = ['llama', 'gemma2', 'mistral', 'dirty']\n",
    "    llama_result = stats.ttest_rel(answer_result[f'{m}_dirty'].values, answer_result[f'{m}_llama'].values)\n",
    "    gemma_result = stats.ttest_rel(answer_result[f'{m}_dirty'].values, answer_result[f'{m}_gemma2'].values)\n",
    "    # print(answer_result[f'{m}_llama'].values)\n",
    "    mistral_result = stats.ttest_ind(answer_result[f'{m}_dirty'].values, answer_result[f'{m}'].values)\n",
    "    ttest_result.append({f'{m}':[llama_result.pvalue.item(), gemma_result.pvalue.item(), mistral_result.pvalue.item()]})\n",
    "    # print(gemma_result)\n",
    "    # print(mistral_result)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_answer(answer_result):\n",
    "    ttest_result = []\n",
    "    for m in metric_names:\n",
    "        model_list = ['llama', 'gemma2', 'mistral', 'dirty']\n",
    "        llama_result = stats.ttest_rel(answer_result[f'{m}_dirty'].values, answer_result[f'{m}_llama'].values)\n",
    "        gemma_result = stats.ttest_rel(answer_result[f'{m}_dirty'].values, answer_result[f'{m}_gemma2'].values)\n",
    "        # print(answer_result[f'{m}_llama'].values)\n",
    "        mistral_result = stats.ttest_ind(answer_result[f'{m}_dirty'].values, answer_result[f'{m}'].values)\n",
    "        ttest_result.append({f'{m}':[llama_result.pvalue.item(), gemma_result.pvalue.item(), mistral_result.pvalue.item()]})\n",
    "    combined_data = {k: v for d in ttest_result for k, v in d.items()}\n",
    "\n",
    "    ttest_result = pd.DataFrame(combined_data)\n",
    "    return ttest_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = {k: v for d in ttest_result for k, v in d.items()}\n",
    "\n",
    "ttest_result = pd.DataFrame(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.409465</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>0.971096</td>\n",
       "      <td>0.945330</td>\n",
       "      <td>0.993090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798445</td>\n",
       "      <td>0.502049</td>\n",
       "      <td>0.553362</td>\n",
       "      <td>0.589685</td>\n",
       "      <td>0.546391</td>\n",
       "      <td>0.383719</td>\n",
       "      <td>0.826350</td>\n",
       "      <td>0.769054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373586</td>\n",
       "      <td>0.966990</td>\n",
       "      <td>0.920003</td>\n",
       "      <td>0.790593</td>\n",
       "      <td>0.844258</td>\n",
       "      <td>0.873258</td>\n",
       "      <td>0.592786</td>\n",
       "      <td>0.701420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  semantic_similarity  precision    recall        f1  bertscore_p  \\\n",
       "0  0.409465             0.016196   0.010599  0.004224  0.009252     0.971096   \n",
       "1  0.798445             0.502049   0.553362  0.589685  0.546391     0.383719   \n",
       "2  0.373586             0.966990   0.920003  0.790593  0.844258     0.873258   \n",
       "\n",
       "   bertscore_r  bertscore_f1  \n",
       "0     0.945330      0.993090  \n",
       "1     0.826350      0.769054  \n",
       "2     0.592786      0.701420  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577642/3278763139.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ppp_results = answer_result[answer_result['pp_id'] >= 62][answer_result['pp_id'] <=91]\n"
     ]
    }
   ],
   "source": [
    "ppp_results = answer_result[answer_result['pp_id'] >= 62][answer_result['pp_id'] <=91]\n",
    "ppp_ttest = ttest_answer(ppp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.665194</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.432985</td>\n",
       "      <td>0.521864</td>\n",
       "      <td>0.468124</td>\n",
       "      <td>0.332356</td>\n",
       "      <td>0.588604</td>\n",
       "      <td>0.430670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328695</td>\n",
       "      <td>0.188103</td>\n",
       "      <td>0.291698</td>\n",
       "      <td>0.204980</td>\n",
       "      <td>0.253631</td>\n",
       "      <td>0.164633</td>\n",
       "      <td>0.602721</td>\n",
       "      <td>0.312134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555640</td>\n",
       "      <td>0.991541</td>\n",
       "      <td>0.584520</td>\n",
       "      <td>0.548433</td>\n",
       "      <td>0.568577</td>\n",
       "      <td>0.751530</td>\n",
       "      <td>0.622030</td>\n",
       "      <td>0.671129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  semantic_similarity  precision    recall        f1  bertscore_p  \\\n",
       "0  0.665194             0.071289   0.432985  0.521864  0.468124     0.332356   \n",
       "1  0.328695             0.188103   0.291698  0.204980  0.253631     0.164633   \n",
       "2  0.555640             0.991541   0.584520  0.548433  0.568577     0.751530   \n",
       "\n",
       "   bertscore_r  bertscore_f1  \n",
       "0     0.588604      0.430670  \n",
       "1     0.602721      0.312134  \n",
       "2     0.622030      0.671129  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppp_ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.580471</td>\n",
       "      <td>0.066705</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.044881</td>\n",
       "      <td>0.042673</td>\n",
       "      <td>0.774325</td>\n",
       "      <td>0.862575</td>\n",
       "      <td>0.817219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718301</td>\n",
       "      <td>0.462110</td>\n",
       "      <td>0.523248</td>\n",
       "      <td>0.523248</td>\n",
       "      <td>0.523248</td>\n",
       "      <td>0.672301</td>\n",
       "      <td>0.897460</td>\n",
       "      <td>0.910012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.680930</td>\n",
       "      <td>0.445805</td>\n",
       "      <td>0.787698</td>\n",
       "      <td>0.787698</td>\n",
       "      <td>0.787698</td>\n",
       "      <td>0.714108</td>\n",
       "      <td>0.377144</td>\n",
       "      <td>0.505227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  semantic_similarity  precision    recall        f1  bertscore_p  \\\n",
       "0  0.580471             0.066705   0.040415  0.044881  0.042673     0.774325   \n",
       "1  0.718301             0.462110   0.523248  0.523248  0.523248     0.672301   \n",
       "2  0.680930             0.445805   0.787698  0.787698  0.787698     0.714108   \n",
       "\n",
       "   bertscore_r  bertscore_f1  \n",
       "0     0.862575      0.817219  \n",
       "1     0.897460      0.910012  \n",
       "2     0.377144      0.505227  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dish_result= answer_result[answer_result['pp_id'] >= 92]\n",
    "dish_ttest = ttest_answer(dish_result)\n",
    "dish_ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.580471</td>\n",
       "      <td>0.599889</td>\n",
       "      <td>0.890791</td>\n",
       "      <td>0.141362</td>\n",
       "      <td>0.825616</td>\n",
       "      <td>0.449021</td>\n",
       "      <td>0.794551</td>\n",
       "      <td>0.713241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.580471</td>\n",
       "      <td>0.288723</td>\n",
       "      <td>0.839887</td>\n",
       "      <td>0.988945</td>\n",
       "      <td>0.949398</td>\n",
       "      <td>0.283264</td>\n",
       "      <td>0.347259</td>\n",
       "      <td>0.314584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.481310</td>\n",
       "      <td>0.919102</td>\n",
       "      <td>0.924996</td>\n",
       "      <td>0.944534</td>\n",
       "      <td>0.935819</td>\n",
       "      <td>0.629457</td>\n",
       "      <td>0.729884</td>\n",
       "      <td>0.688068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  semantic_similarity  precision    recall        f1  bertscore_p  \\\n",
       "0  0.580471             0.599889   0.890791  0.141362  0.825616     0.449021   \n",
       "1  0.580471             0.288723   0.839887  0.988945  0.949398     0.283264   \n",
       "2  0.481310             0.919102   0.924996  0.944534  0.935819     0.629457   \n",
       "\n",
       "   bertscore_r  bertscore_f1  \n",
       "0     0.794551      0.713241  \n",
       "1     0.347259      0.314584  \n",
       "2     0.729884      0.688068  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_results = answer_result[answer_result['pp_id'] < 31]\n",
    "menu_ttest = ttest_answer(menu_results)\n",
    "menu_ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577642/3533590064.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  chi_results = answer_result[answer_result['pp_id'] >= 31][answer_result['pp_id'] <=61]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165407</td>\n",
       "      <td>0.196659</td>\n",
       "      <td>0.052011</td>\n",
       "      <td>0.087528</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.212637</td>\n",
       "      <td>0.808143</td>\n",
       "      <td>0.504440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337049</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.375308</td>\n",
       "      <td>0.433098</td>\n",
       "      <td>0.391871</td>\n",
       "      <td>0.642579</td>\n",
       "      <td>0.931535</td>\n",
       "      <td>0.876010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525309</td>\n",
       "      <td>0.372043</td>\n",
       "      <td>0.559367</td>\n",
       "      <td>0.474808</td>\n",
       "      <td>0.523184</td>\n",
       "      <td>0.682367</td>\n",
       "      <td>0.608927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  semantic_similarity  precision    recall        f1  bertscore_p  \\\n",
       "0  0.165407             0.196659   0.052011  0.087528  0.061788     0.212637   \n",
       "1  0.337049             0.875186   0.375308  0.433098  0.391871     0.642579   \n",
       "2  1.000000             0.525309   0.372043  0.559367  0.474808     0.523184   \n",
       "\n",
       "   bertscore_r  bertscore_f1  \n",
       "0     0.808143      0.504440  \n",
       "1     0.931535      0.876010  \n",
       "2     0.682367      0.608927  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_results = answer_result[answer_result['pp_id'] >= 31][answer_result['pp_id'] <=61]\n",
    "chi_ttest = ttest_answer(chi_results)\n",
    "chi_ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577642/2612646877.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ppp_results = answer_result[answer_result['pp_id'] >= 62][answer_result['pp_id'] <=91]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>bertscore_p</th>\n",
       "      <th>bertscore_r</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.665194</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.432985</td>\n",
       "      <td>0.521864</td>\n",
       "      <td>0.468124</td>\n",
       "      <td>0.332356</td>\n",
       "      <td>0.588604</td>\n",
       "      <td>0.430670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328695</td>\n",
       "      <td>0.188103</td>\n",
       "      <td>0.291698</td>\n",
       "      <td>0.204980</td>\n",
       "      <td>0.253631</td>\n",
       "      <td>0.164633</td>\n",
       "      <td>0.602721</td>\n",
       "      <td>0.312134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555640</td>\n",
       "      <td>0.991541</td>\n",
       "      <td>0.584520</td>\n",
       "      <td>0.548433</td>\n",
       "      <td>0.568577</td>\n",
       "      <td>0.751530</td>\n",
       "      <td>0.622030</td>\n",
       "      <td>0.671129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  semantic_similarity  precision    recall        f1  bertscore_p  \\\n",
       "0  0.665194             0.071289   0.432985  0.521864  0.468124     0.332356   \n",
       "1  0.328695             0.188103   0.291698  0.204980  0.253631     0.164633   \n",
       "2  0.555640             0.991541   0.584520  0.548433  0.568577     0.751530   \n",
       "\n",
       "   bertscore_r  bertscore_f1  \n",
       "0     0.588604      0.430670  \n",
       "1     0.602721      0.312134  \n",
       "2     0.622030      0.671129  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppp_results = answer_result[answer_result['pp_id'] >= 62][answer_result['pp_id'] <=91]\n",
    "ppp_ttest = ttest_answer(ppp_results)\n",
    "ppp_ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_custom_string(data):\n",
    "    # Serialize JSON with indentation for readability within each nested structure\n",
    "    json_str = json.dumps(data, indent=None, separators=(r'')\n",
    "    \n",
    "    # Insert newline only after each top-level key-value pair\n",
    "    # This keeps inner lists and dicts intact without adding extra line breaks\n",
    "    formatted_str = json_str[1:-1].replace('\", \"', '\",\\n\"')  # Exclude outer braces for custom formatting\n",
    "    return f\"{{\\n{formatted_str}\\n}}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(data, indent=1, sepera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'table_caption': 'A mix of simple bibliographic description of the menus', 'columns': ['id', 'name', 'sponsor', 'event', 'venue', 'place', 'physical_description', 'occasion', 'notes', 'call_number', 'keywords', 'language', 'date', 'location', 'location_type', 'currency', 'currency_symbol', 'status', 'page_count', 'dish_count'], 'table_column_priority': [['id', '12579', '25121', '21960'], ['name', '', '', ''], ['sponsor', 'TRUSTEES OF THE MISSOURI BOTANICAL GARDEN', 'HOLLAND HOUSE', 'BATTERY PARK HOTEL'], ['event', '11TH ANNUAL BANQUET', 'LUNCHEON', 'CHRISTMAS DINNER'], ['venue', 'PROF;', 'COMMERCIAL', 'COMMERCIAL'], ['place', 'SOUTHERN HOTEL,ST. LOUIS,MO.', '', 'ASHVILLE, NC'], ['physical_description', 'BROADSIDE; ILLUS; 5.5 X 8.75;', 'CARD;6X8.75;', 'BOOKLET; ILLUS; COL; 6 X 8;'], ['occasion', 'ANNUAL', 'DAILY;', 'RELIGIOUS HOLIDAY'], ['notes', 'WINES LISTED FOR EACH COURSE;', 'ENGLISH ON ONE SIDE,FRENCH ON ONE SIDE;', 'PRINTED ON PARCHMENT-LIKE PAPER; RED LION; DRAWING OF HOTEL; TIED WITH TWINE AND SEALING WAX; MOST OF BOOKLET CONSISTS OF INFORMATION AND PRAISE ABOUT THE HOTEL;'], ['call_number', '1900-2627', '1900-517', '1898-432'], ['keywords', '', '', ''], ['language', '', '', ''], ['date', '1900-03-31', '1900-01-25', '1898-12-25'], ['location', 'Trustees Of The Missouri Botanical Garden', 'Holland House', 'Battery Park Hotel'], ['location_type', '', '', ''], ['currency', '', 'Dollars', ''], ['currency_symbol', '', '$', ''], ['status', 'complete', 'complete', 'complete'], ['page_count', '2', '2', '16'], ['dish_count', '22.0', '546.0', '28.0']]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_str = '\\{\\n'\n",
    "for key, value in data.items():\n",
    "    if key in ['table_caption', 'columns']:\n",
    "        data_str += f'{key}: {value},\\n'\n",
    "    else:\n",
    "        data_str += key + ': [\\n'\n",
    "        for l in value:\n",
    "            data_str += f'  {l},\\n'\n",
    "data_str += '  ]\\n}'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n'\n",
      " 'table_caption: A mix of simple bibliographic description of the menus,\\n'\n",
      " \"columns: ['id', 'name', 'sponsor', 'event', 'venue', 'place', \"\n",
      " \"'physical_description', 'occasion', 'notes', 'call_number', 'keywords', \"\n",
      " \"'language', 'date', 'location', 'location_type', 'currency', \"\n",
      " \"'currency_symbol', 'status', 'page_count', 'dish_count'],\\n\"\n",
      " 'table_column_priority: [\\n'\n",
      " \"  ['id', '12579', '25121', '21960'],\\n\"\n",
      " \"  ['name', '', '', ''],\\n\"\n",
      " \"  ['sponsor', 'TRUSTEES OF THE MISSOURI BOTANICAL GARDEN', 'HOLLAND HOUSE', \"\n",
      " \"'BATTERY PARK HOTEL'],\\n\"\n",
      " \"  ['event', '11TH ANNUAL BANQUET', 'LUNCHEON', 'CHRISTMAS DINNER'],\\n\"\n",
      " \"  ['venue', 'PROF;', 'COMMERCIAL', 'COMMERCIAL'],\\n\"\n",
      " \"  ['place', 'SOUTHERN HOTEL,ST. LOUIS,MO.', '', 'ASHVILLE, NC'],\\n\"\n",
      " \"  ['physical_description', 'BROADSIDE; ILLUS; 5.5 X 8.75;', 'CARD;6X8.75;', \"\n",
      " \"'BOOKLET; ILLUS; COL; 6 X 8;'],\\n\"\n",
      " \"  ['occasion', 'ANNUAL', 'DAILY;', 'RELIGIOUS HOLIDAY'],\\n\"\n",
      " \"  ['notes', 'WINES LISTED FOR EACH COURSE;', 'ENGLISH ON ONE SIDE,FRENCH ON \"\n",
      " \"ONE SIDE;', 'PRINTED ON PARCHMENT-LIKE PAPER; RED LION; DRAWING OF HOTEL; \"\n",
      " 'TIED WITH TWINE AND SEALING WAX; MOST OF BOOKLET CONSISTS OF INFORMATION AND '\n",
      " \"PRAISE ABOUT THE HOTEL;'],\\n\"\n",
      " \"  ['call_number', '1900-2627', '1900-517', '1898-432'],\\n\"\n",
      " \"  ['keywords', '', '', ''],\\n\"\n",
      " \"  ['language', '', '', ''],\\n\"\n",
      " \"  ['date', '1900-03-31', '1900-01-25', '1898-12-25'],\\n\"\n",
      " \"  ['location', 'Trustees Of The Missouri Botanical Garden', 'Holland House', \"\n",
      " \"'Battery Park Hotel'],\\n\"\n",
      " \"  ['location_type', '', '', ''],\\n\"\n",
      " \"  ['currency', '', 'Dollars', ''],\\n\"\n",
      " \"  ['currency_symbol', '', '$', ''],\\n\"\n",
      " \"  ['status', 'complete', 'complete', 'complete'],\\n\"\n",
      " \"  ['page_count', '2', '2', '16'],\\n\"\n",
      " \"  ['dish_count', '22.0', '546.0', '28.0'],\\n\"\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n'\n",
      " '\"table_caption\": \"A mix of simple bibliographic description of the '\n",
      " 'menus\",\"columns\": '\n",
      " '[\"id\",\"name\",\"sponsor\",\"event\",\"venue\",\"place\",\"physical_description\",\"occasion\",\"notes\",\"call_number\",\"keywords\",\"language\",\"date\",\"location\",\"location_type\",\"currency\",\"currency_symbol\",\"status\",\"page_count\",\"dish_count\"],\"table_column_priority\": '\n",
      " '[[\"id\",\"12579\",\"25121\",\"21960\"],[\"name\",\"\",\"\",\"\"],[\"sponsor\",\"TRUSTEES OF '\n",
      " 'THE MISSOURI BOTANICAL GARDEN\",\"HOLLAND HOUSE\",\"BATTERY PARK '\n",
      " 'HOTEL\"],[\"event\",\"11TH ANNUAL BANQUET\",\"LUNCHEON\",\"CHRISTMAS '\n",
      " 'DINNER\"],[\"venue\",\"PROF;\",\"COMMERCIAL\",\"COMMERCIAL\"],[\"place\",\"SOUTHERN '\n",
      " 'HOTEL,ST. LOUIS,MO.\",\"\",\"ASHVILLE, NC\"],[\"physical_description\",\"BROADSIDE; '\n",
      " 'ILLUS; 5.5 X 8.75;\",\"CARD;6X8.75;\",\"BOOKLET; ILLUS; COL; 6 X '\n",
      " '8;\"],[\"occasion\",\"ANNUAL\",\"DAILY;\",\"RELIGIOUS HOLIDAY\"],[\"notes\",\"WINES '\n",
      " 'LISTED FOR EACH COURSE;\",\"ENGLISH ON ONE SIDE,FRENCH ON ONE SIDE;\",\"PRINTED '\n",
      " 'ON PARCHMENT-LIKE PAPER; RED LION; DRAWING OF HOTEL; TIED WITH TWINE AND '\n",
      " 'SEALING WAX; MOST OF BOOKLET CONSISTS OF INFORMATION AND PRAISE ABOUT THE '\n",
      " 'HOTEL;\"],[\"call_number\",\"1900-2627\",\"1900-517\",\"1898-432\"],[\"keywords\",\"\",\"\",\"\"],[\"language\",\"\",\"\",\"\"],[\"date\",\"1900-03-31\",\"1900-01-25\",\"1898-12-25\"],[\"location\",\"Trustees '\n",
      " 'Of The Missouri Botanical Garden\",\"Holland House\",\"Battery Park '\n",
      " 'Hotel\"],[\"location_type\",\"\",\"\",\"\"],[\"currency\",\"\",\"Dollars\",\"\"],[\"currency_symbol\",\"\",\"$\",\"\"],[\"status\",\"complete\",\"complete\",\"complete\"],[\"page_count\",\"2\",\"2\",\"16\"],[\"dish_count\",\"22.0\",\"546.0\",\"28.0\"]]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(json_to_custom_string(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"[    {'from': ['Luncheon', 'lunch'], 'to': 'Luncheon'},    {'from': ['Dinner'], 'to': 'Dinner'},  # No change needed for Dinner    {'from': ['Breakfast'], 'to': 'Breakfast'},  # No change needed for Breakfast    {'from': ['', 'Unknown', None], 'to': 'Unknown'},  # Replace missing values with Unknown    {'from': ['Banquet', 'Annual Banquet'], 'to': 'Annual Banquet'},    {'from': ['Tiffin'], 'to': 'Tiffin'}  # No change needed for Tiffin]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_string = \"\"\"```python\n",
    "[\n",
    "    {'from': ['HONOLULU', 'Honolulu'], 'to': 'Honolulu'},\n",
    "    {'from': ['KANEOHE'], 'to': 'Kaneohe'},  # corrected spelling\n",
    "    {'from': ['KIHEI'], 'to': 'Kihei'},  # corrected spelling\n",
    "    {'from': ['Kailua Kona', 'KAUNAKAKAI', 'WAIMANALO', 'Waimea', 'kalaheo', 'Kahului'], 'to': 'Unknown'},  # unknown cities\n",
    "    {'from': ['HONOLULUulu'], 'to': 'Honolulu'}  # corrected spelling\n",
    "]\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.findall(r'(\\[(:?\\n?.*\\n?)*\\])', raw_string, re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "        for r in result:\n",
    "            raw_string = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[\\n    {'from': ['HONOLULU', 'Honolulu'], 'to': 'Honolulu'},\\n    {'from': ['KANEOHE'], 'to': 'Kaneohe'},  # corrected spelling\\n    {'from': ['KIHEI'], 'to': 'Kihei'},  # corrected spelling\\n    {'from': ['Kailua Kona', 'KAUNAKAKAI', 'WAIMANALO', 'Waimea', 'kalaheo', 'Kahului'], 'to': 'Unknown'},  # unknown cities\\n    {'from': ['HONOLULUulu'], 'to': 'Honolulu'}  # corrected spelling\\n]\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': ['HONOLULU', 'Honolulu'], 'to': 'Honolulu'},\n",
       " {'from': ['KANEOHE'], 'to': 'Kaneohe'},\n",
       " {'from': ['KIHEI'], 'to': 'Kihei'},\n",
       " {'from': ['Kailua Kona',\n",
       "   'KAUNAKAKAI',\n",
       "   'WAIMANALO',\n",
       "   'Waimea',\n",
       "   'kalaheo',\n",
       "   'Kahului'],\n",
       "  'to': 'Unknown'},\n",
       " {'from': ['HONOLULUulu'], 'to': 'Honolulu'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(raw_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = re.sub(r'#.*\\{$', '{', paragraph, flags=re.MULTILINE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.findall(r'(\\[(:?\\n?(^#.*\\{|]}).*\\n?)*\\])', paragraph, re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"{'city':['hhhh'] #????ddfgtecg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'foo': 'bar'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = '''\n",
    "[{'foo':'bar'} # 000asd\n",
    "]'''\n",
    "eval(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[    {'from': ['Luncheon', 'lunch'], 'to': 'Luncheon'},    {'from': ['Dinner'], 'to': 'Dinner'},  # No change needed for Dinner    {'from': ['Breakfast'], 'to': 'Breakfast'},  # No change needed for Breakfast    {'from': ['', 'Unknown', None], 'to': 'Unknown'},  # Replace missing values with Unknown    {'from': ['Banquet', 'Annual Banquet'], 'to': 'Annual Banquet'},    {'from': ['Tiffin'], 'to': 'Tiffin'}  # No change needed for Tiffin]\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"table_caption\": \"south wales derby\",\n",
      "  \"columns\": [\n",
      "    \"competition\",\n",
      "    \"total matches\",\n",
      "    \"cardiff win\",\n",
      "    \"draw\",\n",
      "    \"swansea win\"\n",
      "  ],\n",
      "  \"table_column_priority\": [\n",
      "    [\n",
      "      \"competition\",\n",
      "      \"total matches\",\n",
      "      \"cardiff win\",\n",
      "      \"draw\",\n",
      "      \"swansea win\"\n",
      "    ],\n",
      "    [\n",
      "      \"league\",\n",
      "      \"55\",\n",
      "      \"19\",\n",
      "      \"16\",\n",
      "      \"20\"\n",
      "    ],\n",
      "    [\n",
      "      \"fa cup\",\n",
      "      \"2\",\n",
      "      \"0\",\n",
      "      \"27\",\n",
      "      \"2\"\n",
      "    ],\n",
      "    [\n",
      "      \"league cup\",\n",
      "      \"5\",\n",
      "      \"2\",\n",
      "      \"0\",\n",
      "      \"3\"\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def df_to_table_format(df, table_caption):\n",
    "    # Extract column headers and index to form the first row in the table\n",
    "    columns = [\"competition\"] + df.columns.tolist()\n",
    "    \n",
    "    # Prepare rows by combining index and corresponding row values in the DataFrame\n",
    "    table_column_priority = [columns]  # Start with header row\n",
    "    for idx, row in df.iterrows():\n",
    "        table_column_priority.append([idx] + row.tolist())\n",
    "    \n",
    "    # Create the dictionary in the required format\n",
    "    table_data = {\n",
    "        \"table_caption\": table_caption,\n",
    "        \"columns\": columns,\n",
    "        \"table_column_priority\": table_column_priority\n",
    "    }\n",
    "    \n",
    "    # Convert to JSON string with indentation for readability\n",
    "    return json.dumps(table_data, indent=2)\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    \"total matches\": [\"55\", \"2\", \"5\"],\n",
    "    \"cardiff win\": [\"19\", \"0\", \"2\"],\n",
    "    \"draw\": [\"16\", \"27\", \"0\"],\n",
    "    \"swansea win\": [\"20\", \"2\", \"3\"]\n",
    "}\n",
    "index = [\"league\", \"fa cup\", \"league cup\"]\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "# Convert DataFrame to the specified format and print\n",
    "table_format_json = df_to_table_format(df, \"south wales derby\")\n",
    "print(table_format_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"table_caption\": \"south wales derby\",\n",
      "  \"columns\": [\"competition\", \"total matches\", \"cardiff win\", \"draw\", \"swansea win\"],\n",
      "  \"table_column_priority\": [[\"competition\", \"total matches\", \"cardiff win\", \"draw\", \"swansea win\"], [\"league\", \"55\", \"19\", \"16\", \"20\"], [\"fa cup\", \"2\", \"0\", \"27\", \"2\"], [\"league cup\", \"5\", \"2\", \"0\", \"3\"]]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def df_to_table_format(df, table_caption):\n",
    "    # Extract column headers and index to form the first row in the table\n",
    "    columns = [\"competition\"] + df.columns.tolist()\n",
    "    \n",
    "    # Prepare rows by combining index and corresponding row values in the DataFrame\n",
    "    table_column_priority = [columns]  # Start with header row\n",
    "    for idx, row in df.iterrows():\n",
    "        table_column_priority.append([idx] + row.tolist())\n",
    "    \n",
    "    # Create the dictionary in the required format\n",
    "    table_data = {\n",
    "        \"table_caption\": table_caption,\n",
    "        \"columns\": columns,\n",
    "        \"table_column_priority\": table_column_priority\n",
    "    }\n",
    "    \n",
    "    # Format 'columns' as a compact list and use json.dumps for the rest\n",
    "    columns_str = f'\"columns\": {json.dumps(columns)}'\n",
    "    table_column_priority_str = f'\"table_column_priority\": {json.dumps(table_column_priority)}'\n",
    "    caption_str = f'\"table_caption\": \"{table_caption}\"'\n",
    "    \n",
    "    # Concatenate each component into a final JSON format\n",
    "    final_output = f'{{\\n  {caption_str},\\n  {columns_str},\\n  {table_column_priority_str}\\n}}'\n",
    "    \n",
    "    return final_output\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    \"total matches\": [\"55\", \"2\", \"5\"],\n",
    "    \"cardiff win\": [\"19\", \"0\", \"2\"],\n",
    "    \"draw\": [\"16\", \"27\", \"0\"],\n",
    "    \"swansea win\": [\"20\", \"2\", \"3\"]\n",
    "}\n",
    "index = [\"league\", \"fa cup\", \"league cup\"]\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "# Convert DataFrame to the specified format and print\n",
    "table_format_json = df_to_table_format(df, \"south wales derby\")\n",
    "print(table_format_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"table_caption\": \"south wales derby\",\n",
      "  \"columns\": [\n",
      "    \"competition\",\n",
      "    \"total matches\",\n",
      "    \"cardiff win\",\n",
      "    \"draw\",\n",
      "    \"swansea win\"\n",
      "  ],\n",
      "  \"table_column_priority\": [\n",
      "    [\n",
      "      \"competition\",\n",
      "      \"league\",\n",
      "      \"fa cup\",\n",
      "      \"league cup\"\n",
      "    ],\n",
      "    [\n",
      "      \"total matches\",\n",
      "      \"55\",\n",
      "      \"2\",\n",
      "      \"5\"\n",
      "    ],\n",
      "    [\n",
      "      \"cardiff win\",\n",
      "      \"19\",\n",
      "      \"0\",\n",
      "      \"2\"\n",
      "    ],\n",
      "    [\n",
      "      \"draw\",\n",
      "      \"16\",\n",
      "      \"27\",\n",
      "      \"0\"\n",
      "    ],\n",
      "    [\n",
      "      \"swansea win\",\n",
      "      \"20\",\n",
      "      \"2\",\n",
      "      \"3\"\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def df_to_table_format(df, table_caption):\n",
    "    # Prepare rows for table_column_priority\n",
    "    table_column_priority = []\n",
    "    \n",
    "    # The first list is the competition names (the DataFrame index)\n",
    "    table_column_priority.append([\"competition\"] + df.index.tolist())\n",
    "    \n",
    "    # Append each DataFrame column values to table_column_priority\n",
    "    for col in df.columns:\n",
    "        table_column_priority.append([col] + df[col].tolist())\n",
    "    \n",
    "    # Create the final dictionary\n",
    "    table_data = {\n",
    "        \"table_caption\": table_caption,\n",
    "        \"columns\": [\"competition\"] + df.columns.tolist(),\n",
    "        \"table_column_priority\": table_column_priority\n",
    "    }\n",
    "    \n",
    "    return table_data\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    \"total matches\": [\"55\", \"2\", \"5\"],\n",
    "    \"cardiff win\": [\"19\", \"0\", \"2\"],\n",
    "    \"draw\": [\"16\", \"27\", \"0\"],\n",
    "    \"swansea win\": [\"20\", \"2\", \"3\"]\n",
    "}\n",
    "index = [\"league\", \"fa cup\", \"league cup\"]\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "# Convert DataFrame to the specified format\n",
    "table_format = df_to_table_format(df, \"south wales derby\")\n",
    "\n",
    "# Print the output in the desired format\n",
    "print(json.dumps(table_format, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4dc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
